{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67b5a42-6c25-4bb5-ab2d-a68d1bf22fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "     \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a37771-2b38-434b-8cee-9bc76b50cdbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): Sequential()\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): QuantConv2d(\n",
      "      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"VGG16_quant4bit\"\n",
    "model = VGG16_quant()\n",
    "\n",
    "conv_layer_index = 27\n",
    "\n",
    "model.features[24] = QuantConv2d(256, 8, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model.features[25] = nn.BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "model.features[conv_layer_index] = QuantConv2d(\n",
    "    in_channels=8,\n",
    "    out_channels=8,\n",
    "    kernel_size=3,\n",
    "    stride=1,\n",
    "    padding=1,\n",
    "    bias=False\n",
    ")\n",
    "model.features[28] = nn.Sequential()\n",
    "model.features[30] = QuantConv2d(8, 512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "junior-reminder",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 3.483 (3.483)\tData 0.968 (0.968)\tLoss 2.4381 (2.4381)\tPrec 7.812% (7.812%)\n",
      "Epoch: [0][100/391]\tTime 0.043 (0.079)\tData 0.002 (0.013)\tLoss 2.3082 (3.5804)\tPrec 9.375% (11.409%)\n",
      "Epoch: [0][200/391]\tTime 0.049 (0.062)\tData 0.003 (0.008)\tLoss 2.3215 (2.9492)\tPrec 14.062% (11.785%)\n",
      "Epoch: [0][300/391]\tTime 0.042 (0.056)\tData 0.003 (0.006)\tLoss 2.2700 (2.7269)\tPrec 11.719% (12.059%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.291 (0.291)\tLoss 2.2449 (2.2449)\tPrec 14.062% (14.062%)\n",
      " * Prec 15.660% \n",
      "best acc: 15.660000\n",
      "Epoch: [1][0/391]\tTime 1.131 (1.131)\tData 1.074 (1.074)\tLoss 2.3365 (2.3365)\tPrec 13.281% (13.281%)\n",
      "Epoch: [1][100/391]\tTime 0.041 (0.052)\tData 0.002 (0.013)\tLoss 2.2836 (2.2461)\tPrec 18.750% (14.124%)\n",
      "Epoch: [1][200/391]\tTime 0.041 (0.047)\tData 0.002 (0.008)\tLoss 2.2234 (2.2306)\tPrec 17.188% (15.295%)\n",
      "Epoch: [1][300/391]\tTime 0.044 (0.046)\tData 0.003 (0.006)\tLoss 2.1250 (2.2139)\tPrec 21.094% (15.900%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.309 (0.309)\tLoss 1.9568 (1.9568)\tPrec 33.594% (33.594%)\n",
      " * Prec 21.920% \n",
      "best acc: 21.920000\n",
      "Epoch: [2][0/391]\tTime 0.815 (0.815)\tData 0.777 (0.777)\tLoss 2.0242 (2.0242)\tPrec 26.562% (26.562%)\n",
      "Epoch: [2][100/391]\tTime 0.039 (0.049)\tData 0.002 (0.010)\tLoss 1.9854 (2.0680)\tPrec 29.688% (21.689%)\n",
      "Epoch: [2][200/391]\tTime 0.043 (0.045)\tData 0.002 (0.006)\tLoss 2.0798 (2.0271)\tPrec 21.094% (23.103%)\n",
      "Epoch: [2][300/391]\tTime 0.040 (0.044)\tData 0.002 (0.005)\tLoss 1.9011 (2.0014)\tPrec 25.781% (23.754%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.241 (0.241)\tLoss 2.0227 (2.0227)\tPrec 24.219% (24.219%)\n",
      " * Prec 24.010% \n",
      "best acc: 24.010000\n",
      "Epoch: [3][0/391]\tTime 0.818 (0.818)\tData 0.762 (0.762)\tLoss 1.8842 (1.8842)\tPrec 25.781% (25.781%)\n",
      "Epoch: [3][100/391]\tTime 0.040 (0.051)\tData 0.002 (0.010)\tLoss 1.9569 (1.8700)\tPrec 30.469% (27.413%)\n",
      "Epoch: [3][200/391]\tTime 0.046 (0.046)\tData 0.003 (0.006)\tLoss 1.8726 (1.8658)\tPrec 25.781% (27.725%)\n",
      "Epoch: [3][300/391]\tTime 0.043 (0.044)\tData 0.002 (0.005)\tLoss 1.8352 (1.8555)\tPrec 31.250% (27.941%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.323 (0.323)\tLoss 1.9204 (1.9204)\tPrec 28.125% (28.125%)\n",
      " * Prec 28.130% \n",
      "best acc: 28.130000\n",
      "Epoch: [4][0/391]\tTime 0.816 (0.816)\tData 0.763 (0.763)\tLoss 1.9676 (1.9676)\tPrec 23.438% (23.438%)\n",
      "Epoch: [4][100/391]\tTime 0.042 (0.048)\tData 0.002 (0.010)\tLoss 1.8200 (1.8434)\tPrec 29.688% (28.442%)\n",
      "Epoch: [4][200/391]\tTime 0.037 (0.044)\tData 0.002 (0.006)\tLoss 1.7508 (1.8156)\tPrec 32.812% (29.474%)\n",
      "Epoch: [4][300/391]\tTime 0.044 (0.043)\tData 0.002 (0.005)\tLoss 1.9247 (1.7977)\tPrec 30.469% (30.240%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.793 (0.793)\tLoss 1.8212 (1.8212)\tPrec 28.125% (28.125%)\n",
      " * Prec 31.930% \n",
      "best acc: 31.930000\n",
      "Epoch: [5][0/391]\tTime 0.795 (0.795)\tData 0.730 (0.730)\tLoss 1.6759 (1.6759)\tPrec 28.906% (28.906%)\n",
      "Epoch: [5][100/391]\tTime 0.040 (0.048)\tData 0.002 (0.009)\tLoss 1.5720 (1.7201)\tPrec 37.500% (32.333%)\n",
      "Epoch: [5][200/391]\tTime 0.038 (0.045)\tData 0.001 (0.006)\tLoss 1.6760 (1.7060)\tPrec 39.844% (33.333%)\n",
      "Epoch: [5][300/391]\tTime 0.038 (0.043)\tData 0.002 (0.005)\tLoss 1.6619 (1.6915)\tPrec 34.375% (33.960%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.258 (0.258)\tLoss 1.6927 (1.6927)\tPrec 34.375% (34.375%)\n",
      " * Prec 34.090% \n",
      "best acc: 34.090000\n",
      "Epoch: [6][0/391]\tTime 0.652 (0.652)\tData 0.599 (0.599)\tLoss 1.6476 (1.6476)\tPrec 30.469% (30.469%)\n",
      "Epoch: [6][100/391]\tTime 0.044 (0.047)\tData 0.002 (0.008)\tLoss 1.6975 (1.6190)\tPrec 35.156% (36.711%)\n",
      "Epoch: [6][200/391]\tTime 0.039 (0.043)\tData 0.002 (0.005)\tLoss 1.5429 (1.6205)\tPrec 35.156% (36.866%)\n",
      "Epoch: [6][300/391]\tTime 0.045 (0.043)\tData 0.002 (0.004)\tLoss 1.5684 (1.6125)\tPrec 41.406% (37.168%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.274 (0.274)\tLoss 1.6014 (1.6014)\tPrec 40.625% (40.625%)\n",
      " * Prec 38.930% \n",
      "best acc: 38.930000\n",
      "Epoch: [7][0/391]\tTime 0.832 (0.832)\tData 0.780 (0.780)\tLoss 1.5264 (1.5264)\tPrec 47.656% (47.656%)\n",
      "Epoch: [7][100/391]\tTime 0.045 (0.048)\tData 0.003 (0.010)\tLoss 1.5144 (1.5565)\tPrec 40.625% (40.261%)\n",
      "Epoch: [7][200/391]\tTime 0.037 (0.045)\tData 0.002 (0.006)\tLoss 1.4792 (1.5423)\tPrec 42.188% (40.563%)\n",
      "Epoch: [7][300/391]\tTime 0.043 (0.043)\tData 0.003 (0.005)\tLoss 1.4800 (1.5268)\tPrec 38.281% (41.404%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.448 (0.448)\tLoss 1.4518 (1.4518)\tPrec 46.094% (46.094%)\n",
      " * Prec 43.970% \n",
      "best acc: 43.970000\n",
      "Epoch: [8][0/391]\tTime 0.890 (0.890)\tData 0.835 (0.835)\tLoss 1.3567 (1.3567)\tPrec 46.094% (46.094%)\n",
      "Epoch: [8][100/391]\tTime 0.043 (0.049)\tData 0.002 (0.011)\tLoss 1.2555 (1.4359)\tPrec 57.812% (46.016%)\n",
      "Epoch: [8][200/391]\tTime 0.040 (0.045)\tData 0.002 (0.006)\tLoss 1.3267 (1.4119)\tPrec 52.344% (46.922%)\n",
      "Epoch: [8][300/391]\tTime 0.042 (0.043)\tData 0.002 (0.005)\tLoss 1.2499 (1.3893)\tPrec 53.125% (47.944%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.358 (0.358)\tLoss 1.2846 (1.2846)\tPrec 55.469% (55.469%)\n",
      " * Prec 52.460% \n",
      "best acc: 52.460000\n",
      "Epoch: [9][0/391]\tTime 0.699 (0.699)\tData 0.638 (0.638)\tLoss 1.3541 (1.3541)\tPrec 45.312% (45.312%)\n",
      "Epoch: [9][100/391]\tTime 0.041 (0.048)\tData 0.002 (0.009)\tLoss 1.3045 (1.2821)\tPrec 50.781% (52.653%)\n",
      "Epoch: [9][200/391]\tTime 0.038 (0.044)\tData 0.002 (0.005)\tLoss 1.1519 (1.2650)\tPrec 57.031% (53.568%)\n",
      "Epoch: [9][300/391]\tTime 0.041 (0.043)\tData 0.002 (0.004)\tLoss 1.3404 (1.2558)\tPrec 52.344% (53.766%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.303 (0.303)\tLoss 1.3352 (1.3352)\tPrec 50.781% (50.781%)\n",
      " * Prec 53.950% \n",
      "best acc: 53.950000\n",
      "Epoch: [10][0/391]\tTime 0.747 (0.747)\tData 0.694 (0.694)\tLoss 1.1985 (1.1985)\tPrec 57.812% (57.812%)\n",
      "Epoch: [10][100/391]\tTime 0.043 (0.048)\tData 0.002 (0.009)\tLoss 1.1063 (1.1627)\tPrec 57.031% (58.153%)\n",
      "Epoch: [10][200/391]\tTime 0.040 (0.044)\tData 0.002 (0.006)\tLoss 1.1052 (1.1493)\tPrec 63.281% (58.815%)\n",
      "Epoch: [10][300/391]\tTime 0.049 (0.043)\tData 0.002 (0.004)\tLoss 1.2536 (1.1329)\tPrec 59.375% (59.396%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.9498 (0.9498)\tPrec 66.406% (66.406%)\n",
      " * Prec 62.570% \n",
      "best acc: 62.570000\n",
      "Epoch: [11][0/391]\tTime 0.774 (0.774)\tData 0.723 (0.723)\tLoss 1.1192 (1.1192)\tPrec 63.281% (63.281%)\n",
      "Epoch: [11][100/391]\tTime 0.040 (0.049)\tData 0.002 (0.010)\tLoss 0.9410 (1.0482)\tPrec 62.500% (62.407%)\n",
      "Epoch: [11][200/391]\tTime 0.037 (0.045)\tData 0.002 (0.006)\tLoss 1.2939 (1.0295)\tPrec 60.938% (63.126%)\n",
      "Epoch: [11][300/391]\tTime 0.047 (0.044)\tData 0.003 (0.005)\tLoss 1.0234 (1.0192)\tPrec 66.406% (63.567%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.311 (0.311)\tLoss 0.9629 (0.9629)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.620% \n",
      "best acc: 63.620000\n",
      "Epoch: [12][0/391]\tTime 0.818 (0.818)\tData 0.763 (0.763)\tLoss 1.0206 (1.0206)\tPrec 60.938% (60.938%)\n",
      "Epoch: [12][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.010)\tLoss 0.9858 (0.9529)\tPrec 66.406% (65.950%)\n",
      "Epoch: [12][200/391]\tTime 0.041 (0.045)\tData 0.002 (0.006)\tLoss 0.8982 (0.9393)\tPrec 73.438% (66.294%)\n",
      "Epoch: [12][300/391]\tTime 0.043 (0.044)\tData 0.002 (0.005)\tLoss 0.9176 (0.9315)\tPrec 67.188% (66.754%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.055 (1.055)\tLoss 0.9906 (0.9906)\tPrec 66.406% (66.406%)\n",
      " * Prec 64.750% \n",
      "best acc: 64.750000\n",
      "Epoch: [13][0/391]\tTime 0.804 (0.804)\tData 0.760 (0.760)\tLoss 0.7100 (0.7100)\tPrec 77.344% (77.344%)\n",
      "Epoch: [13][100/391]\tTime 0.039 (0.049)\tData 0.002 (0.010)\tLoss 0.9282 (0.8668)\tPrec 67.969% (69.237%)\n",
      "Epoch: [13][200/391]\tTime 0.040 (0.045)\tData 0.002 (0.006)\tLoss 0.9564 (0.8615)\tPrec 71.875% (69.446%)\n",
      "Epoch: [13][300/391]\tTime 0.039 (0.044)\tData 0.002 (0.005)\tLoss 0.9939 (0.8596)\tPrec 60.938% (69.573%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.372 (0.372)\tLoss 0.8068 (0.8068)\tPrec 72.656% (72.656%)\n",
      " * Prec 71.620% \n",
      "best acc: 71.620000\n",
      "Epoch: [14][0/391]\tTime 1.002 (1.002)\tData 0.949 (0.949)\tLoss 0.8542 (0.8542)\tPrec 67.969% (67.969%)\n",
      "Epoch: [14][100/391]\tTime 0.042 (0.050)\tData 0.002 (0.011)\tLoss 0.7493 (0.8035)\tPrec 76.562% (72.037%)\n",
      "Epoch: [14][200/391]\tTime 0.042 (0.045)\tData 0.002 (0.007)\tLoss 0.9825 (0.8036)\tPrec 67.188% (72.112%)\n",
      "Epoch: [14][300/391]\tTime 0.040 (0.044)\tData 0.002 (0.005)\tLoss 0.8825 (0.7954)\tPrec 67.969% (72.220%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.283 (0.283)\tLoss 0.8450 (0.8450)\tPrec 70.312% (70.312%)\n",
      " * Prec 70.030% \n",
      "best acc: 71.620000\n",
      "Epoch: [15][0/391]\tTime 0.805 (0.805)\tData 0.740 (0.740)\tLoss 0.7158 (0.7158)\tPrec 75.781% (75.781%)\n",
      "Epoch: [15][100/391]\tTime 0.068 (0.049)\tData 0.022 (0.010)\tLoss 0.7682 (0.7563)\tPrec 76.562% (73.438%)\n",
      "Epoch: [15][200/391]\tTime 0.042 (0.045)\tData 0.002 (0.006)\tLoss 0.8787 (0.7574)\tPrec 67.969% (73.651%)\n",
      "Epoch: [15][300/391]\tTime 0.041 (0.043)\tData 0.002 (0.005)\tLoss 0.8733 (0.7539)\tPrec 71.875% (73.884%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.306 (0.306)\tLoss 0.7825 (0.7825)\tPrec 75.781% (75.781%)\n",
      " * Prec 73.270% \n",
      "best acc: 73.270000\n",
      "Epoch: [16][0/391]\tTime 0.786 (0.786)\tData 0.719 (0.719)\tLoss 0.7207 (0.7207)\tPrec 76.562% (76.562%)\n",
      "Epoch: [16][100/391]\tTime 0.042 (0.049)\tData 0.003 (0.010)\tLoss 0.6583 (0.7107)\tPrec 77.344% (75.642%)\n",
      "Epoch: [16][200/391]\tTime 0.043 (0.045)\tData 0.002 (0.006)\tLoss 0.7751 (0.7059)\tPrec 73.438% (75.836%)\n",
      "Epoch: [16][300/391]\tTime 0.051 (0.044)\tData 0.002 (0.005)\tLoss 0.5996 (0.7092)\tPrec 78.125% (75.771%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.434 (0.434)\tLoss 0.6515 (0.6515)\tPrec 75.000% (75.000%)\n",
      " * Prec 75.310% \n",
      "best acc: 75.310000\n",
      "Epoch: [17][0/391]\tTime 0.824 (0.824)\tData 0.761 (0.761)\tLoss 0.8070 (0.8070)\tPrec 66.406% (66.406%)\n",
      "Epoch: [17][100/391]\tTime 0.048 (0.051)\tData 0.003 (0.010)\tLoss 0.7290 (0.6601)\tPrec 73.438% (77.351%)\n",
      "Epoch: [17][200/391]\tTime 0.048 (0.048)\tData 0.003 (0.007)\tLoss 0.7867 (0.6649)\tPrec 69.531% (77.355%)\n",
      "Epoch: [17][300/391]\tTime 0.044 (0.047)\tData 0.003 (0.006)\tLoss 0.7587 (0.6711)\tPrec 76.562% (77.123%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.301 (0.301)\tLoss 0.5614 (0.5614)\tPrec 84.375% (84.375%)\n",
      " * Prec 76.040% \n",
      "best acc: 76.040000\n",
      "Epoch: [18][0/391]\tTime 0.796 (0.796)\tData 0.744 (0.744)\tLoss 0.6746 (0.6746)\tPrec 78.906% (78.906%)\n",
      "Epoch: [18][100/391]\tTime 0.048 (0.051)\tData 0.003 (0.010)\tLoss 0.4920 (0.6166)\tPrec 85.938% (78.806%)\n",
      "Epoch: [18][200/391]\tTime 0.040 (0.047)\tData 0.002 (0.006)\tLoss 0.5969 (0.6261)\tPrec 80.469% (78.409%)\n",
      "Epoch: [18][300/391]\tTime 0.046 (0.045)\tData 0.002 (0.005)\tLoss 0.6560 (0.6291)\tPrec 77.344% (78.343%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.710 (0.710)\tLoss 0.5981 (0.5981)\tPrec 81.250% (81.250%)\n",
      " * Prec 76.470% \n",
      "best acc: 76.470000\n",
      "Epoch: [19][0/391]\tTime 0.812 (0.812)\tData 0.760 (0.760)\tLoss 0.4772 (0.4772)\tPrec 85.938% (85.938%)\n",
      "Epoch: [19][100/391]\tTime 0.043 (0.050)\tData 0.003 (0.010)\tLoss 0.6074 (0.5984)\tPrec 77.344% (79.889%)\n",
      "Epoch: [19][200/391]\tTime 0.039 (0.045)\tData 0.002 (0.006)\tLoss 0.5418 (0.5986)\tPrec 81.250% (79.645%)\n",
      "Epoch: [19][300/391]\tTime 0.044 (0.045)\tData 0.003 (0.005)\tLoss 0.5731 (0.5962)\tPrec 78.125% (79.659%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.286 (0.286)\tLoss 0.5671 (0.5671)\tPrec 78.906% (78.906%)\n",
      " * Prec 77.410% \n",
      "best acc: 77.410000\n",
      "Epoch: [20][0/391]\tTime 0.959 (0.959)\tData 0.904 (0.904)\tLoss 0.7596 (0.7596)\tPrec 75.000% (75.000%)\n",
      "Epoch: [20][100/391]\tTime 0.040 (0.054)\tData 0.003 (0.012)\tLoss 0.5546 (0.5611)\tPrec 75.781% (81.010%)\n",
      "Epoch: [20][200/391]\tTime 0.047 (0.049)\tData 0.003 (0.007)\tLoss 0.5247 (0.5632)\tPrec 79.688% (80.795%)\n",
      "Epoch: [20][300/391]\tTime 0.044 (0.047)\tData 0.003 (0.006)\tLoss 0.6030 (0.5659)\tPrec 82.812% (80.731%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.675 (0.675)\tLoss 0.5526 (0.5526)\tPrec 81.250% (81.250%)\n",
      " * Prec 77.660% \n",
      "best acc: 77.660000\n",
      "Epoch: [21][0/391]\tTime 0.757 (0.757)\tData 0.691 (0.691)\tLoss 0.6882 (0.6882)\tPrec 77.344% (77.344%)\n",
      "Epoch: [21][100/391]\tTime 0.044 (0.050)\tData 0.002 (0.010)\tLoss 0.5876 (0.5361)\tPrec 81.250% (81.799%)\n",
      "Epoch: [21][200/391]\tTime 0.042 (0.046)\tData 0.002 (0.006)\tLoss 0.4575 (0.5389)\tPrec 82.031% (81.705%)\n",
      "Epoch: [21][300/391]\tTime 0.043 (0.045)\tData 0.003 (0.005)\tLoss 0.3529 (0.5418)\tPrec 87.500% (81.632%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.949 (0.949)\tLoss 0.5258 (0.5258)\tPrec 80.469% (80.469%)\n",
      " * Prec 80.060% \n",
      "best acc: 80.060000\n",
      "Epoch: [22][0/391]\tTime 0.667 (0.667)\tData 0.612 (0.612)\tLoss 0.3785 (0.3785)\tPrec 87.500% (87.500%)\n",
      "Epoch: [22][100/391]\tTime 0.046 (0.051)\tData 0.003 (0.009)\tLoss 0.5588 (0.5142)\tPrec 83.594% (82.464%)\n",
      "Epoch: [22][200/391]\tTime 0.050 (0.049)\tData 0.003 (0.006)\tLoss 0.5659 (0.5229)\tPrec 81.250% (82.070%)\n",
      "Epoch: [22][300/391]\tTime 0.045 (0.048)\tData 0.002 (0.005)\tLoss 0.5568 (0.5209)\tPrec 78.906% (82.309%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.496 (0.496)\tLoss 0.6982 (0.6982)\tPrec 78.906% (78.906%)\n",
      " * Prec 78.670% \n",
      "best acc: 80.060000\n",
      "Epoch: [23][0/391]\tTime 0.710 (0.710)\tData 0.653 (0.653)\tLoss 0.5894 (0.5894)\tPrec 78.125% (78.125%)\n",
      "Epoch: [23][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.009)\tLoss 0.4247 (0.4887)\tPrec 85.156% (83.872%)\n",
      "Epoch: [23][200/391]\tTime 0.044 (0.047)\tData 0.003 (0.006)\tLoss 0.4842 (0.4980)\tPrec 84.375% (83.415%)\n",
      "Epoch: [23][300/391]\tTime 0.038 (0.045)\tData 0.002 (0.005)\tLoss 0.4313 (0.4957)\tPrec 84.375% (83.542%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.321 (0.321)\tLoss 0.4931 (0.4931)\tPrec 82.812% (82.812%)\n",
      " * Prec 81.640% \n",
      "best acc: 81.640000\n",
      "Epoch: [24][0/391]\tTime 0.660 (0.660)\tData 0.617 (0.617)\tLoss 0.4885 (0.4885)\tPrec 82.812% (82.812%)\n",
      "Epoch: [24][100/391]\tTime 0.043 (0.047)\tData 0.003 (0.008)\tLoss 0.4956 (0.4689)\tPrec 82.812% (84.004%)\n",
      "Epoch: [24][200/391]\tTime 0.043 (0.045)\tData 0.003 (0.005)\tLoss 0.4363 (0.4771)\tPrec 84.375% (83.893%)\n",
      "Epoch: [24][300/391]\tTime 0.043 (0.044)\tData 0.002 (0.004)\tLoss 0.5474 (0.4809)\tPrec 82.812% (83.861%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.268 (0.268)\tLoss 0.7172 (0.7172)\tPrec 75.781% (75.781%)\n",
      " * Prec 74.440% \n",
      "best acc: 81.640000\n",
      "Epoch: [25][0/391]\tTime 0.820 (0.820)\tData 0.755 (0.755)\tLoss 0.5850 (0.5850)\tPrec 82.031% (82.031%)\n",
      "Epoch: [25][100/391]\tTime 0.048 (0.050)\tData 0.003 (0.010)\tLoss 0.3241 (0.4566)\tPrec 90.625% (84.367%)\n",
      "Epoch: [25][200/391]\tTime 0.040 (0.046)\tData 0.002 (0.006)\tLoss 0.4569 (0.4634)\tPrec 85.156% (84.227%)\n",
      "Epoch: [25][300/391]\tTime 0.043 (0.044)\tData 0.003 (0.005)\tLoss 0.5203 (0.4616)\tPrec 84.375% (84.391%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.743 (0.743)\tLoss 0.3019 (0.3019)\tPrec 87.500% (87.500%)\n",
      " * Prec 83.300% \n",
      "best acc: 83.300000\n",
      "Epoch: [26][0/391]\tTime 0.639 (0.639)\tData 0.585 (0.585)\tLoss 0.3870 (0.3870)\tPrec 87.500% (87.500%)\n",
      "Epoch: [26][100/391]\tTime 0.038 (0.048)\tData 0.002 (0.008)\tLoss 0.5574 (0.4494)\tPrec 83.594% (84.754%)\n",
      "Epoch: [26][200/391]\tTime 0.046 (0.046)\tData 0.003 (0.005)\tLoss 0.5077 (0.4439)\tPrec 82.812% (85.133%)\n",
      "Epoch: [26][300/391]\tTime 0.050 (0.045)\tData 0.003 (0.004)\tLoss 0.4812 (0.4477)\tPrec 85.938% (85.065%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.268 (0.268)\tLoss 0.3791 (0.3791)\tPrec 88.281% (88.281%)\n",
      " * Prec 83.500% \n",
      "best acc: 83.500000\n",
      "Epoch: [27][0/391]\tTime 0.799 (0.799)\tData 0.745 (0.745)\tLoss 0.5548 (0.5548)\tPrec 80.469% (80.469%)\n",
      "Epoch: [27][100/391]\tTime 0.040 (0.049)\tData 0.002 (0.010)\tLoss 0.4510 (0.4255)\tPrec 84.375% (85.729%)\n",
      "Epoch: [27][200/391]\tTime 0.040 (0.045)\tData 0.003 (0.006)\tLoss 0.4758 (0.4272)\tPrec 82.812% (85.798%)\n",
      "Epoch: [27][300/391]\tTime 0.039 (0.044)\tData 0.002 (0.005)\tLoss 0.5068 (0.4267)\tPrec 85.156% (85.725%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.477 (0.477)\tLoss 0.4366 (0.4366)\tPrec 83.594% (83.594%)\n",
      " * Prec 82.440% \n",
      "best acc: 83.500000\n",
      "Epoch: [28][0/391]\tTime 0.916 (0.916)\tData 0.861 (0.861)\tLoss 0.3763 (0.3763)\tPrec 88.281% (88.281%)\n",
      "Epoch: [28][100/391]\tTime 0.040 (0.053)\tData 0.002 (0.012)\tLoss 0.3046 (0.4008)\tPrec 89.844% (86.425%)\n",
      "Epoch: [28][200/391]\tTime 0.048 (0.048)\tData 0.003 (0.007)\tLoss 0.4107 (0.4100)\tPrec 82.031% (86.120%)\n",
      "Epoch: [28][300/391]\tTime 0.046 (0.046)\tData 0.003 (0.006)\tLoss 0.4905 (0.4110)\tPrec 86.719% (86.130%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.339 (0.339)\tLoss 0.5736 (0.5736)\tPrec 82.031% (82.031%)\n",
      " * Prec 81.970% \n",
      "best acc: 83.500000\n",
      "Epoch: [29][0/391]\tTime 0.850 (0.850)\tData 0.794 (0.794)\tLoss 0.3450 (0.3450)\tPrec 89.844% (89.844%)\n",
      "Epoch: [29][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.010)\tLoss 0.3758 (0.3903)\tPrec 88.281% (87.136%)\n",
      "Epoch: [29][200/391]\tTime 0.051 (0.049)\tData 0.003 (0.006)\tLoss 0.4227 (0.3940)\tPrec 81.250% (86.831%)\n",
      "Epoch: [29][300/391]\tTime 0.049 (0.048)\tData 0.003 (0.005)\tLoss 0.4782 (0.4008)\tPrec 84.375% (86.589%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.286 (0.286)\tLoss 0.4785 (0.4785)\tPrec 81.250% (81.250%)\n",
      " * Prec 81.830% \n",
      "best acc: 83.500000\n",
      "Epoch: [30][0/391]\tTime 0.795 (0.795)\tData 0.734 (0.734)\tLoss 0.4106 (0.4106)\tPrec 84.375% (84.375%)\n",
      "Epoch: [30][100/391]\tTime 0.043 (0.050)\tData 0.002 (0.009)\tLoss 0.4238 (0.3692)\tPrec 86.719% (87.508%)\n",
      "Epoch: [30][200/391]\tTime 0.039 (0.046)\tData 0.002 (0.006)\tLoss 0.2837 (0.3836)\tPrec 92.188% (87.006%)\n",
      "Epoch: [30][300/391]\tTime 0.049 (0.045)\tData 0.002 (0.005)\tLoss 0.4077 (0.3866)\tPrec 83.594% (86.955%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.576 (0.576)\tLoss 0.3536 (0.3536)\tPrec 88.281% (88.281%)\n",
      " * Prec 82.080% \n",
      "best acc: 83.500000\n",
      "Epoch: [31][0/391]\tTime 0.683 (0.683)\tData 0.606 (0.606)\tLoss 0.4646 (0.4646)\tPrec 83.594% (83.594%)\n",
      "Epoch: [31][100/391]\tTime 0.042 (0.050)\tData 0.003 (0.009)\tLoss 0.2089 (0.3636)\tPrec 92.188% (87.848%)\n",
      "Epoch: [31][200/391]\tTime 0.040 (0.046)\tData 0.003 (0.005)\tLoss 0.4247 (0.3740)\tPrec 86.719% (87.574%)\n",
      "Epoch: [31][300/391]\tTime 0.038 (0.044)\tData 0.002 (0.004)\tLoss 0.4041 (0.3736)\tPrec 85.156% (87.523%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.481 (0.481)\tLoss 0.3586 (0.3586)\tPrec 85.938% (85.938%)\n",
      " * Prec 84.660% \n",
      "best acc: 84.660000\n",
      "Epoch: [32][0/391]\tTime 0.736 (0.736)\tData 0.682 (0.682)\tLoss 0.2815 (0.2815)\tPrec 89.844% (89.844%)\n",
      "Epoch: [32][100/391]\tTime 0.049 (0.048)\tData 0.003 (0.009)\tLoss 0.3135 (0.3399)\tPrec 88.281% (88.645%)\n",
      "Epoch: [32][200/391]\tTime 0.039 (0.049)\tData 0.003 (0.006)\tLoss 0.3131 (0.3543)\tPrec 90.625% (88.083%)\n",
      "Epoch: [32][300/391]\tTime 0.052 (0.049)\tData 0.003 (0.005)\tLoss 0.3360 (0.3610)\tPrec 86.719% (87.871%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.769 (0.769)\tLoss 0.3397 (0.3397)\tPrec 89.062% (89.062%)\n",
      " * Prec 83.800% \n",
      "best acc: 84.660000\n",
      "Epoch: [33][0/391]\tTime 0.808 (0.808)\tData 0.756 (0.756)\tLoss 0.2434 (0.2434)\tPrec 92.188% (92.188%)\n",
      "Epoch: [33][100/391]\tTime 0.048 (0.052)\tData 0.003 (0.010)\tLoss 0.3384 (0.3455)\tPrec 90.625% (88.297%)\n",
      "Epoch: [33][200/391]\tTime 0.045 (0.048)\tData 0.003 (0.007)\tLoss 0.4164 (0.3436)\tPrec 88.281% (88.262%)\n",
      "Epoch: [33][300/391]\tTime 0.041 (0.046)\tData 0.002 (0.005)\tLoss 0.3188 (0.3475)\tPrec 86.719% (88.167%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.534 (0.534)\tLoss 0.3234 (0.3234)\tPrec 89.844% (89.844%)\n",
      " * Prec 83.590% \n",
      "best acc: 84.660000\n",
      "Epoch: [34][0/391]\tTime 0.768 (0.768)\tData 0.690 (0.690)\tLoss 0.2823 (0.2823)\tPrec 90.625% (90.625%)\n",
      "Epoch: [34][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.009)\tLoss 0.2511 (0.3401)\tPrec 91.406% (88.660%)\n",
      "Epoch: [34][200/391]\tTime 0.041 (0.047)\tData 0.003 (0.006)\tLoss 0.4600 (0.3374)\tPrec 85.156% (88.740%)\n",
      "Epoch: [34][300/391]\tTime 0.036 (0.045)\tData 0.002 (0.005)\tLoss 0.3065 (0.3372)\tPrec 89.844% (88.725%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.258 (0.258)\tLoss 0.3298 (0.3298)\tPrec 87.500% (87.500%)\n",
      " * Prec 84.910% \n",
      "best acc: 84.910000\n",
      "Epoch: [35][0/391]\tTime 0.701 (0.701)\tData 0.646 (0.646)\tLoss 0.3567 (0.3567)\tPrec 86.719% (86.719%)\n",
      "Epoch: [35][100/391]\tTime 0.040 (0.049)\tData 0.003 (0.009)\tLoss 0.3823 (0.3153)\tPrec 85.938% (89.395%)\n",
      "Epoch: [35][200/391]\tTime 0.042 (0.045)\tData 0.002 (0.006)\tLoss 0.2511 (0.3191)\tPrec 91.406% (89.167%)\n",
      "Epoch: [35][300/391]\tTime 0.040 (0.044)\tData 0.002 (0.005)\tLoss 0.3459 (0.3234)\tPrec 86.719% (89.117%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.258 (0.258)\tLoss 0.5258 (0.5258)\tPrec 82.812% (82.812%)\n",
      " * Prec 82.760% \n",
      "best acc: 84.910000\n",
      "Epoch: [36][0/391]\tTime 0.874 (0.874)\tData 0.835 (0.835)\tLoss 0.3657 (0.3657)\tPrec 92.188% (92.188%)\n",
      "Epoch: [36][100/391]\tTime 0.041 (0.049)\tData 0.003 (0.011)\tLoss 0.2746 (0.3176)\tPrec 90.625% (89.318%)\n",
      "Epoch: [36][200/391]\tTime 0.041 (0.046)\tData 0.002 (0.006)\tLoss 0.3233 (0.3180)\tPrec 86.719% (89.443%)\n",
      "Epoch: [36][300/391]\tTime 0.042 (0.044)\tData 0.002 (0.005)\tLoss 0.3676 (0.3230)\tPrec 89.844% (89.278%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.315 (0.315)\tLoss 0.4233 (0.4233)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.200% \n",
      "best acc: 84.910000\n",
      "Epoch: [37][0/391]\tTime 0.876 (0.876)\tData 0.829 (0.829)\tLoss 0.2374 (0.2374)\tPrec 92.969% (92.969%)\n",
      "Epoch: [37][100/391]\tTime 0.051 (0.053)\tData 0.003 (0.011)\tLoss 0.3346 (0.3145)\tPrec 88.281% (89.465%)\n",
      "Epoch: [37][200/391]\tTime 0.035 (0.051)\tData 0.002 (0.007)\tLoss 0.4485 (0.3181)\tPrec 86.719% (89.272%)\n",
      "Epoch: [37][300/391]\tTime 0.043 (0.048)\tData 0.002 (0.005)\tLoss 0.2604 (0.3201)\tPrec 91.406% (89.159%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.332 (0.332)\tLoss 0.3835 (0.3835)\tPrec 87.500% (87.500%)\n",
      " * Prec 83.960% \n",
      "best acc: 84.910000\n",
      "Epoch: [38][0/391]\tTime 1.101 (1.101)\tData 1.049 (1.049)\tLoss 0.2612 (0.2612)\tPrec 89.844% (89.844%)\n",
      "Epoch: [38][100/391]\tTime 0.044 (0.054)\tData 0.003 (0.013)\tLoss 0.2926 (0.3049)\tPrec 89.062% (89.573%)\n",
      "Epoch: [38][200/391]\tTime 0.042 (0.049)\tData 0.003 (0.008)\tLoss 0.4732 (0.3048)\tPrec 83.594% (89.684%)\n",
      "Epoch: [38][300/391]\tTime 0.040 (0.046)\tData 0.002 (0.006)\tLoss 0.2654 (0.3027)\tPrec 88.281% (89.753%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.354 (0.354)\tLoss 0.3879 (0.3879)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.700% \n",
      "best acc: 86.700000\n",
      "Epoch: [39][0/391]\tTime 0.693 (0.693)\tData 0.652 (0.652)\tLoss 0.2716 (0.2716)\tPrec 87.500% (87.500%)\n",
      "Epoch: [39][100/391]\tTime 0.045 (0.049)\tData 0.004 (0.009)\tLoss 0.2514 (0.2734)\tPrec 93.750% (90.687%)\n",
      "Epoch: [39][200/391]\tTime 0.045 (0.046)\tData 0.003 (0.006)\tLoss 0.4268 (0.2856)\tPrec 85.938% (90.229%)\n",
      "Epoch: [39][300/391]\tTime 0.043 (0.045)\tData 0.002 (0.005)\tLoss 0.3484 (0.2909)\tPrec 89.062% (90.171%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.329 (0.329)\tLoss 0.4307 (0.4307)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.970% \n",
      "best acc: 86.700000\n",
      "Epoch: [40][0/391]\tTime 0.914 (0.914)\tData 0.858 (0.858)\tLoss 0.1956 (0.1956)\tPrec 90.625% (90.625%)\n",
      "Epoch: [40][100/391]\tTime 0.049 (0.058)\tData 0.003 (0.011)\tLoss 0.3296 (0.2756)\tPrec 89.844% (90.416%)\n",
      "Epoch: [40][200/391]\tTime 0.045 (0.054)\tData 0.003 (0.007)\tLoss 0.3240 (0.2797)\tPrec 87.500% (90.419%)\n",
      "Epoch: [40][300/391]\tTime 0.049 (0.052)\tData 0.003 (0.006)\tLoss 0.1823 (0.2881)\tPrec 94.531% (90.293%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.322 (0.322)\tLoss 0.2890 (0.2890)\tPrec 88.281% (88.281%)\n",
      " * Prec 84.670% \n",
      "best acc: 86.700000\n",
      "Epoch: [41][0/391]\tTime 1.032 (1.032)\tData 0.973 (0.973)\tLoss 0.2304 (0.2304)\tPrec 91.406% (91.406%)\n",
      "Epoch: [41][100/391]\tTime 0.043 (0.056)\tData 0.003 (0.012)\tLoss 0.3819 (0.2775)\tPrec 86.719% (90.494%)\n",
      "Epoch: [41][200/391]\tTime 0.040 (0.050)\tData 0.002 (0.007)\tLoss 0.2487 (0.2808)\tPrec 93.750% (90.477%)\n",
      "Epoch: [41][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.006)\tLoss 0.2606 (0.2822)\tPrec 92.188% (90.480%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.469 (0.469)\tLoss 0.2804 (0.2804)\tPrec 89.844% (89.844%)\n",
      " * Prec 84.790% \n",
      "best acc: 86.700000\n",
      "Epoch: [42][0/391]\tTime 0.756 (0.756)\tData 0.714 (0.714)\tLoss 0.3428 (0.3428)\tPrec 89.062% (89.062%)\n",
      "Epoch: [42][100/391]\tTime 0.048 (0.050)\tData 0.003 (0.010)\tLoss 0.2056 (0.2573)\tPrec 92.188% (91.329%)\n",
      "Epoch: [42][200/391]\tTime 0.040 (0.046)\tData 0.002 (0.006)\tLoss 0.2527 (0.2640)\tPrec 90.625% (91.064%)\n",
      "Epoch: [42][300/391]\tTime 0.048 (0.045)\tData 0.003 (0.005)\tLoss 0.2827 (0.2665)\tPrec 88.281% (91.025%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.314 (0.314)\tLoss 0.3466 (0.3466)\tPrec 86.719% (86.719%)\n",
      " * Prec 85.480% \n",
      "best acc: 86.700000\n",
      "Epoch: [43][0/391]\tTime 0.834 (0.834)\tData 0.778 (0.778)\tLoss 0.1866 (0.1866)\tPrec 95.312% (95.312%)\n",
      "Epoch: [43][100/391]\tTime 0.036 (0.045)\tData 0.002 (0.010)\tLoss 0.2198 (0.2529)\tPrec 93.750% (91.391%)\n",
      "Epoch: [43][200/391]\tTime 0.041 (0.043)\tData 0.002 (0.006)\tLoss 0.2653 (0.2631)\tPrec 92.969% (91.157%)\n",
      "Epoch: [43][300/391]\tTime 0.037 (0.043)\tData 0.002 (0.005)\tLoss 0.2367 (0.2653)\tPrec 92.969% (91.082%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.449 (0.449)\tLoss 0.2454 (0.2454)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.310% \n",
      "best acc: 86.700000\n",
      "Epoch: [44][0/391]\tTime 0.649 (0.649)\tData 0.597 (0.597)\tLoss 0.2247 (0.2247)\tPrec 92.188% (92.188%)\n",
      "Epoch: [44][100/391]\tTime 0.036 (0.048)\tData 0.002 (0.008)\tLoss 0.2089 (0.2476)\tPrec 92.188% (91.638%)\n",
      "Epoch: [44][200/391]\tTime 0.044 (0.045)\tData 0.003 (0.005)\tLoss 0.2077 (0.2460)\tPrec 92.188% (91.721%)\n",
      "Epoch: [44][300/391]\tTime 0.040 (0.044)\tData 0.002 (0.004)\tLoss 0.2769 (0.2558)\tPrec 90.625% (91.313%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.365 (0.365)\tLoss 0.2719 (0.2719)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.470% \n",
      "best acc: 86.700000\n",
      "Epoch: [45][0/391]\tTime 0.923 (0.923)\tData 0.866 (0.866)\tLoss 0.1778 (0.1778)\tPrec 95.312% (95.312%)\n",
      "Epoch: [45][100/391]\tTime 0.047 (0.052)\tData 0.003 (0.011)\tLoss 0.3018 (0.2511)\tPrec 90.625% (91.491%)\n",
      "Epoch: [45][200/391]\tTime 0.041 (0.048)\tData 0.002 (0.007)\tLoss 0.1848 (0.2481)\tPrec 94.531% (91.616%)\n",
      "Epoch: [45][300/391]\tTime 0.042 (0.046)\tData 0.002 (0.005)\tLoss 0.2546 (0.2508)\tPrec 91.406% (91.494%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.565 (0.565)\tLoss 0.2281 (0.2281)\tPrec 92.188% (92.188%)\n",
      " * Prec 86.370% \n",
      "best acc: 86.700000\n",
      "Epoch: [46][0/391]\tTime 0.818 (0.818)\tData 0.765 (0.765)\tLoss 0.3697 (0.3697)\tPrec 86.719% (86.719%)\n",
      "Epoch: [46][100/391]\tTime 0.041 (0.051)\tData 0.002 (0.010)\tLoss 0.2047 (0.2358)\tPrec 90.625% (92.157%)\n",
      "Epoch: [46][200/391]\tTime 0.040 (0.048)\tData 0.002 (0.006)\tLoss 0.2654 (0.2417)\tPrec 90.625% (91.830%)\n",
      "Epoch: [46][300/391]\tTime 0.044 (0.046)\tData 0.002 (0.005)\tLoss 0.3336 (0.2461)\tPrec 85.938% (91.640%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.332 (0.332)\tLoss 0.2588 (0.2588)\tPrec 89.062% (89.062%)\n",
      " * Prec 84.700% \n",
      "best acc: 86.700000\n",
      "Epoch: [47][0/391]\tTime 1.035 (1.035)\tData 0.984 (0.984)\tLoss 0.1984 (0.1984)\tPrec 92.188% (92.188%)\n",
      "Epoch: [47][100/391]\tTime 0.047 (0.052)\tData 0.003 (0.012)\tLoss 0.3023 (0.2321)\tPrec 92.969% (92.342%)\n",
      "Epoch: [47][200/391]\tTime 0.040 (0.047)\tData 0.002 (0.007)\tLoss 0.3284 (0.2437)\tPrec 87.500% (91.826%)\n",
      "Epoch: [47][300/391]\tTime 0.040 (0.046)\tData 0.002 (0.006)\tLoss 0.1886 (0.2443)\tPrec 92.188% (91.728%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.838 (0.838)\tLoss 0.3024 (0.3024)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.030% \n",
      "best acc: 86.700000\n",
      "Epoch: [48][0/391]\tTime 0.837 (0.837)\tData 0.786 (0.786)\tLoss 0.1828 (0.1828)\tPrec 94.531% (94.531%)\n",
      "Epoch: [48][100/391]\tTime 0.041 (0.051)\tData 0.003 (0.010)\tLoss 0.2215 (0.2295)\tPrec 94.531% (92.226%)\n",
      "Epoch: [48][200/391]\tTime 0.050 (0.048)\tData 0.002 (0.006)\tLoss 0.1227 (0.2372)\tPrec 96.875% (91.974%)\n",
      "Epoch: [48][300/391]\tTime 0.047 (0.047)\tData 0.003 (0.005)\tLoss 0.1622 (0.2396)\tPrec 94.531% (91.951%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.417 (0.417)\tLoss 0.2885 (0.2885)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.360% \n",
      "best acc: 86.700000\n",
      "Epoch: [49][0/391]\tTime 0.728 (0.728)\tData 0.673 (0.673)\tLoss 0.1968 (0.1968)\tPrec 93.750% (93.750%)\n",
      "Epoch: [49][100/391]\tTime 0.045 (0.050)\tData 0.003 (0.009)\tLoss 0.2393 (0.2134)\tPrec 92.969% (92.783%)\n",
      "Epoch: [49][200/391]\tTime 0.049 (0.047)\tData 0.003 (0.006)\tLoss 0.2435 (0.2221)\tPrec 92.188% (92.456%)\n",
      "Epoch: [49][300/391]\tTime 0.042 (0.045)\tData 0.002 (0.005)\tLoss 0.1681 (0.2287)\tPrec 93.750% (92.146%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.502 (0.502)\tLoss 0.3418 (0.3418)\tPrec 85.938% (85.938%)\n",
      " * Prec 85.080% \n",
      "best acc: 86.700000\n",
      "Epoch: [50][0/391]\tTime 0.728 (0.728)\tData 0.674 (0.674)\tLoss 0.2729 (0.2729)\tPrec 89.844% (89.844%)\n",
      "Epoch: [50][100/391]\tTime 0.041 (0.051)\tData 0.002 (0.010)\tLoss 0.1958 (0.2179)\tPrec 93.750% (92.775%)\n",
      "Epoch: [50][200/391]\tTime 0.041 (0.046)\tData 0.002 (0.006)\tLoss 0.2806 (0.2210)\tPrec 89.844% (92.611%)\n",
      "Epoch: [50][300/391]\tTime 0.044 (0.045)\tData 0.003 (0.005)\tLoss 0.2803 (0.2229)\tPrec 92.969% (92.507%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.337 (0.337)\tLoss 0.2644 (0.2644)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.540% \n",
      "best acc: 86.700000\n",
      "Epoch: [51][0/391]\tTime 0.782 (0.782)\tData 0.728 (0.728)\tLoss 0.1447 (0.1447)\tPrec 96.094% (96.094%)\n",
      "Epoch: [51][100/391]\tTime 0.043 (0.054)\tData 0.002 (0.010)\tLoss 0.1992 (0.2118)\tPrec 91.406% (92.946%)\n",
      "Epoch: [51][200/391]\tTime 0.048 (0.048)\tData 0.002 (0.006)\tLoss 0.2391 (0.2188)\tPrec 92.188% (92.615%)\n",
      "Epoch: [51][300/391]\tTime 0.045 (0.046)\tData 0.003 (0.005)\tLoss 0.2754 (0.2231)\tPrec 90.625% (92.499%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.282 (0.282)\tLoss 0.3410 (0.3410)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.060% \n",
      "best acc: 86.700000\n",
      "Epoch: [52][0/391]\tTime 0.751 (0.751)\tData 0.685 (0.685)\tLoss 0.2400 (0.2400)\tPrec 92.969% (92.969%)\n",
      "Epoch: [52][100/391]\tTime 0.042 (0.054)\tData 0.003 (0.010)\tLoss 0.1616 (0.2027)\tPrec 96.875% (93.185%)\n",
      "Epoch: [52][200/391]\tTime 0.045 (0.052)\tData 0.003 (0.007)\tLoss 0.0939 (0.2081)\tPrec 95.312% (93.050%)\n",
      "Epoch: [52][300/391]\tTime 0.044 (0.050)\tData 0.002 (0.005)\tLoss 0.2456 (0.2091)\tPrec 92.188% (93.005%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.268 (0.268)\tLoss 0.3678 (0.3678)\tPrec 92.188% (92.188%)\n",
      " * Prec 84.860% \n",
      "best acc: 86.700000\n",
      "Epoch: [53][0/391]\tTime 0.811 (0.811)\tData 0.753 (0.753)\tLoss 0.2243 (0.2243)\tPrec 90.625% (90.625%)\n",
      "Epoch: [53][100/391]\tTime 0.040 (0.050)\tData 0.002 (0.010)\tLoss 0.2308 (0.1980)\tPrec 92.969% (93.394%)\n",
      "Epoch: [53][200/391]\tTime 0.037 (0.046)\tData 0.002 (0.006)\tLoss 0.1991 (0.2008)\tPrec 92.969% (93.295%)\n",
      "Epoch: [53][300/391]\tTime 0.045 (0.045)\tData 0.003 (0.005)\tLoss 0.2873 (0.2094)\tPrec 89.062% (92.969%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.348 (0.348)\tLoss 0.4077 (0.4077)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.680% \n",
      "best acc: 86.700000\n",
      "Epoch: [54][0/391]\tTime 0.918 (0.918)\tData 0.860 (0.860)\tLoss 0.1735 (0.1735)\tPrec 92.969% (92.969%)\n",
      "Epoch: [54][100/391]\tTime 0.041 (0.050)\tData 0.002 (0.011)\tLoss 0.2253 (0.1990)\tPrec 93.750% (93.185%)\n",
      "Epoch: [54][200/391]\tTime 0.033 (0.046)\tData 0.001 (0.007)\tLoss 0.2421 (0.2060)\tPrec 91.406% (92.965%)\n",
      "Epoch: [54][300/391]\tTime 0.043 (0.045)\tData 0.003 (0.006)\tLoss 0.1696 (0.2079)\tPrec 92.969% (92.909%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.671 (0.671)\tLoss 0.4079 (0.4079)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.230% \n",
      "best acc: 86.700000\n",
      "Epoch: [55][0/391]\tTime 0.852 (0.852)\tData 0.776 (0.776)\tLoss 0.1531 (0.1531)\tPrec 94.531% (94.531%)\n",
      "Epoch: [55][100/391]\tTime 0.039 (0.043)\tData 0.002 (0.010)\tLoss 0.2035 (0.1955)\tPrec 94.531% (93.495%)\n",
      "Epoch: [55][200/391]\tTime 0.043 (0.042)\tData 0.002 (0.006)\tLoss 0.1579 (0.1970)\tPrec 95.312% (93.474%)\n",
      "Epoch: [55][300/391]\tTime 0.049 (0.042)\tData 0.003 (0.005)\tLoss 0.2177 (0.2019)\tPrec 92.969% (93.218%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.342 (0.342)\tLoss 0.3271 (0.3271)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.450% \n",
      "best acc: 86.700000\n",
      "Epoch: [56][0/391]\tTime 0.750 (0.750)\tData 0.694 (0.694)\tLoss 0.2173 (0.2173)\tPrec 91.406% (91.406%)\n",
      "Epoch: [56][100/391]\tTime 0.040 (0.051)\tData 0.002 (0.010)\tLoss 0.1198 (0.1859)\tPrec 96.875% (94.005%)\n",
      "Epoch: [56][200/391]\tTime 0.045 (0.047)\tData 0.003 (0.006)\tLoss 0.1584 (0.1910)\tPrec 93.750% (93.560%)\n",
      "Epoch: [56][300/391]\tTime 0.043 (0.046)\tData 0.002 (0.005)\tLoss 0.1704 (0.1969)\tPrec 94.531% (93.387%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.548 (0.548)\tLoss 0.3847 (0.3847)\tPrec 85.156% (85.156%)\n",
      " * Prec 86.820% \n",
      "best acc: 86.820000\n",
      "Epoch: [57][0/391]\tTime 1.120 (1.120)\tData 1.061 (1.061)\tLoss 0.1445 (0.1445)\tPrec 96.094% (96.094%)\n",
      "Epoch: [57][100/391]\tTime 0.038 (0.054)\tData 0.003 (0.013)\tLoss 0.1559 (0.1914)\tPrec 94.531% (93.649%)\n",
      "Epoch: [57][200/391]\tTime 0.041 (0.049)\tData 0.002 (0.008)\tLoss 0.1989 (0.1990)\tPrec 93.750% (93.455%)\n",
      "Epoch: [57][300/391]\tTime 0.044 (0.047)\tData 0.003 (0.006)\tLoss 0.1627 (0.1965)\tPrec 93.750% (93.480%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.441 (0.441)\tLoss 0.3905 (0.3905)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.420% \n",
      "best acc: 86.820000\n",
      "Epoch: [58][0/391]\tTime 0.821 (0.821)\tData 0.765 (0.765)\tLoss 0.1248 (0.1248)\tPrec 95.312% (95.312%)\n",
      "Epoch: [58][100/391]\tTime 0.048 (0.048)\tData 0.003 (0.010)\tLoss 0.2070 (0.1867)\tPrec 92.188% (93.827%)\n",
      "Epoch: [58][200/391]\tTime 0.038 (0.046)\tData 0.002 (0.006)\tLoss 0.2039 (0.1931)\tPrec 92.969% (93.587%)\n",
      "Epoch: [58][300/391]\tTime 0.046 (0.045)\tData 0.003 (0.005)\tLoss 0.3329 (0.1959)\tPrec 87.500% (93.454%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.240 (0.240)\tLoss 0.3326 (0.3326)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.930% \n",
      "best acc: 86.930000\n",
      "Epoch: [59][0/391]\tTime 0.733 (0.733)\tData 0.680 (0.680)\tLoss 0.1898 (0.1898)\tPrec 95.312% (95.312%)\n",
      "Epoch: [59][100/391]\tTime 0.037 (0.049)\tData 0.002 (0.009)\tLoss 0.1035 (0.1837)\tPrec 98.438% (93.642%)\n",
      "Epoch: [59][200/391]\tTime 0.039 (0.045)\tData 0.002 (0.006)\tLoss 0.1013 (0.1900)\tPrec 96.875% (93.517%)\n",
      "Epoch: [59][300/391]\tTime 0.031 (0.044)\tData 0.002 (0.004)\tLoss 0.1927 (0.1911)\tPrec 89.844% (93.579%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.378 (0.378)\tLoss 0.2378 (0.2378)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.890% \n",
      "best acc: 86.930000\n",
      "Epoch: [60][0/391]\tTime 0.638 (0.638)\tData 0.573 (0.573)\tLoss 0.0797 (0.0797)\tPrec 96.094% (96.094%)\n",
      "Epoch: [60][100/391]\tTime 0.038 (0.050)\tData 0.002 (0.008)\tLoss 0.1716 (0.1792)\tPrec 92.188% (94.013%)\n",
      "Epoch: [60][200/391]\tTime 0.036 (0.046)\tData 0.002 (0.005)\tLoss 0.1860 (0.1770)\tPrec 92.969% (94.139%)\n",
      "Epoch: [60][300/391]\tTime 0.038 (0.044)\tData 0.002 (0.004)\tLoss 0.1538 (0.1804)\tPrec 94.531% (94.087%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.636 (0.636)\tLoss 0.2199 (0.2199)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.240% \n",
      "best acc: 87.240000\n",
      "Epoch: [61][0/391]\tTime 0.686 (0.686)\tData 0.630 (0.630)\tLoss 0.1259 (0.1259)\tPrec 96.094% (96.094%)\n",
      "Epoch: [61][100/391]\tTime 0.038 (0.049)\tData 0.002 (0.009)\tLoss 0.0910 (0.1707)\tPrec 96.875% (94.168%)\n",
      "Epoch: [61][200/391]\tTime 0.041 (0.045)\tData 0.002 (0.005)\tLoss 0.1007 (0.1726)\tPrec 96.875% (94.205%)\n",
      "Epoch: [61][300/391]\tTime 0.038 (0.043)\tData 0.002 (0.004)\tLoss 0.2544 (0.1783)\tPrec 89.062% (93.958%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.704 (0.704)\tLoss 0.2960 (0.2960)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.550% \n",
      "best acc: 87.240000\n",
      "Epoch: [62][0/391]\tTime 0.774 (0.774)\tData 0.719 (0.719)\tLoss 0.1503 (0.1503)\tPrec 92.188% (92.188%)\n",
      "Epoch: [62][100/391]\tTime 0.045 (0.049)\tData 0.003 (0.010)\tLoss 0.2358 (0.1763)\tPrec 90.625% (94.083%)\n",
      "Epoch: [62][200/391]\tTime 0.037 (0.046)\tData 0.002 (0.006)\tLoss 0.2554 (0.1819)\tPrec 89.844% (93.948%)\n",
      "Epoch: [62][300/391]\tTime 0.049 (0.045)\tData 0.002 (0.005)\tLoss 0.2539 (0.1823)\tPrec 91.406% (93.914%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.370 (0.370)\tLoss 0.2226 (0.2226)\tPrec 93.750% (93.750%)\n",
      " * Prec 87.790% \n",
      "best acc: 87.790000\n",
      "Epoch: [63][0/391]\tTime 0.665 (0.665)\tData 0.610 (0.610)\tLoss 0.1289 (0.1289)\tPrec 96.094% (96.094%)\n",
      "Epoch: [63][100/391]\tTime 0.038 (0.048)\tData 0.002 (0.009)\tLoss 0.1842 (0.1751)\tPrec 94.531% (94.021%)\n",
      "Epoch: [63][200/391]\tTime 0.043 (0.045)\tData 0.002 (0.006)\tLoss 0.2024 (0.1750)\tPrec 92.969% (94.014%)\n",
      "Epoch: [63][300/391]\tTime 0.044 (0.044)\tData 0.002 (0.005)\tLoss 0.2198 (0.1747)\tPrec 93.750% (94.056%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.393 (0.393)\tLoss 0.3799 (0.3799)\tPrec 85.938% (85.938%)\n",
      " * Prec 86.400% \n",
      "best acc: 87.790000\n",
      "Epoch: [64][0/391]\tTime 1.066 (1.066)\tData 1.012 (1.012)\tLoss 0.1926 (0.1926)\tPrec 95.312% (95.312%)\n",
      "Epoch: [64][100/391]\tTime 0.039 (0.052)\tData 0.002 (0.013)\tLoss 0.1849 (0.1591)\tPrec 92.969% (94.539%)\n",
      "Epoch: [64][200/391]\tTime 0.041 (0.046)\tData 0.002 (0.007)\tLoss 0.1895 (0.1675)\tPrec 92.969% (94.360%)\n",
      "Epoch: [64][300/391]\tTime 0.038 (0.044)\tData 0.002 (0.006)\tLoss 0.3389 (0.1699)\tPrec 91.406% (94.352%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.302 (0.302)\tLoss 0.3085 (0.3085)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.940% \n",
      "best acc: 87.940000\n",
      "Epoch: [65][0/391]\tTime 0.664 (0.664)\tData 0.609 (0.609)\tLoss 0.1961 (0.1961)\tPrec 92.188% (92.188%)\n",
      "Epoch: [65][100/391]\tTime 0.037 (0.048)\tData 0.002 (0.009)\tLoss 0.2410 (0.1739)\tPrec 92.188% (94.415%)\n",
      "Epoch: [65][200/391]\tTime 0.038 (0.045)\tData 0.002 (0.006)\tLoss 0.1449 (0.1708)\tPrec 94.531% (94.438%)\n",
      "Epoch: [65][300/391]\tTime 0.043 (0.043)\tData 0.003 (0.004)\tLoss 0.1208 (0.1702)\tPrec 96.875% (94.433%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.860 (0.860)\tLoss 0.4031 (0.4031)\tPrec 87.500% (87.500%)\n",
      " * Prec 84.830% \n",
      "best acc: 87.940000\n",
      "Epoch: [66][0/391]\tTime 1.105 (1.105)\tData 1.056 (1.056)\tLoss 0.1521 (0.1521)\tPrec 94.531% (94.531%)\n",
      "Epoch: [66][100/391]\tTime 0.041 (0.054)\tData 0.002 (0.013)\tLoss 0.1897 (0.1539)\tPrec 94.531% (94.725%)\n",
      "Epoch: [66][200/391]\tTime 0.042 (0.048)\tData 0.002 (0.008)\tLoss 0.2297 (0.1634)\tPrec 89.844% (94.496%)\n",
      "Epoch: [66][300/391]\tTime 0.046 (0.046)\tData 0.003 (0.006)\tLoss 0.1727 (0.1665)\tPrec 94.531% (94.417%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.010 (1.010)\tLoss 0.3216 (0.3216)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.890% \n",
      "best acc: 87.940000\n",
      "Epoch: [67][0/391]\tTime 0.926 (0.926)\tData 0.884 (0.884)\tLoss 0.1016 (0.1016)\tPrec 97.656% (97.656%)\n",
      "Epoch: [67][100/391]\tTime 0.040 (0.047)\tData 0.002 (0.011)\tLoss 0.2189 (0.1671)\tPrec 92.188% (94.469%)\n",
      "Epoch: [67][200/391]\tTime 0.074 (0.045)\tData 0.028 (0.007)\tLoss 0.2220 (0.1597)\tPrec 91.406% (94.531%)\n",
      "Epoch: [67][300/391]\tTime 0.045 (0.045)\tData 0.002 (0.006)\tLoss 0.1808 (0.1648)\tPrec 92.188% (94.414%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.967 (0.967)\tLoss 0.3291 (0.3291)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.610% \n",
      "best acc: 87.940000\n",
      "Epoch: [68][0/391]\tTime 1.071 (1.071)\tData 1.026 (1.026)\tLoss 0.1525 (0.1525)\tPrec 94.531% (94.531%)\n",
      "Epoch: [68][100/391]\tTime 0.040 (0.047)\tData 0.002 (0.012)\tLoss 0.2113 (0.1582)\tPrec 93.750% (94.725%)\n",
      "Epoch: [68][200/391]\tTime 0.039 (0.044)\tData 0.002 (0.008)\tLoss 0.1819 (0.1643)\tPrec 94.531% (94.547%)\n",
      "Epoch: [68][300/391]\tTime 0.042 (0.043)\tData 0.002 (0.006)\tLoss 0.2182 (0.1660)\tPrec 93.750% (94.469%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.052 (1.052)\tLoss 0.3331 (0.3331)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.010% \n",
      "best acc: 87.940000\n",
      "Epoch: [69][0/391]\tTime 1.025 (1.025)\tData 0.973 (0.973)\tLoss 0.2027 (0.2027)\tPrec 92.969% (92.969%)\n",
      "Epoch: [69][100/391]\tTime 0.043 (0.050)\tData 0.002 (0.012)\tLoss 0.1491 (0.1720)\tPrec 94.531% (94.106%)\n",
      "Epoch: [69][200/391]\tTime 0.041 (0.046)\tData 0.002 (0.007)\tLoss 0.1516 (0.1683)\tPrec 95.312% (94.286%)\n",
      "Epoch: [69][300/391]\tTime 0.041 (0.044)\tData 0.002 (0.006)\tLoss 0.1375 (0.1671)\tPrec 95.312% (94.373%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.682 (0.682)\tLoss 0.3019 (0.3019)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.600% \n",
      "best acc: 87.940000\n",
      "Epoch: [70][0/391]\tTime 1.020 (1.020)\tData 0.966 (0.966)\tLoss 0.0881 (0.0881)\tPrec 96.094% (96.094%)\n",
      "Epoch: [70][100/391]\tTime 0.038 (0.050)\tData 0.002 (0.012)\tLoss 0.1211 (0.1565)\tPrec 94.531% (94.848%)\n",
      "Epoch: [70][200/391]\tTime 0.039 (0.045)\tData 0.002 (0.007)\tLoss 0.1514 (0.1527)\tPrec 96.094% (94.959%)\n",
      "Epoch: [70][300/391]\tTime 0.040 (0.044)\tData 0.002 (0.005)\tLoss 0.1897 (0.1578)\tPrec 92.188% (94.752%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.028 (1.028)\tLoss 0.4881 (0.4881)\tPrec 86.719% (86.719%)\n",
      " * Prec 86.550% \n",
      "best acc: 87.940000\n",
      "Epoch: [71][0/391]\tTime 1.004 (1.004)\tData 0.952 (0.952)\tLoss 0.2498 (0.2498)\tPrec 91.406% (91.406%)\n",
      "Epoch: [71][100/391]\tTime 0.041 (0.051)\tData 0.002 (0.012)\tLoss 0.0747 (0.1444)\tPrec 96.875% (95.258%)\n",
      "Epoch: [71][200/391]\tTime 0.031 (0.046)\tData 0.003 (0.007)\tLoss 0.1978 (0.1496)\tPrec 90.625% (94.947%)\n",
      "Epoch: [71][300/391]\tTime 0.045 (0.044)\tData 0.002 (0.006)\tLoss 0.2083 (0.1547)\tPrec 93.750% (94.786%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.827 (0.827)\tLoss 0.3147 (0.3147)\tPrec 92.188% (92.188%)\n",
      " * Prec 86.900% \n",
      "best acc: 87.940000\n",
      "Epoch: [72][0/391]\tTime 1.006 (1.006)\tData 0.955 (0.955)\tLoss 0.1051 (0.1051)\tPrec 96.094% (96.094%)\n",
      "Epoch: [72][100/391]\tTime 0.044 (0.051)\tData 0.003 (0.012)\tLoss 0.2952 (0.1487)\tPrec 89.844% (94.825%)\n",
      "Epoch: [72][200/391]\tTime 0.044 (0.046)\tData 0.003 (0.007)\tLoss 0.1485 (0.1547)\tPrec 96.094% (94.753%)\n",
      "Epoch: [72][300/391]\tTime 0.043 (0.045)\tData 0.002 (0.006)\tLoss 0.0738 (0.1535)\tPrec 97.656% (94.749%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.269 (0.269)\tLoss 0.2770 (0.2770)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.050% \n",
      "best acc: 87.940000\n",
      "Epoch: [73][0/391]\tTime 1.013 (1.013)\tData 0.959 (0.959)\tLoss 0.1747 (0.1747)\tPrec 93.750% (93.750%)\n",
      "Epoch: [73][100/391]\tTime 0.038 (0.051)\tData 0.002 (0.012)\tLoss 0.1992 (0.1539)\tPrec 94.531% (94.864%)\n",
      "Epoch: [73][200/391]\tTime 0.040 (0.047)\tData 0.002 (0.007)\tLoss 0.2125 (0.1556)\tPrec 94.531% (94.803%)\n",
      "Epoch: [73][300/391]\tTime 0.037 (0.045)\tData 0.003 (0.006)\tLoss 0.1984 (0.1549)\tPrec 93.750% (94.783%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.900 (0.900)\tLoss 0.2175 (0.2175)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.150% \n",
      "best acc: 88.150000\n",
      "Epoch: [74][0/391]\tTime 1.006 (1.006)\tData 0.952 (0.952)\tLoss 0.1400 (0.1400)\tPrec 96.875% (96.875%)\n",
      "Epoch: [74][100/391]\tTime 0.041 (0.050)\tData 0.003 (0.012)\tLoss 0.2195 (0.1460)\tPrec 96.875% (94.957%)\n",
      "Epoch: [74][200/391]\tTime 0.033 (0.045)\tData 0.002 (0.007)\tLoss 0.1084 (0.1477)\tPrec 96.875% (94.796%)\n",
      "Epoch: [74][300/391]\tTime 0.037 (0.044)\tData 0.002 (0.005)\tLoss 0.0872 (0.1513)\tPrec 98.438% (94.734%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.656 (0.656)\tLoss 0.3523 (0.3523)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.870% \n",
      "best acc: 88.150000\n",
      "Epoch: [75][0/391]\tTime 0.781 (0.781)\tData 0.725 (0.725)\tLoss 0.1775 (0.1775)\tPrec 92.969% (92.969%)\n",
      "Epoch: [75][100/391]\tTime 0.040 (0.053)\tData 0.002 (0.010)\tLoss 0.1453 (0.1404)\tPrec 94.531% (95.328%)\n",
      "Epoch: [75][200/391]\tTime 0.038 (0.047)\tData 0.002 (0.006)\tLoss 0.1379 (0.1423)\tPrec 96.875% (95.235%)\n",
      "Epoch: [75][300/391]\tTime 0.045 (0.045)\tData 0.003 (0.005)\tLoss 0.1253 (0.1450)\tPrec 96.094% (95.139%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.338 (0.338)\tLoss 0.4160 (0.4160)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.070% \n",
      "best acc: 88.150000\n",
      "Epoch: [76][0/391]\tTime 0.798 (0.798)\tData 0.741 (0.741)\tLoss 0.1150 (0.1150)\tPrec 95.312% (95.312%)\n",
      "Epoch: [76][100/391]\tTime 0.032 (0.048)\tData 0.002 (0.010)\tLoss 0.1456 (0.1470)\tPrec 94.531% (95.096%)\n",
      "Epoch: [76][200/391]\tTime 0.046 (0.045)\tData 0.003 (0.006)\tLoss 0.2484 (0.1524)\tPrec 92.188% (94.854%)\n",
      "Epoch: [76][300/391]\tTime 0.036 (0.045)\tData 0.002 (0.005)\tLoss 0.1271 (0.1526)\tPrec 96.875% (94.858%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.323 (0.323)\tLoss 0.4210 (0.4210)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.230% \n",
      "best acc: 88.150000\n",
      "Epoch: [77][0/391]\tTime 0.754 (0.754)\tData 0.688 (0.688)\tLoss 0.0870 (0.0870)\tPrec 98.438% (98.438%)\n",
      "Epoch: [77][100/391]\tTime 0.042 (0.049)\tData 0.002 (0.009)\tLoss 0.1357 (0.1306)\tPrec 95.312% (95.622%)\n",
      "Epoch: [77][200/391]\tTime 0.042 (0.045)\tData 0.002 (0.006)\tLoss 0.1363 (0.1399)\tPrec 95.312% (95.270%)\n",
      "Epoch: [77][300/391]\tTime 0.041 (0.044)\tData 0.002 (0.004)\tLoss 0.2069 (0.1413)\tPrec 92.969% (95.170%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.477 (0.477)\tLoss 0.4036 (0.4036)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.250% \n",
      "best acc: 88.150000\n",
      "Epoch: [78][0/391]\tTime 0.848 (0.848)\tData 0.793 (0.793)\tLoss 0.1873 (0.1873)\tPrec 92.969% (92.969%)\n",
      "Epoch: [78][100/391]\tTime 0.039 (0.049)\tData 0.002 (0.010)\tLoss 0.0571 (0.1367)\tPrec 97.656% (95.351%)\n",
      "Epoch: [78][200/391]\tTime 0.041 (0.045)\tData 0.002 (0.006)\tLoss 0.1950 (0.1418)\tPrec 90.625% (95.285%)\n",
      "Epoch: [78][300/391]\tTime 0.046 (0.044)\tData 0.004 (0.005)\tLoss 0.0994 (0.1454)\tPrec 96.875% (95.123%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.384 (0.384)\tLoss 0.5795 (0.5795)\tPrec 82.812% (82.812%)\n",
      " * Prec 86.070% \n",
      "best acc: 88.150000\n",
      "Epoch: [79][0/391]\tTime 0.819 (0.819)\tData 0.751 (0.751)\tLoss 0.1863 (0.1863)\tPrec 92.969% (92.969%)\n",
      "Epoch: [79][100/391]\tTime 0.040 (0.050)\tData 0.002 (0.010)\tLoss 0.1691 (0.1342)\tPrec 93.750% (95.498%)\n",
      "Epoch: [79][200/391]\tTime 0.051 (0.047)\tData 0.003 (0.006)\tLoss 0.1760 (0.1416)\tPrec 95.312% (95.281%)\n",
      "Epoch: [79][300/391]\tTime 0.047 (0.046)\tData 0.003 (0.005)\tLoss 0.0943 (0.1446)\tPrec 96.875% (95.165%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.879 (0.879)\tLoss 0.3994 (0.3994)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.340% \n",
      "best acc: 88.150000\n",
      "Epoch: [80][0/391]\tTime 0.712 (0.712)\tData 0.659 (0.659)\tLoss 0.0857 (0.0857)\tPrec 96.875% (96.875%)\n",
      "Epoch: [80][100/391]\tTime 0.041 (0.047)\tData 0.002 (0.009)\tLoss 0.1767 (0.1381)\tPrec 95.312% (95.514%)\n",
      "Epoch: [80][200/391]\tTime 0.047 (0.045)\tData 0.002 (0.005)\tLoss 0.1881 (0.1427)\tPrec 95.312% (95.398%)\n",
      "Epoch: [80][300/391]\tTime 0.038 (0.044)\tData 0.002 (0.005)\tLoss 0.1197 (0.1444)\tPrec 96.875% (95.390%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.510 (0.510)\tLoss 0.2877 (0.2877)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.930% \n",
      "best acc: 88.150000\n",
      "Epoch: [81][0/391]\tTime 0.856 (0.856)\tData 0.803 (0.803)\tLoss 0.1341 (0.1341)\tPrec 96.875% (96.875%)\n",
      "Epoch: [81][100/391]\tTime 0.039 (0.049)\tData 0.002 (0.010)\tLoss 0.0776 (0.1289)\tPrec 96.875% (95.568%)\n",
      "Epoch: [81][200/391]\tTime 0.037 (0.047)\tData 0.002 (0.006)\tLoss 0.1289 (0.1341)\tPrec 96.094% (95.499%)\n",
      "Epoch: [81][300/391]\tTime 0.031 (0.045)\tData 0.001 (0.005)\tLoss 0.1186 (0.1311)\tPrec 96.094% (95.569%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.314 (0.314)\tLoss 0.3233 (0.3233)\tPrec 87.500% (87.500%)\n",
      " * Prec 87.110% \n",
      "best acc: 88.150000\n",
      "Epoch: [82][0/391]\tTime 0.694 (0.694)\tData 0.637 (0.637)\tLoss 0.1695 (0.1695)\tPrec 94.531% (94.531%)\n",
      "Epoch: [82][100/391]\tTime 0.041 (0.039)\tData 0.002 (0.008)\tLoss 0.0880 (0.1308)\tPrec 96.875% (95.676%)\n",
      "Epoch: [82][200/391]\tTime 0.042 (0.040)\tData 0.002 (0.005)\tLoss 0.0689 (0.1383)\tPrec 98.438% (95.421%)\n",
      "Epoch: [82][300/391]\tTime 0.039 (0.040)\tData 0.002 (0.004)\tLoss 0.1964 (0.1365)\tPrec 92.969% (95.484%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.594 (0.594)\tLoss 0.3473 (0.3473)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.400% \n",
      "best acc: 88.150000\n",
      "Epoch: [83][0/391]\tTime 0.709 (0.709)\tData 0.652 (0.652)\tLoss 0.1883 (0.1883)\tPrec 95.312% (95.312%)\n",
      "Epoch: [83][100/391]\tTime 0.039 (0.049)\tData 0.002 (0.009)\tLoss 0.1337 (0.1270)\tPrec 95.312% (95.707%)\n",
      "Epoch: [83][200/391]\tTime 0.047 (0.045)\tData 0.006 (0.006)\tLoss 0.2788 (0.1347)\tPrec 92.188% (95.421%)\n",
      "Epoch: [83][300/391]\tTime 0.047 (0.044)\tData 0.002 (0.005)\tLoss 0.1992 (0.1384)\tPrec 92.188% (95.331%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.854 (0.854)\tLoss 0.5360 (0.5360)\tPrec 86.719% (86.719%)\n",
      " * Prec 85.980% \n",
      "best acc: 88.150000\n",
      "Epoch: [84][0/391]\tTime 0.716 (0.716)\tData 0.662 (0.662)\tLoss 0.2716 (0.2716)\tPrec 89.062% (89.062%)\n",
      "Epoch: [84][100/391]\tTime 0.045 (0.048)\tData 0.003 (0.009)\tLoss 0.1021 (0.1241)\tPrec 96.875% (95.877%)\n",
      "Epoch: [84][200/391]\tTime 0.041 (0.044)\tData 0.002 (0.006)\tLoss 0.1089 (0.1270)\tPrec 96.875% (95.857%)\n",
      "Epoch: [84][300/391]\tTime 0.039 (0.043)\tData 0.002 (0.005)\tLoss 0.0522 (0.1297)\tPrec 98.438% (95.697%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.291 (0.291)\tLoss 0.3863 (0.3863)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.650% \n",
      "best acc: 88.150000\n",
      "Epoch: [85][0/391]\tTime 0.667 (0.667)\tData 0.614 (0.614)\tLoss 0.1882 (0.1882)\tPrec 93.750% (93.750%)\n",
      "Epoch: [85][100/391]\tTime 0.046 (0.048)\tData 0.003 (0.008)\tLoss 0.1945 (0.1357)\tPrec 94.531% (95.529%)\n",
      "Epoch: [85][200/391]\tTime 0.050 (0.048)\tData 0.002 (0.006)\tLoss 0.1999 (0.1395)\tPrec 93.750% (95.278%)\n",
      "Epoch: [85][300/391]\tTime 0.047 (0.046)\tData 0.002 (0.004)\tLoss 0.1230 (0.1377)\tPrec 95.312% (95.318%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.328 (0.328)\tLoss 0.4301 (0.4301)\tPrec 87.500% (87.500%)\n",
      " * Prec 86.240% \n",
      "best acc: 88.150000\n",
      "Epoch: [86][0/391]\tTime 0.718 (0.718)\tData 0.658 (0.658)\tLoss 0.1134 (0.1134)\tPrec 96.094% (96.094%)\n",
      "Epoch: [86][100/391]\tTime 0.041 (0.048)\tData 0.002 (0.009)\tLoss 0.1347 (0.1254)\tPrec 94.531% (95.777%)\n",
      "Epoch: [86][200/391]\tTime 0.041 (0.044)\tData 0.002 (0.005)\tLoss 0.1671 (0.1345)\tPrec 94.531% (95.468%)\n",
      "Epoch: [86][300/391]\tTime 0.043 (0.044)\tData 0.002 (0.004)\tLoss 0.1238 (0.1371)\tPrec 93.750% (95.422%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.290 (0.290)\tLoss 0.4429 (0.4429)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.710% \n",
      "best acc: 88.150000\n",
      "Epoch: [87][0/391]\tTime 1.030 (1.030)\tData 0.949 (0.949)\tLoss 0.1572 (0.1572)\tPrec 95.312% (95.312%)\n",
      "Epoch: [87][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.012)\tLoss 0.1008 (0.1202)\tPrec 96.094% (95.939%)\n",
      "Epoch: [87][200/391]\tTime 0.044 (0.053)\tData 0.002 (0.007)\tLoss 0.0670 (0.1202)\tPrec 97.656% (95.899%)\n",
      "Epoch: [87][300/391]\tTime 0.040 (0.050)\tData 0.003 (0.006)\tLoss 0.1347 (0.1246)\tPrec 96.094% (95.764%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.316 (0.316)\tLoss 0.3546 (0.3546)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.620% \n",
      "best acc: 88.150000\n",
      "Epoch: [88][0/391]\tTime 0.789 (0.789)\tData 0.736 (0.736)\tLoss 0.1140 (0.1140)\tPrec 97.656% (97.656%)\n",
      "Epoch: [88][100/391]\tTime 0.050 (0.053)\tData 0.002 (0.009)\tLoss 0.2527 (0.1282)\tPrec 92.969% (95.908%)\n",
      "Epoch: [88][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.006)\tLoss 0.1171 (0.1239)\tPrec 94.531% (95.845%)\n",
      "Epoch: [88][300/391]\tTime 0.040 (0.046)\tData 0.002 (0.005)\tLoss 0.1510 (0.1273)\tPrec 94.531% (95.736%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.400 (0.400)\tLoss 0.4954 (0.4954)\tPrec 86.719% (86.719%)\n",
      " * Prec 87.200% \n",
      "best acc: 88.150000\n",
      "Epoch: [89][0/391]\tTime 0.805 (0.805)\tData 0.746 (0.746)\tLoss 0.0582 (0.0582)\tPrec 99.219% (99.219%)\n",
      "Epoch: [89][100/391]\tTime 0.046 (0.050)\tData 0.003 (0.010)\tLoss 0.0867 (0.1132)\tPrec 96.094% (96.194%)\n",
      "Epoch: [89][200/391]\tTime 0.044 (0.046)\tData 0.003 (0.006)\tLoss 0.0812 (0.1254)\tPrec 96.875% (95.728%)\n",
      "Epoch: [89][300/391]\tTime 0.041 (0.045)\tData 0.002 (0.005)\tLoss 0.0675 (0.1301)\tPrec 97.656% (95.614%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.645 (0.645)\tLoss 0.3307 (0.3307)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.440% \n",
      "best acc: 88.440000\n",
      "Epoch: [90][0/391]\tTime 0.732 (0.732)\tData 0.674 (0.674)\tLoss 0.0416 (0.0416)\tPrec 99.219% (99.219%)\n",
      "Epoch: [90][100/391]\tTime 0.052 (0.049)\tData 0.003 (0.009)\tLoss 0.1888 (0.1230)\tPrec 92.969% (95.815%)\n",
      "Epoch: [90][200/391]\tTime 0.049 (0.049)\tData 0.003 (0.006)\tLoss 0.2470 (0.1258)\tPrec 89.062% (95.728%)\n",
      "Epoch: [90][300/391]\tTime 0.034 (0.048)\tData 0.003 (0.005)\tLoss 0.1530 (0.1269)\tPrec 94.531% (95.741%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.282 (0.282)\tLoss 0.4438 (0.4438)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.540% \n",
      "best acc: 88.440000\n",
      "Epoch: [91][0/391]\tTime 1.080 (1.080)\tData 1.021 (1.021)\tLoss 0.1326 (0.1326)\tPrec 96.094% (96.094%)\n",
      "Epoch: [91][100/391]\tTime 0.043 (0.054)\tData 0.002 (0.013)\tLoss 0.0973 (0.1148)\tPrec 97.656% (96.241%)\n",
      "Epoch: [91][200/391]\tTime 0.043 (0.049)\tData 0.003 (0.008)\tLoss 0.0682 (0.1181)\tPrec 97.656% (96.039%)\n",
      "Epoch: [91][300/391]\tTime 0.031 (0.044)\tData 0.001 (0.006)\tLoss 0.1157 (0.1198)\tPrec 96.875% (95.909%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.709 (0.709)\tLoss 0.2505 (0.2505)\tPrec 89.062% (89.062%)\n",
      " * Prec 88.260% \n",
      "best acc: 88.440000\n",
      "Epoch: [92][0/391]\tTime 0.885 (0.885)\tData 0.809 (0.809)\tLoss 0.0504 (0.0504)\tPrec 98.438% (98.438%)\n",
      "Epoch: [92][100/391]\tTime 0.047 (0.050)\tData 0.002 (0.010)\tLoss 0.1967 (0.1072)\tPrec 90.625% (96.357%)\n",
      "Epoch: [92][200/391]\tTime 0.038 (0.046)\tData 0.003 (0.006)\tLoss 0.0780 (0.1213)\tPrec 96.875% (95.861%)\n",
      "Epoch: [92][300/391]\tTime 0.049 (0.044)\tData 0.002 (0.005)\tLoss 0.0536 (0.1273)\tPrec 99.219% (95.668%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.297 (0.297)\tLoss 0.4184 (0.4184)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.430% \n",
      "best acc: 88.440000\n",
      "Epoch: [93][0/391]\tTime 0.907 (0.907)\tData 0.853 (0.853)\tLoss 0.1539 (0.1539)\tPrec 95.312% (95.312%)\n",
      "Epoch: [93][100/391]\tTime 0.043 (0.051)\tData 0.003 (0.011)\tLoss 0.2165 (0.1224)\tPrec 93.750% (95.808%)\n",
      "Epoch: [93][200/391]\tTime 0.038 (0.047)\tData 0.002 (0.007)\tLoss 0.2001 (0.1283)\tPrec 92.188% (95.592%)\n",
      "Epoch: [93][300/391]\tTime 0.040 (0.046)\tData 0.002 (0.005)\tLoss 0.1279 (0.1279)\tPrec 93.750% (95.593%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.677 (0.677)\tLoss 0.2665 (0.2665)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.760% \n",
      "best acc: 88.440000\n",
      "Epoch: [94][0/391]\tTime 0.819 (0.819)\tData 0.752 (0.752)\tLoss 0.0930 (0.0930)\tPrec 98.438% (98.438%)\n",
      "Epoch: [94][100/391]\tTime 0.050 (0.052)\tData 0.003 (0.010)\tLoss 0.1366 (0.1155)\tPrec 96.094% (96.156%)\n",
      "Epoch: [94][200/391]\tTime 0.050 (0.049)\tData 0.003 (0.006)\tLoss 0.2108 (0.1181)\tPrec 93.750% (95.969%)\n",
      "Epoch: [94][300/391]\tTime 0.045 (0.049)\tData 0.002 (0.005)\tLoss 0.1276 (0.1218)\tPrec 94.531% (95.826%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.328 (0.328)\tLoss 0.2869 (0.2869)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.380% \n",
      "best acc: 88.440000\n",
      "Epoch: [95][0/391]\tTime 0.646 (0.646)\tData 0.578 (0.578)\tLoss 0.1304 (0.1304)\tPrec 96.094% (96.094%)\n",
      "Epoch: [95][100/391]\tTime 0.042 (0.051)\tData 0.002 (0.009)\tLoss 0.0786 (0.1225)\tPrec 98.438% (95.893%)\n",
      "Epoch: [95][200/391]\tTime 0.041 (0.046)\tData 0.002 (0.005)\tLoss 0.1678 (0.1216)\tPrec 92.969% (95.864%)\n",
      "Epoch: [95][300/391]\tTime 0.039 (0.045)\tData 0.002 (0.004)\tLoss 0.0723 (0.1209)\tPrec 98.438% (95.884%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.372 (0.372)\tLoss 0.4539 (0.4539)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.890% \n",
      "best acc: 88.440000\n",
      "Epoch: [96][0/391]\tTime 0.763 (0.763)\tData 0.706 (0.706)\tLoss 0.2275 (0.2275)\tPrec 90.625% (90.625%)\n",
      "Epoch: [96][100/391]\tTime 0.043 (0.048)\tData 0.002 (0.009)\tLoss 0.0626 (0.1170)\tPrec 97.656% (96.163%)\n",
      "Epoch: [96][200/391]\tTime 0.048 (0.045)\tData 0.003 (0.006)\tLoss 0.1638 (0.1115)\tPrec 94.531% (96.327%)\n",
      "Epoch: [96][300/391]\tTime 0.044 (0.045)\tData 0.003 (0.005)\tLoss 0.1105 (0.1152)\tPrec 96.875% (96.249%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.271 (0.271)\tLoss 0.2578 (0.2578)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.060% \n",
      "best acc: 88.440000\n",
      "Epoch: [97][0/391]\tTime 0.702 (0.702)\tData 0.630 (0.630)\tLoss 0.1857 (0.1857)\tPrec 93.750% (93.750%)\n",
      "Epoch: [97][100/391]\tTime 0.048 (0.052)\tData 0.003 (0.009)\tLoss 0.0824 (0.1090)\tPrec 97.656% (96.341%)\n",
      "Epoch: [97][200/391]\tTime 0.042 (0.047)\tData 0.002 (0.006)\tLoss 0.0791 (0.1137)\tPrec 98.438% (96.214%)\n",
      "Epoch: [97][300/391]\tTime 0.053 (0.046)\tData 0.003 (0.005)\tLoss 0.1467 (0.1210)\tPrec 96.094% (95.974%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.623 (0.623)\tLoss 0.4835 (0.4835)\tPrec 86.719% (86.719%)\n",
      " * Prec 87.380% \n",
      "best acc: 88.440000\n",
      "Epoch: [98][0/391]\tTime 0.647 (0.647)\tData 0.575 (0.575)\tLoss 0.0862 (0.0862)\tPrec 95.312% (95.312%)\n",
      "Epoch: [98][100/391]\tTime 0.048 (0.050)\tData 0.003 (0.009)\tLoss 0.1043 (0.1114)\tPrec 96.094% (96.187%)\n",
      "Epoch: [98][200/391]\tTime 0.041 (0.047)\tData 0.002 (0.006)\tLoss 0.1160 (0.1180)\tPrec 96.094% (95.993%)\n",
      "Epoch: [98][300/391]\tTime 0.047 (0.046)\tData 0.003 (0.005)\tLoss 0.1342 (0.1230)\tPrec 96.094% (95.782%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.370 (0.370)\tLoss 0.2470 (0.2470)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.810% \n",
      "best acc: 88.440000\n",
      "Epoch: [99][0/391]\tTime 0.932 (0.932)\tData 0.867 (0.867)\tLoss 0.0809 (0.0809)\tPrec 96.875% (96.875%)\n",
      "Epoch: [99][100/391]\tTime 0.037 (0.051)\tData 0.002 (0.011)\tLoss 0.0555 (0.1109)\tPrec 96.875% (96.248%)\n",
      "Epoch: [99][200/391]\tTime 0.048 (0.046)\tData 0.002 (0.007)\tLoss 0.1376 (0.1167)\tPrec 96.094% (96.152%)\n",
      "Epoch: [99][300/391]\tTime 0.039 (0.044)\tData 0.002 (0.005)\tLoss 0.2265 (0.1180)\tPrec 94.531% (96.037%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.300 (0.300)\tLoss 0.4610 (0.4610)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.410% \n",
      "best acc: 88.440000\n",
      "Epoch: [100][0/391]\tTime 0.998 (0.998)\tData 0.944 (0.944)\tLoss 0.0609 (0.0609)\tPrec 98.438% (98.438%)\n",
      "Epoch: [100][100/391]\tTime 0.038 (0.053)\tData 0.002 (0.012)\tLoss 0.1017 (0.1212)\tPrec 96.875% (95.800%)\n",
      "Epoch: [100][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.007)\tLoss 0.0801 (0.1178)\tPrec 97.656% (95.993%)\n",
      "Epoch: [100][300/391]\tTime 0.044 (0.046)\tData 0.003 (0.006)\tLoss 0.0930 (0.1176)\tPrec 95.312% (95.985%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.671 (0.671)\tLoss 0.3970 (0.3970)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.760% \n",
      "best acc: 88.440000\n",
      "Epoch: [101][0/391]\tTime 0.926 (0.926)\tData 0.867 (0.867)\tLoss 0.1744 (0.1744)\tPrec 95.312% (95.312%)\n",
      "Epoch: [101][100/391]\tTime 0.043 (0.056)\tData 0.002 (0.011)\tLoss 0.1957 (0.1159)\tPrec 93.750% (96.024%)\n",
      "Epoch: [101][200/391]\tTime 0.047 (0.049)\tData 0.002 (0.007)\tLoss 0.1392 (0.1182)\tPrec 93.750% (95.915%)\n",
      "Epoch: [101][300/391]\tTime 0.040 (0.047)\tData 0.002 (0.005)\tLoss 0.0987 (0.1172)\tPrec 95.312% (95.961%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.635 (0.635)\tLoss 0.4954 (0.4954)\tPrec 86.719% (86.719%)\n",
      " * Prec 87.150% \n",
      "best acc: 88.440000\n",
      "Epoch: [102][0/391]\tTime 1.086 (1.086)\tData 1.012 (1.012)\tLoss 0.1259 (0.1259)\tPrec 95.312% (95.312%)\n",
      "Epoch: [102][100/391]\tTime 0.045 (0.053)\tData 0.003 (0.012)\tLoss 0.0276 (0.1047)\tPrec 99.219% (96.566%)\n",
      "Epoch: [102][200/391]\tTime 0.040 (0.048)\tData 0.002 (0.007)\tLoss 0.0529 (0.1110)\tPrec 99.219% (96.346%)\n",
      "Epoch: [102][300/391]\tTime 0.043 (0.047)\tData 0.002 (0.006)\tLoss 0.1505 (0.1174)\tPrec 96.094% (96.070%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.493 (0.493)\tLoss 0.3158 (0.3158)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.530% \n",
      "best acc: 88.530000\n",
      "Epoch: [103][0/391]\tTime 0.941 (0.941)\tData 0.879 (0.879)\tLoss 0.1342 (0.1342)\tPrec 94.531% (94.531%)\n",
      "Epoch: [103][100/391]\tTime 0.041 (0.053)\tData 0.002 (0.012)\tLoss 0.1286 (0.1118)\tPrec 96.094% (96.148%)\n",
      "Epoch: [103][200/391]\tTime 0.041 (0.048)\tData 0.002 (0.007)\tLoss 0.0938 (0.1211)\tPrec 95.312% (95.907%)\n",
      "Epoch: [103][300/391]\tTime 0.053 (0.046)\tData 0.009 (0.006)\tLoss 0.0396 (0.1242)\tPrec 98.438% (95.808%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.769 (0.769)\tLoss 0.1968 (0.1968)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.000% \n",
      "best acc: 89.000000\n",
      "Epoch: [104][0/391]\tTime 0.624 (0.624)\tData 0.566 (0.566)\tLoss 0.0386 (0.0386)\tPrec 99.219% (99.219%)\n",
      "Epoch: [104][100/391]\tTime 0.045 (0.049)\tData 0.003 (0.008)\tLoss 0.0758 (0.1046)\tPrec 96.875% (96.341%)\n",
      "Epoch: [104][200/391]\tTime 0.035 (0.045)\tData 0.002 (0.005)\tLoss 0.1577 (0.1163)\tPrec 93.750% (96.012%)\n",
      "Epoch: [104][300/391]\tTime 0.045 (0.044)\tData 0.003 (0.004)\tLoss 0.2213 (0.1150)\tPrec 93.750% (96.096%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.457 (0.457)\tLoss 0.3506 (0.3506)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.210% \n",
      "best acc: 89.000000\n",
      "Epoch: [105][0/391]\tTime 0.934 (0.934)\tData 0.878 (0.878)\tLoss 0.1478 (0.1478)\tPrec 95.312% (95.312%)\n",
      "Epoch: [105][100/391]\tTime 0.049 (0.050)\tData 0.004 (0.011)\tLoss 0.1028 (0.1104)\tPrec 96.875% (96.372%)\n",
      "Epoch: [105][200/391]\tTime 0.044 (0.045)\tData 0.003 (0.007)\tLoss 0.1537 (0.1110)\tPrec 96.094% (96.377%)\n",
      "Epoch: [105][300/391]\tTime 0.053 (0.045)\tData 0.003 (0.005)\tLoss 0.1403 (0.1150)\tPrec 96.094% (96.174%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.330 (0.330)\tLoss 0.4138 (0.4138)\tPrec 85.156% (85.156%)\n",
      " * Prec 86.230% \n",
      "best acc: 89.000000\n",
      "Epoch: [106][0/391]\tTime 0.940 (0.940)\tData 0.885 (0.885)\tLoss 0.2295 (0.2295)\tPrec 93.750% (93.750%)\n",
      "Epoch: [106][100/391]\tTime 0.043 (0.051)\tData 0.002 (0.011)\tLoss 0.1076 (0.1130)\tPrec 95.312% (96.202%)\n",
      "Epoch: [106][200/391]\tTime 0.039 (0.047)\tData 0.002 (0.007)\tLoss 0.0565 (0.1067)\tPrec 97.656% (96.381%)\n",
      "Epoch: [106][300/391]\tTime 0.043 (0.045)\tData 0.002 (0.005)\tLoss 0.0708 (0.1110)\tPrec 97.656% (96.190%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.545 (0.545)\tLoss 0.3128 (0.3128)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.230% \n",
      "best acc: 89.000000\n",
      "Epoch: [107][0/391]\tTime 0.713 (0.713)\tData 0.658 (0.658)\tLoss 0.1383 (0.1383)\tPrec 94.531% (94.531%)\n",
      "Epoch: [107][100/391]\tTime 0.043 (0.050)\tData 0.003 (0.009)\tLoss 0.1222 (0.1038)\tPrec 96.094% (96.434%)\n",
      "Epoch: [107][200/391]\tTime 0.059 (0.047)\tData 0.003 (0.006)\tLoss 0.0819 (0.1097)\tPrec 96.875% (96.245%)\n",
      "Epoch: [107][300/391]\tTime 0.040 (0.045)\tData 0.002 (0.005)\tLoss 0.1346 (0.1116)\tPrec 93.750% (96.221%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.562 (0.562)\tLoss 0.3403 (0.3403)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.230% \n",
      "best acc: 89.000000\n",
      "Epoch: [108][0/391]\tTime 0.955 (0.955)\tData 0.896 (0.896)\tLoss 0.1259 (0.1259)\tPrec 95.312% (95.312%)\n",
      "Epoch: [108][100/391]\tTime 0.036 (0.052)\tData 0.002 (0.011)\tLoss 0.0987 (0.1074)\tPrec 97.656% (96.604%)\n",
      "Epoch: [108][200/391]\tTime 0.047 (0.048)\tData 0.003 (0.007)\tLoss 0.0922 (0.1056)\tPrec 96.875% (96.564%)\n",
      "Epoch: [108][300/391]\tTime 0.031 (0.043)\tData 0.001 (0.005)\tLoss 0.1036 (0.1087)\tPrec 96.875% (96.431%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.315 (0.315)\tLoss 0.5816 (0.5816)\tPrec 85.156% (85.156%)\n",
      " * Prec 85.770% \n",
      "best acc: 89.000000\n",
      "Epoch: [109][0/391]\tTime 0.824 (0.824)\tData 0.770 (0.770)\tLoss 0.1178 (0.1178)\tPrec 96.094% (96.094%)\n",
      "Epoch: [109][100/391]\tTime 0.039 (0.049)\tData 0.002 (0.010)\tLoss 0.0843 (0.1017)\tPrec 98.438% (96.658%)\n",
      "Epoch: [109][200/391]\tTime 0.039 (0.045)\tData 0.003 (0.006)\tLoss 0.2002 (0.0996)\tPrec 94.531% (96.626%)\n",
      "Epoch: [109][300/391]\tTime 0.030 (0.040)\tData 0.001 (0.004)\tLoss 0.0595 (0.1076)\tPrec 97.656% (96.405%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.589 (0.589)\tLoss 0.3291 (0.3291)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.760% \n",
      "best acc: 89.000000\n",
      "Epoch: [110][0/391]\tTime 0.670 (0.670)\tData 0.618 (0.618)\tLoss 0.0648 (0.0648)\tPrec 96.875% (96.875%)\n",
      "Epoch: [110][100/391]\tTime 0.038 (0.047)\tData 0.003 (0.008)\tLoss 0.1806 (0.1028)\tPrec 94.531% (96.697%)\n",
      "Epoch: [110][200/391]\tTime 0.043 (0.044)\tData 0.002 (0.005)\tLoss 0.1214 (0.1111)\tPrec 94.531% (96.385%)\n",
      "Epoch: [110][300/391]\tTime 0.038 (0.043)\tData 0.002 (0.004)\tLoss 0.0912 (0.1088)\tPrec 97.656% (96.431%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.333 (0.333)\tLoss 0.3118 (0.3118)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.190% \n",
      "best acc: 89.000000\n",
      "Epoch: [111][0/391]\tTime 0.950 (0.950)\tData 0.894 (0.894)\tLoss 0.0951 (0.0951)\tPrec 96.875% (96.875%)\n",
      "Epoch: [111][100/391]\tTime 0.035 (0.051)\tData 0.002 (0.011)\tLoss 0.0467 (0.1079)\tPrec 98.438% (96.504%)\n",
      "Epoch: [111][200/391]\tTime 0.038 (0.047)\tData 0.002 (0.007)\tLoss 0.0944 (0.1089)\tPrec 95.312% (96.300%)\n",
      "Epoch: [111][300/391]\tTime 0.047 (0.046)\tData 0.003 (0.005)\tLoss 0.1002 (0.1133)\tPrec 96.094% (96.231%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.512 (0.512)\tLoss 0.2318 (0.2318)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.430% \n",
      "best acc: 89.430000\n",
      "Epoch: [112][0/391]\tTime 1.017 (1.017)\tData 0.964 (0.964)\tLoss 0.0675 (0.0675)\tPrec 96.875% (96.875%)\n",
      "Epoch: [112][100/391]\tTime 0.039 (0.053)\tData 0.002 (0.012)\tLoss 0.0963 (0.0945)\tPrec 97.656% (96.898%)\n",
      "Epoch: [112][200/391]\tTime 0.047 (0.048)\tData 0.003 (0.007)\tLoss 0.0815 (0.1007)\tPrec 97.656% (96.650%)\n",
      "Epoch: [112][300/391]\tTime 0.048 (0.046)\tData 0.003 (0.006)\tLoss 0.1337 (0.1067)\tPrec 94.531% (96.356%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.567 (0.567)\tLoss 0.3378 (0.3378)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.990% \n",
      "best acc: 89.430000\n",
      "Epoch: [113][0/391]\tTime 1.317 (1.317)\tData 1.289 (1.289)\tLoss 0.0785 (0.0785)\tPrec 97.656% (97.656%)\n",
      "Epoch: [113][100/391]\tTime 0.044 (0.055)\tData 0.002 (0.015)\tLoss 0.0861 (0.1038)\tPrec 97.656% (96.666%)\n",
      "Epoch: [113][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.009)\tLoss 0.0857 (0.1077)\tPrec 96.875% (96.479%)\n",
      "Epoch: [113][300/391]\tTime 0.041 (0.046)\tData 0.002 (0.007)\tLoss 0.1405 (0.1078)\tPrec 96.094% (96.457%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.704 (0.704)\tLoss 0.2965 (0.2965)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.960% \n",
      "best acc: 89.430000\n",
      "Epoch: [114][0/391]\tTime 1.013 (1.013)\tData 0.940 (0.940)\tLoss 0.1140 (0.1140)\tPrec 96.875% (96.875%)\n",
      "Epoch: [114][100/391]\tTime 0.041 (0.052)\tData 0.002 (0.012)\tLoss 0.0989 (0.1106)\tPrec 96.875% (96.109%)\n",
      "Epoch: [114][200/391]\tTime 0.038 (0.046)\tData 0.002 (0.007)\tLoss 0.0818 (0.1127)\tPrec 97.656% (96.140%)\n",
      "Epoch: [114][300/391]\tTime 0.037 (0.044)\tData 0.002 (0.005)\tLoss 0.0901 (0.1099)\tPrec 96.094% (96.327%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.681 (0.681)\tLoss 0.3805 (0.3805)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.980% \n",
      "best acc: 89.430000\n",
      "Epoch: [115][0/391]\tTime 0.928 (0.928)\tData 0.875 (0.875)\tLoss 0.1171 (0.1171)\tPrec 97.656% (97.656%)\n",
      "Epoch: [115][100/391]\tTime 0.035 (0.049)\tData 0.002 (0.011)\tLoss 0.1301 (0.0963)\tPrec 96.094% (96.658%)\n",
      "Epoch: [115][200/391]\tTime 0.045 (0.045)\tData 0.002 (0.007)\tLoss 0.1718 (0.1063)\tPrec 94.531% (96.393%)\n",
      "Epoch: [115][300/391]\tTime 0.041 (0.044)\tData 0.002 (0.005)\tLoss 0.2104 (0.1098)\tPrec 94.531% (96.340%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.314 (0.314)\tLoss 0.5359 (0.5359)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.600% \n",
      "best acc: 89.430000\n",
      "Epoch: [116][0/391]\tTime 0.841 (0.841)\tData 0.786 (0.786)\tLoss 0.1472 (0.1472)\tPrec 95.312% (95.312%)\n",
      "Epoch: [116][100/391]\tTime 0.041 (0.049)\tData 0.002 (0.010)\tLoss 0.1248 (0.1128)\tPrec 96.875% (96.272%)\n",
      "Epoch: [116][200/391]\tTime 0.041 (0.045)\tData 0.002 (0.006)\tLoss 0.1648 (0.1109)\tPrec 96.875% (96.280%)\n",
      "Epoch: [116][300/391]\tTime 0.038 (0.044)\tData 0.003 (0.005)\tLoss 0.0628 (0.1141)\tPrec 98.438% (96.172%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.327 (0.327)\tLoss 0.3032 (0.3032)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.550% \n",
      "best acc: 89.430000\n",
      "Epoch: [117][0/391]\tTime 1.044 (1.044)\tData 0.990 (0.990)\tLoss 0.1283 (0.1283)\tPrec 96.875% (96.875%)\n",
      "Epoch: [117][100/391]\tTime 0.042 (0.051)\tData 0.002 (0.012)\tLoss 0.0675 (0.0964)\tPrec 97.656% (96.813%)\n",
      "Epoch: [117][200/391]\tTime 0.042 (0.046)\tData 0.002 (0.007)\tLoss 0.1710 (0.1016)\tPrec 94.531% (96.657%)\n",
      "Epoch: [117][300/391]\tTime 0.045 (0.044)\tData 0.003 (0.006)\tLoss 0.2000 (0.1089)\tPrec 93.750% (96.377%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.347 (0.347)\tLoss 0.4280 (0.4280)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.670% \n",
      "best acc: 89.430000\n",
      "Epoch: [118][0/391]\tTime 0.841 (0.841)\tData 0.789 (0.789)\tLoss 0.0844 (0.0844)\tPrec 96.875% (96.875%)\n",
      "Epoch: [118][100/391]\tTime 0.043 (0.050)\tData 0.002 (0.010)\tLoss 0.1484 (0.0974)\tPrec 92.969% (96.736%)\n",
      "Epoch: [118][200/391]\tTime 0.037 (0.046)\tData 0.002 (0.006)\tLoss 0.0507 (0.1092)\tPrec 98.438% (96.385%)\n",
      "Epoch: [118][300/391]\tTime 0.038 (0.045)\tData 0.002 (0.005)\tLoss 0.1024 (0.1099)\tPrec 95.312% (96.286%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.255 (0.255)\tLoss 0.4106 (0.4106)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.640% \n",
      "best acc: 89.430000\n",
      "Epoch: [119][0/391]\tTime 0.995 (0.995)\tData 0.938 (0.938)\tLoss 0.1047 (0.1047)\tPrec 96.094% (96.094%)\n",
      "Epoch: [119][100/391]\tTime 0.042 (0.052)\tData 0.002 (0.012)\tLoss 0.0179 (0.0942)\tPrec 99.219% (96.790%)\n",
      "Epoch: [119][200/391]\tTime 0.038 (0.047)\tData 0.002 (0.007)\tLoss 0.0878 (0.0981)\tPrec 96.094% (96.630%)\n",
      "Epoch: [119][300/391]\tTime 0.050 (0.048)\tData 0.003 (0.006)\tLoss 0.2193 (0.1022)\tPrec 92.188% (96.545%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.471 (0.471)\tLoss 0.2767 (0.2767)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.840% \n",
      "best acc: 89.430000\n",
      "Epoch: [120][0/391]\tTime 0.851 (0.851)\tData 0.797 (0.797)\tLoss 0.1189 (0.1189)\tPrec 95.312% (95.312%)\n",
      "Epoch: [120][100/391]\tTime 0.040 (0.045)\tData 0.002 (0.010)\tLoss 0.2038 (0.0906)\tPrec 94.531% (97.030%)\n",
      "Epoch: [120][200/391]\tTime 0.038 (0.041)\tData 0.002 (0.006)\tLoss 0.1394 (0.0977)\tPrec 95.312% (96.716%)\n",
      "Epoch: [120][300/391]\tTime 0.031 (0.040)\tData 0.001 (0.005)\tLoss 0.1478 (0.1032)\tPrec 95.312% (96.582%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.504 (0.504)\tLoss 0.2937 (0.2937)\tPrec 92.969% (92.969%)\n",
      " * Prec 86.540% \n",
      "best acc: 89.430000\n",
      "Epoch: [121][0/391]\tTime 0.917 (0.917)\tData 0.867 (0.867)\tLoss 0.1265 (0.1265)\tPrec 96.875% (96.875%)\n",
      "Epoch: [121][100/391]\tTime 0.043 (0.049)\tData 0.002 (0.010)\tLoss 0.0528 (0.0883)\tPrec 97.656% (97.146%)\n",
      "Epoch: [121][200/391]\tTime 0.036 (0.044)\tData 0.002 (0.006)\tLoss 0.0741 (0.0900)\tPrec 98.438% (97.023%)\n",
      "Epoch: [121][300/391]\tTime 0.044 (0.041)\tData 0.005 (0.005)\tLoss 0.1111 (0.0925)\tPrec 94.531% (96.950%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.559 (0.559)\tLoss 0.4625 (0.4625)\tPrec 87.500% (87.500%)\n",
      " * Prec 87.240% \n",
      "best acc: 89.430000\n",
      "Epoch: [122][0/391]\tTime 1.039 (1.039)\tData 0.989 (0.989)\tLoss 0.1380 (0.1380)\tPrec 95.312% (95.312%)\n",
      "Epoch: [122][100/391]\tTime 0.032 (0.048)\tData 0.001 (0.012)\tLoss 0.1366 (0.0956)\tPrec 95.312% (96.844%)\n",
      "Epoch: [122][200/391]\tTime 0.035 (0.043)\tData 0.001 (0.007)\tLoss 0.1559 (0.0998)\tPrec 96.094% (96.735%)\n",
      "Epoch: [122][300/391]\tTime 0.034 (0.042)\tData 0.002 (0.005)\tLoss 0.1823 (0.1053)\tPrec 93.750% (96.577%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.320 (0.320)\tLoss 0.3834 (0.3834)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.190% \n",
      "best acc: 89.430000\n",
      "Epoch: [123][0/391]\tTime 0.655 (0.655)\tData 0.587 (0.587)\tLoss 0.0592 (0.0592)\tPrec 98.438% (98.438%)\n",
      "Epoch: [123][100/391]\tTime 0.042 (0.050)\tData 0.005 (0.008)\tLoss 0.0711 (0.0911)\tPrec 96.875% (96.945%)\n",
      "Epoch: [123][200/391]\tTime 0.046 (0.046)\tData 0.003 (0.005)\tLoss 0.0631 (0.0960)\tPrec 98.438% (96.755%)\n",
      "Epoch: [123][300/391]\tTime 0.042 (0.045)\tData 0.002 (0.004)\tLoss 0.0739 (0.0993)\tPrec 97.656% (96.589%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.467 (0.467)\tLoss 0.4978 (0.4978)\tPrec 89.062% (89.062%)\n",
      " * Prec 84.820% \n",
      "best acc: 89.430000\n",
      "Epoch: [124][0/391]\tTime 0.610 (0.610)\tData 0.556 (0.556)\tLoss 0.1941 (0.1941)\tPrec 94.531% (94.531%)\n",
      "Epoch: [124][100/391]\tTime 0.047 (0.049)\tData 0.003 (0.008)\tLoss 0.0823 (0.1057)\tPrec 96.094% (96.264%)\n",
      "Epoch: [124][200/391]\tTime 0.043 (0.047)\tData 0.003 (0.005)\tLoss 0.0369 (0.1001)\tPrec 98.438% (96.506%)\n",
      "Epoch: [124][300/391]\tTime 0.041 (0.045)\tData 0.002 (0.004)\tLoss 0.0345 (0.1005)\tPrec 99.219% (96.595%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.333 (0.333)\tLoss 0.5525 (0.5525)\tPrec 86.719% (86.719%)\n",
      " * Prec 86.980% \n",
      "best acc: 89.430000\n",
      "Epoch: [125][0/391]\tTime 0.696 (0.696)\tData 0.643 (0.643)\tLoss 0.0748 (0.0748)\tPrec 96.875% (96.875%)\n",
      "Epoch: [125][100/391]\tTime 0.041 (0.049)\tData 0.002 (0.009)\tLoss 0.1216 (0.0935)\tPrec 96.094% (96.999%)\n",
      "Epoch: [125][200/391]\tTime 0.036 (0.045)\tData 0.002 (0.006)\tLoss 0.0461 (0.0974)\tPrec 99.219% (96.848%)\n",
      "Epoch: [125][300/391]\tTime 0.039 (0.045)\tData 0.002 (0.005)\tLoss 0.0290 (0.0978)\tPrec 98.438% (96.805%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.465 (0.465)\tLoss 0.2844 (0.2844)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.000% \n",
      "best acc: 89.430000\n",
      "Epoch: [126][0/391]\tTime 0.907 (0.907)\tData 0.851 (0.851)\tLoss 0.0924 (0.0924)\tPrec 96.875% (96.875%)\n",
      "Epoch: [126][100/391]\tTime 0.042 (0.051)\tData 0.002 (0.011)\tLoss 0.1452 (0.0923)\tPrec 96.094% (96.890%)\n",
      "Epoch: [126][200/391]\tTime 0.039 (0.046)\tData 0.002 (0.007)\tLoss 0.0678 (0.0939)\tPrec 98.438% (96.906%)\n",
      "Epoch: [126][300/391]\tTime 0.040 (0.045)\tData 0.002 (0.005)\tLoss 0.0918 (0.0956)\tPrec 98.438% (96.849%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.358 (0.358)\tLoss 0.4053 (0.4053)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.440% \n",
      "best acc: 89.430000\n",
      "Epoch: [127][0/391]\tTime 0.816 (0.816)\tData 0.746 (0.746)\tLoss 0.0417 (0.0417)\tPrec 98.438% (98.438%)\n",
      "Epoch: [127][100/391]\tTime 0.044 (0.051)\tData 0.003 (0.010)\tLoss 0.1310 (0.0881)\tPrec 95.312% (96.960%)\n",
      "Epoch: [127][200/391]\tTime 0.038 (0.047)\tData 0.002 (0.006)\tLoss 0.1635 (0.1003)\tPrec 94.531% (96.506%)\n",
      "Epoch: [127][300/391]\tTime 0.040 (0.046)\tData 0.002 (0.005)\tLoss 0.0722 (0.1008)\tPrec 98.438% (96.543%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.988 (0.988)\tLoss 0.3759 (0.3759)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.510% \n",
      "best acc: 89.430000\n",
      "Epoch: [128][0/391]\tTime 0.618 (0.618)\tData 0.575 (0.575)\tLoss 0.1284 (0.1284)\tPrec 94.531% (94.531%)\n",
      "Epoch: [128][100/391]\tTime 0.042 (0.048)\tData 0.002 (0.008)\tLoss 0.0958 (0.0965)\tPrec 96.875% (96.852%)\n",
      "Epoch: [128][200/391]\tTime 0.042 (0.044)\tData 0.002 (0.005)\tLoss 0.0847 (0.0950)\tPrec 96.094% (96.883%)\n",
      "Epoch: [128][300/391]\tTime 0.039 (0.043)\tData 0.003 (0.004)\tLoss 0.0647 (0.0987)\tPrec 96.875% (96.701%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.476 (0.476)\tLoss 0.4498 (0.4498)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.570% \n",
      "best acc: 89.430000\n",
      "Epoch: [129][0/391]\tTime 0.749 (0.749)\tData 0.694 (0.694)\tLoss 0.0968 (0.0968)\tPrec 96.875% (96.875%)\n",
      "Epoch: [129][100/391]\tTime 0.040 (0.049)\tData 0.002 (0.009)\tLoss 0.0702 (0.0971)\tPrec 96.875% (96.821%)\n",
      "Epoch: [129][200/391]\tTime 0.038 (0.046)\tData 0.002 (0.006)\tLoss 0.1104 (0.0976)\tPrec 96.094% (96.755%)\n",
      "Epoch: [129][300/391]\tTime 0.045 (0.044)\tData 0.002 (0.005)\tLoss 0.0924 (0.1019)\tPrec 97.656% (96.621%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.244 (0.244)\tLoss 0.3153 (0.3153)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.920% \n",
      "best acc: 89.430000\n",
      "Epoch: [130][0/391]\tTime 0.628 (0.628)\tData 0.574 (0.574)\tLoss 0.0812 (0.0812)\tPrec 95.312% (95.312%)\n",
      "Epoch: [130][100/391]\tTime 0.043 (0.047)\tData 0.002 (0.008)\tLoss 0.0855 (0.0980)\tPrec 98.438% (96.813%)\n",
      "Epoch: [130][200/391]\tTime 0.048 (0.044)\tData 0.002 (0.005)\tLoss 0.1847 (0.1041)\tPrec 92.188% (96.521%)\n",
      "Epoch: [130][300/391]\tTime 0.042 (0.043)\tData 0.002 (0.004)\tLoss 0.1104 (0.1068)\tPrec 97.656% (96.418%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.407 (0.407)\tLoss 0.3960 (0.3960)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.290% \n",
      "best acc: 89.430000\n",
      "Epoch: [131][0/391]\tTime 1.207 (1.207)\tData 1.154 (1.154)\tLoss 0.0673 (0.0673)\tPrec 97.656% (97.656%)\n",
      "Epoch: [131][100/391]\tTime 0.035 (0.049)\tData 0.002 (0.014)\tLoss 0.0780 (0.0919)\tPrec 96.875% (97.030%)\n",
      "Epoch: [131][200/391]\tTime 0.044 (0.044)\tData 0.003 (0.008)\tLoss 0.1223 (0.1001)\tPrec 95.312% (96.735%)\n",
      "Epoch: [131][300/391]\tTime 0.041 (0.043)\tData 0.002 (0.006)\tLoss 0.0525 (0.0996)\tPrec 98.438% (96.730%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.981 (0.981)\tLoss 0.3619 (0.3619)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.590% \n",
      "best acc: 89.430000\n",
      "Epoch: [132][0/391]\tTime 1.016 (1.016)\tData 0.965 (0.965)\tLoss 0.0869 (0.0869)\tPrec 96.875% (96.875%)\n",
      "Epoch: [132][100/391]\tTime 0.046 (0.051)\tData 0.002 (0.012)\tLoss 0.1265 (0.1015)\tPrec 95.312% (96.573%)\n",
      "Epoch: [132][200/391]\tTime 0.042 (0.046)\tData 0.003 (0.007)\tLoss 0.1359 (0.0981)\tPrec 96.094% (96.673%)\n",
      "Epoch: [132][300/391]\tTime 0.067 (0.045)\tData 0.020 (0.006)\tLoss 0.1245 (0.1000)\tPrec 94.531% (96.660%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.166 (1.166)\tLoss 0.5365 (0.5365)\tPrec 85.156% (85.156%)\n",
      " * Prec 87.430% \n",
      "best acc: 89.430000\n",
      "Epoch: [133][0/391]\tTime 0.828 (0.828)\tData 0.774 (0.774)\tLoss 0.1120 (0.1120)\tPrec 97.656% (97.656%)\n",
      "Epoch: [133][100/391]\tTime 0.038 (0.049)\tData 0.002 (0.010)\tLoss 0.1066 (0.1040)\tPrec 95.312% (96.535%)\n",
      "Epoch: [133][200/391]\tTime 0.043 (0.045)\tData 0.002 (0.006)\tLoss 0.0360 (0.1062)\tPrec 99.219% (96.537%)\n",
      "Epoch: [133][300/391]\tTime 0.042 (0.044)\tData 0.001 (0.005)\tLoss 0.0618 (0.1061)\tPrec 96.875% (96.501%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.581 (0.581)\tLoss 0.4102 (0.4102)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.660% \n",
      "best acc: 89.430000\n",
      "Epoch: [134][0/391]\tTime 0.680 (0.680)\tData 0.628 (0.628)\tLoss 0.0707 (0.0707)\tPrec 97.656% (97.656%)\n",
      "Epoch: [134][100/391]\tTime 0.047 (0.047)\tData 0.003 (0.008)\tLoss 0.1223 (0.0966)\tPrec 95.312% (96.728%)\n",
      "Epoch: [134][200/391]\tTime 0.043 (0.044)\tData 0.002 (0.005)\tLoss 0.1312 (0.0945)\tPrec 95.312% (96.801%)\n",
      "Epoch: [134][300/391]\tTime 0.043 (0.043)\tData 0.002 (0.004)\tLoss 0.1355 (0.0967)\tPrec 95.312% (96.745%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.882 (0.882)\tLoss 0.4100 (0.4100)\tPrec 89.062% (89.062%)\n",
      " * Prec 88.630% \n",
      "best acc: 89.430000\n",
      "Epoch: [135][0/391]\tTime 0.922 (0.922)\tData 0.868 (0.868)\tLoss 0.1288 (0.1288)\tPrec 95.312% (95.312%)\n",
      "Epoch: [135][100/391]\tTime 0.043 (0.050)\tData 0.002 (0.011)\tLoss 0.0961 (0.0860)\tPrec 97.656% (97.324%)\n",
      "Epoch: [135][200/391]\tTime 0.039 (0.045)\tData 0.002 (0.006)\tLoss 0.0955 (0.0944)\tPrec 96.875% (96.972%)\n",
      "Epoch: [135][300/391]\tTime 0.038 (0.044)\tData 0.002 (0.005)\tLoss 0.0414 (0.1006)\tPrec 98.438% (96.740%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.922 (0.922)\tLoss 0.3283 (0.3283)\tPrec 89.062% (89.062%)\n",
      " * Prec 88.070% \n",
      "best acc: 89.430000\n",
      "Epoch: [136][0/391]\tTime 0.920 (0.920)\tData 0.868 (0.868)\tLoss 0.1118 (0.1118)\tPrec 96.094% (96.094%)\n",
      "Epoch: [136][100/391]\tTime 0.034 (0.050)\tData 0.002 (0.011)\tLoss 0.1192 (0.0920)\tPrec 94.531% (96.999%)\n",
      "Epoch: [136][200/391]\tTime 0.036 (0.045)\tData 0.002 (0.007)\tLoss 0.1060 (0.0905)\tPrec 94.531% (96.976%)\n",
      "Epoch: [136][300/391]\tTime 0.034 (0.044)\tData 0.003 (0.005)\tLoss 0.1779 (0.0938)\tPrec 95.312% (96.849%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.765 (0.765)\tLoss 0.3602 (0.3602)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.320% \n",
      "best acc: 89.430000\n",
      "Epoch: [137][0/391]\tTime 0.944 (0.944)\tData 0.891 (0.891)\tLoss 0.0485 (0.0485)\tPrec 99.219% (99.219%)\n",
      "Epoch: [137][100/391]\tTime 0.040 (0.049)\tData 0.002 (0.011)\tLoss 0.1085 (0.0957)\tPrec 96.094% (96.952%)\n",
      "Epoch: [137][200/391]\tTime 0.040 (0.045)\tData 0.002 (0.007)\tLoss 0.0658 (0.0955)\tPrec 97.656% (96.813%)\n",
      "Epoch: [137][300/391]\tTime 0.041 (0.043)\tData 0.002 (0.005)\tLoss 0.1248 (0.0990)\tPrec 96.875% (96.717%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.876 (0.876)\tLoss 0.4446 (0.4446)\tPrec 86.719% (86.719%)\n",
      " * Prec 87.320% \n",
      "best acc: 89.430000\n",
      "Epoch: [138][0/391]\tTime 0.992 (0.992)\tData 0.946 (0.946)\tLoss 0.0516 (0.0516)\tPrec 98.438% (98.438%)\n",
      "Epoch: [138][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.012)\tLoss 0.1154 (0.0835)\tPrec 96.875% (97.099%)\n",
      "Epoch: [138][200/391]\tTime 0.041 (0.045)\tData 0.002 (0.007)\tLoss 0.0281 (0.0905)\tPrec 99.219% (96.910%)\n",
      "Epoch: [138][300/391]\tTime 0.040 (0.044)\tData 0.002 (0.005)\tLoss 0.0980 (0.0942)\tPrec 96.875% (96.774%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.932 (0.932)\tLoss 0.6066 (0.6066)\tPrec 85.156% (85.156%)\n",
      " * Prec 87.490% \n",
      "best acc: 89.430000\n",
      "Epoch: [139][0/391]\tTime 1.220 (1.220)\tData 1.167 (1.167)\tLoss 0.2058 (0.2058)\tPrec 92.969% (92.969%)\n",
      "Epoch: [139][100/391]\tTime 0.044 (0.052)\tData 0.002 (0.014)\tLoss 0.0485 (0.0929)\tPrec 98.438% (96.914%)\n",
      "Epoch: [139][200/391]\tTime 0.030 (0.043)\tData 0.001 (0.008)\tLoss 0.1377 (0.0911)\tPrec 95.312% (96.902%)\n",
      "Epoch: [139][300/391]\tTime 0.038 (0.040)\tData 0.002 (0.006)\tLoss 0.0694 (0.0958)\tPrec 98.438% (96.797%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.795 (0.795)\tLoss 0.3166 (0.3166)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.960% \n",
      "best acc: 89.430000\n",
      "Epoch: [140][0/391]\tTime 1.040 (1.040)\tData 0.985 (0.985)\tLoss 0.0539 (0.0539)\tPrec 96.875% (96.875%)\n",
      "Epoch: [140][100/391]\tTime 0.039 (0.052)\tData 0.002 (0.012)\tLoss 0.0747 (0.0862)\tPrec 99.219% (97.084%)\n",
      "Epoch: [140][200/391]\tTime 0.040 (0.046)\tData 0.002 (0.007)\tLoss 0.0879 (0.0914)\tPrec 97.656% (97.015%)\n",
      "Epoch: [140][300/391]\tTime 0.040 (0.044)\tData 0.002 (0.005)\tLoss 0.0316 (0.0933)\tPrec 99.219% (96.953%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.871 (0.871)\tLoss 0.3388 (0.3388)\tPrec 87.500% (87.500%)\n",
      " * Prec 88.610% \n",
      "best acc: 89.430000\n",
      "Epoch: [141][0/391]\tTime 0.974 (0.974)\tData 0.920 (0.920)\tLoss 0.1552 (0.1552)\tPrec 95.312% (95.312%)\n",
      "Epoch: [141][100/391]\tTime 0.044 (0.050)\tData 0.002 (0.011)\tLoss 0.0263 (0.0885)\tPrec 99.219% (96.914%)\n",
      "Epoch: [141][200/391]\tTime 0.040 (0.045)\tData 0.003 (0.007)\tLoss 0.0224 (0.0919)\tPrec 99.219% (96.840%)\n",
      "Epoch: [141][300/391]\tTime 0.041 (0.044)\tData 0.002 (0.005)\tLoss 0.0945 (0.0952)\tPrec 96.875% (96.784%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.047 (1.047)\tLoss 0.4307 (0.4307)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.960% \n",
      "best acc: 89.430000\n",
      "Epoch: [142][0/391]\tTime 0.883 (0.883)\tData 0.829 (0.829)\tLoss 0.0576 (0.0576)\tPrec 98.438% (98.438%)\n",
      "Epoch: [142][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.010)\tLoss 0.0784 (0.0802)\tPrec 97.656% (97.269%)\n",
      "Epoch: [142][200/391]\tTime 0.041 (0.045)\tData 0.002 (0.006)\tLoss 0.0784 (0.0891)\tPrec 96.875% (96.984%)\n",
      "Epoch: [142][300/391]\tTime 0.040 (0.043)\tData 0.002 (0.005)\tLoss 0.0650 (0.0923)\tPrec 98.438% (96.898%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.867 (0.867)\tLoss 0.5416 (0.5416)\tPrec 86.719% (86.719%)\n",
      " * Prec 88.080% \n",
      "best acc: 89.430000\n",
      "Epoch: [143][0/391]\tTime 0.944 (0.944)\tData 0.891 (0.891)\tLoss 0.0675 (0.0675)\tPrec 96.875% (96.875%)\n",
      "Epoch: [143][100/391]\tTime 0.039 (0.049)\tData 0.002 (0.011)\tLoss 0.1136 (0.0977)\tPrec 96.094% (96.829%)\n",
      "Epoch: [143][200/391]\tTime 0.041 (0.045)\tData 0.002 (0.007)\tLoss 0.1238 (0.0958)\tPrec 96.094% (96.817%)\n",
      "Epoch: [143][300/391]\tTime 0.040 (0.043)\tData 0.002 (0.005)\tLoss 0.1154 (0.0951)\tPrec 96.875% (96.815%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.942 (0.942)\tLoss 0.3405 (0.3405)\tPrec 91.406% (91.406%)\n",
      " * Prec 89.390% \n",
      "best acc: 89.430000\n",
      "Epoch: [144][0/391]\tTime 0.772 (0.772)\tData 0.720 (0.720)\tLoss 0.0531 (0.0531)\tPrec 98.438% (98.438%)\n",
      "Epoch: [144][100/391]\tTime 0.040 (0.048)\tData 0.002 (0.009)\tLoss 0.1340 (0.0843)\tPrec 96.875% (97.123%)\n",
      "Epoch: [144][200/391]\tTime 0.041 (0.044)\tData 0.002 (0.006)\tLoss 0.0608 (0.0923)\tPrec 97.656% (96.852%)\n",
      "Epoch: [144][300/391]\tTime 0.039 (0.043)\tData 0.002 (0.005)\tLoss 0.1411 (0.0958)\tPrec 94.531% (96.758%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.939 (0.939)\tLoss 0.4081 (0.4081)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.830% \n",
      "best acc: 89.430000\n",
      "Epoch: [145][0/391]\tTime 0.958 (0.958)\tData 0.906 (0.906)\tLoss 0.1273 (0.1273)\tPrec 96.094% (96.094%)\n",
      "Epoch: [145][100/391]\tTime 0.044 (0.050)\tData 0.002 (0.011)\tLoss 0.0739 (0.0968)\tPrec 97.656% (96.782%)\n",
      "Epoch: [145][200/391]\tTime 0.041 (0.045)\tData 0.002 (0.007)\tLoss 0.1199 (0.0923)\tPrec 96.094% (96.972%)\n",
      "Epoch: [145][300/391]\tTime 0.044 (0.043)\tData 0.002 (0.005)\tLoss 0.0565 (0.0952)\tPrec 97.656% (96.919%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.061 (1.061)\tLoss 0.5588 (0.5588)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.980% \n",
      "best acc: 89.430000\n",
      "Epoch: [146][0/391]\tTime 0.962 (0.962)\tData 0.909 (0.909)\tLoss 0.0753 (0.0753)\tPrec 96.094% (96.094%)\n",
      "Epoch: [146][100/391]\tTime 0.040 (0.051)\tData 0.002 (0.011)\tLoss 0.0868 (0.0887)\tPrec 97.656% (97.146%)\n",
      "Epoch: [146][200/391]\tTime 0.035 (0.046)\tData 0.002 (0.007)\tLoss 0.0737 (0.0894)\tPrec 97.656% (97.027%)\n",
      "Epoch: [146][300/391]\tTime 0.041 (0.044)\tData 0.002 (0.005)\tLoss 0.0865 (0.0915)\tPrec 96.875% (96.932%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.759 (0.759)\tLoss 0.3522 (0.3522)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.930% \n",
      "best acc: 89.430000\n",
      "Epoch: [147][0/391]\tTime 0.950 (0.950)\tData 0.898 (0.898)\tLoss 0.1135 (0.1135)\tPrec 97.656% (97.656%)\n",
      "Epoch: [147][100/391]\tTime 0.041 (0.050)\tData 0.002 (0.011)\tLoss 0.0906 (0.0875)\tPrec 96.094% (97.123%)\n",
      "Epoch: [147][200/391]\tTime 0.045 (0.046)\tData 0.003 (0.007)\tLoss 0.0560 (0.0889)\tPrec 97.656% (97.027%)\n",
      "Epoch: [147][300/391]\tTime 0.042 (0.044)\tData 0.003 (0.005)\tLoss 0.1488 (0.0902)\tPrec 96.094% (96.966%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.736 (0.736)\tLoss 0.4075 (0.4075)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.020% \n",
      "best acc: 89.430000\n",
      "Epoch: [148][0/391]\tTime 0.894 (0.894)\tData 0.841 (0.841)\tLoss 0.1172 (0.1172)\tPrec 93.750% (93.750%)\n",
      "Epoch: [148][100/391]\tTime 0.038 (0.049)\tData 0.002 (0.010)\tLoss 0.0951 (0.0856)\tPrec 97.656% (97.177%)\n",
      "Epoch: [148][200/391]\tTime 0.037 (0.045)\tData 0.002 (0.006)\tLoss 0.0951 (0.0918)\tPrec 96.875% (96.980%)\n",
      "Epoch: [148][300/391]\tTime 0.048 (0.043)\tData 0.003 (0.005)\tLoss 0.0923 (0.0923)\tPrec 96.094% (96.924%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.786 (0.786)\tLoss 0.3611 (0.3611)\tPrec 89.062% (89.062%)\n",
      " * Prec 88.040% \n",
      "best acc: 89.430000\n",
      "Epoch: [149][0/391]\tTime 1.007 (1.007)\tData 0.934 (0.934)\tLoss 0.0883 (0.0883)\tPrec 97.656% (97.656%)\n",
      "Epoch: [149][100/391]\tTime 0.041 (0.051)\tData 0.002 (0.012)\tLoss 0.0872 (0.0879)\tPrec 96.094% (97.153%)\n",
      "Epoch: [149][200/391]\tTime 0.039 (0.046)\tData 0.002 (0.007)\tLoss 0.0618 (0.0909)\tPrec 98.438% (96.995%)\n",
      "Epoch: [149][300/391]\tTime 0.042 (0.044)\tData 0.002 (0.005)\tLoss 0.1015 (0.0909)\tPrec 96.094% (96.945%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.966 (0.966)\tLoss 0.4268 (0.4268)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.010% \n",
      "best acc: 89.430000\n",
      "Epoch: [150][0/391]\tTime 0.983 (0.983)\tData 0.931 (0.931)\tLoss 0.1121 (0.1121)\tPrec 96.875% (96.875%)\n",
      "Epoch: [150][100/391]\tTime 0.038 (0.050)\tData 0.002 (0.011)\tLoss 0.0195 (0.0638)\tPrec 99.219% (97.896%)\n",
      "Epoch: [150][200/391]\tTime 0.043 (0.045)\tData 0.002 (0.007)\tLoss 0.0249 (0.0544)\tPrec 100.000% (98.173%)\n",
      "Epoch: [150][300/391]\tTime 0.039 (0.044)\tData 0.003 (0.005)\tLoss 0.0715 (0.0489)\tPrec 97.656% (98.380%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.879 (0.879)\tLoss 0.2870 (0.2870)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.840% \n",
      "best acc: 90.840000\n",
      "Epoch: [151][0/391]\tTime 1.089 (1.089)\tData 1.035 (1.035)\tLoss 0.0160 (0.0160)\tPrec 99.219% (99.219%)\n",
      "Epoch: [151][100/391]\tTime 0.036 (0.051)\tData 0.002 (0.012)\tLoss 0.0222 (0.0256)\tPrec 98.438% (99.203%)\n",
      "Epoch: [151][200/391]\tTime 0.041 (0.046)\tData 0.002 (0.007)\tLoss 0.0276 (0.0254)\tPrec 99.219% (99.219%)\n",
      "Epoch: [151][300/391]\tTime 0.038 (0.044)\tData 0.001 (0.006)\tLoss 0.0035 (0.0260)\tPrec 100.000% (99.185%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.915 (0.915)\tLoss 0.2983 (0.2983)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.190% \n",
      "best acc: 91.190000\n",
      "Epoch: [152][0/391]\tTime 0.917 (0.917)\tData 0.862 (0.862)\tLoss 0.0625 (0.0625)\tPrec 97.656% (97.656%)\n",
      "Epoch: [152][100/391]\tTime 0.035 (0.049)\tData 0.002 (0.011)\tLoss 0.0052 (0.0215)\tPrec 100.000% (99.350%)\n",
      "Epoch: [152][200/391]\tTime 0.043 (0.045)\tData 0.002 (0.006)\tLoss 0.0130 (0.0193)\tPrec 100.000% (99.405%)\n",
      "Epoch: [152][300/391]\tTime 0.040 (0.043)\tData 0.002 (0.005)\tLoss 0.0208 (0.0191)\tPrec 99.219% (99.398%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.994 (0.994)\tLoss 0.2933 (0.2933)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.940% \n",
      "best acc: 91.190000\n",
      "Epoch: [153][0/391]\tTime 1.008 (1.008)\tData 0.954 (0.954)\tLoss 0.0121 (0.0121)\tPrec 100.000% (100.000%)\n",
      "Epoch: [153][100/391]\tTime 0.038 (0.050)\tData 0.003 (0.012)\tLoss 0.0110 (0.0160)\tPrec 100.000% (99.544%)\n",
      "Epoch: [153][200/391]\tTime 0.041 (0.046)\tData 0.002 (0.007)\tLoss 0.0060 (0.0173)\tPrec 100.000% (99.464%)\n",
      "Epoch: [153][300/391]\tTime 0.038 (0.044)\tData 0.002 (0.005)\tLoss 0.0037 (0.0160)\tPrec 100.000% (99.507%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.664 (0.664)\tLoss 0.2899 (0.2899)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.100% \n",
      "best acc: 91.190000\n",
      "Epoch: [154][0/391]\tTime 0.921 (0.921)\tData 0.870 (0.870)\tLoss 0.0127 (0.0127)\tPrec 100.000% (100.000%)\n",
      "Epoch: [154][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.011)\tLoss 0.0434 (0.0154)\tPrec 97.656% (99.528%)\n",
      "Epoch: [154][200/391]\tTime 0.038 (0.045)\tData 0.002 (0.007)\tLoss 0.0175 (0.0159)\tPrec 99.219% (99.518%)\n",
      "Epoch: [154][300/391]\tTime 0.041 (0.044)\tData 0.002 (0.005)\tLoss 0.0033 (0.0154)\tPrec 100.000% (99.522%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.670 (0.670)\tLoss 0.2389 (0.2389)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.440% \n",
      "best acc: 91.440000\n",
      "Epoch: [155][0/391]\tTime 0.838 (0.838)\tData 0.785 (0.785)\tLoss 0.0088 (0.0088)\tPrec 100.000% (100.000%)\n",
      "Epoch: [155][100/391]\tTime 0.040 (0.048)\tData 0.002 (0.010)\tLoss 0.0109 (0.0160)\tPrec 100.000% (99.528%)\n",
      "Epoch: [155][200/391]\tTime 0.044 (0.044)\tData 0.002 (0.006)\tLoss 0.0031 (0.0146)\tPrec 100.000% (99.565%)\n",
      "Epoch: [155][300/391]\tTime 0.044 (0.043)\tData 0.003 (0.005)\tLoss 0.0032 (0.0139)\tPrec 100.000% (99.569%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.899 (0.899)\tLoss 0.3141 (0.3141)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.320% \n",
      "best acc: 91.440000\n",
      "Epoch: [156][0/391]\tTime 1.086 (1.086)\tData 1.033 (1.033)\tLoss 0.0047 (0.0047)\tPrec 100.000% (100.000%)\n",
      "Epoch: [156][100/391]\tTime 0.042 (0.053)\tData 0.002 (0.013)\tLoss 0.0024 (0.0115)\tPrec 100.000% (99.636%)\n",
      "Epoch: [156][200/391]\tTime 0.041 (0.047)\tData 0.003 (0.007)\tLoss 0.0064 (0.0122)\tPrec 100.000% (99.615%)\n",
      "Epoch: [156][300/391]\tTime 0.043 (0.045)\tData 0.002 (0.006)\tLoss 0.0077 (0.0121)\tPrec 100.000% (99.621%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.577 (0.577)\tLoss 0.2859 (0.2859)\tPrec 92.969% (92.969%)\n",
      " * Prec 91.510% \n",
      "best acc: 91.510000\n",
      "Epoch: [157][0/391]\tTime 1.038 (1.038)\tData 0.985 (0.985)\tLoss 0.0038 (0.0038)\tPrec 100.000% (100.000%)\n",
      "Epoch: [157][100/391]\tTime 0.041 (0.050)\tData 0.002 (0.012)\tLoss 0.0009 (0.0123)\tPrec 100.000% (99.621%)\n",
      "Epoch: [157][200/391]\tTime 0.041 (0.045)\tData 0.002 (0.007)\tLoss 0.0031 (0.0117)\tPrec 100.000% (99.639%)\n",
      "Epoch: [157][300/391]\tTime 0.042 (0.044)\tData 0.002 (0.005)\tLoss 0.0037 (0.0113)\tPrec 100.000% (99.644%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.770 (0.770)\tLoss 0.3096 (0.3096)\tPrec 92.188% (92.188%)\n",
      " * Prec 91.280% \n",
      "best acc: 91.510000\n",
      "Epoch: [158][0/391]\tTime 0.959 (0.959)\tData 0.904 (0.904)\tLoss 0.0224 (0.0224)\tPrec 99.219% (99.219%)\n",
      "Epoch: [158][100/391]\tTime 0.038 (0.050)\tData 0.001 (0.011)\tLoss 0.0014 (0.0105)\tPrec 100.000% (99.652%)\n",
      "Epoch: [158][200/391]\tTime 0.041 (0.046)\tData 0.002 (0.006)\tLoss 0.0029 (0.0093)\tPrec 100.000% (99.685%)\n",
      "Epoch: [158][300/391]\tTime 0.041 (0.044)\tData 0.002 (0.005)\tLoss 0.0080 (0.0094)\tPrec 100.000% (99.699%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.765 (0.765)\tLoss 0.2928 (0.2928)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.360% \n",
      "best acc: 91.510000\n",
      "Epoch: [159][0/391]\tTime 1.015 (1.015)\tData 0.961 (0.961)\tLoss 0.0077 (0.0077)\tPrec 99.219% (99.219%)\n",
      "Epoch: [159][100/391]\tTime 0.040 (0.050)\tData 0.002 (0.012)\tLoss 0.0070 (0.0102)\tPrec 100.000% (99.636%)\n",
      "Epoch: [159][200/391]\tTime 0.035 (0.045)\tData 0.002 (0.007)\tLoss 0.0075 (0.0091)\tPrec 100.000% (99.685%)\n",
      "Epoch: [159][300/391]\tTime 0.039 (0.044)\tData 0.002 (0.005)\tLoss 0.0015 (0.0099)\tPrec 100.000% (99.663%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.859 (0.859)\tLoss 0.3294 (0.3294)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.220% \n",
      "best acc: 91.510000\n",
      "Epoch: [160][0/391]\tTime 1.044 (1.044)\tData 0.987 (0.987)\tLoss 0.0131 (0.0131)\tPrec 99.219% (99.219%)\n",
      "Epoch: [160][100/391]\tTime 0.036 (0.050)\tData 0.002 (0.012)\tLoss 0.0170 (0.0091)\tPrec 99.219% (99.660%)\n",
      "Epoch: [160][200/391]\tTime 0.041 (0.045)\tData 0.002 (0.007)\tLoss 0.0227 (0.0090)\tPrec 99.219% (99.681%)\n",
      "Epoch: [160][300/391]\tTime 0.042 (0.043)\tData 0.002 (0.005)\tLoss 0.0016 (0.0098)\tPrec 100.000% (99.673%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.173 (1.173)\tLoss 0.2693 (0.2693)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.570% \n",
      "best acc: 91.570000\n",
      "Epoch: [161][0/391]\tTime 1.008 (1.008)\tData 0.962 (0.962)\tLoss 0.0018 (0.0018)\tPrec 100.000% (100.000%)\n",
      "Epoch: [161][100/391]\tTime 0.047 (0.049)\tData 0.002 (0.012)\tLoss 0.0037 (0.0078)\tPrec 100.000% (99.745%)\n",
      "Epoch: [161][200/391]\tTime 0.040 (0.045)\tData 0.002 (0.007)\tLoss 0.0094 (0.0090)\tPrec 99.219% (99.740%)\n",
      "Epoch: [161][300/391]\tTime 0.041 (0.044)\tData 0.002 (0.005)\tLoss 0.0029 (0.0081)\tPrec 100.000% (99.764%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.860 (0.860)\tLoss 0.2605 (0.2605)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.390% \n",
      "best acc: 91.570000\n",
      "Epoch: [162][0/391]\tTime 1.061 (1.061)\tData 1.008 (1.008)\tLoss 0.0022 (0.0022)\tPrec 100.000% (100.000%)\n",
      "Epoch: [162][100/391]\tTime 0.042 (0.051)\tData 0.002 (0.012)\tLoss 0.0019 (0.0087)\tPrec 100.000% (99.722%)\n",
      "Epoch: [162][200/391]\tTime 0.036 (0.046)\tData 0.002 (0.007)\tLoss 0.0006 (0.0082)\tPrec 100.000% (99.732%)\n",
      "Epoch: [162][300/391]\tTime 0.042 (0.044)\tData 0.002 (0.006)\tLoss 0.0043 (0.0080)\tPrec 100.000% (99.743%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.961 (0.961)\tLoss 0.2730 (0.2730)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.370% \n",
      "best acc: 91.570000\n",
      "Epoch: [163][0/391]\tTime 1.061 (1.061)\tData 1.005 (1.005)\tLoss 0.0020 (0.0020)\tPrec 100.000% (100.000%)\n",
      "Epoch: [163][100/391]\tTime 0.046 (0.051)\tData 0.003 (0.012)\tLoss 0.0063 (0.0068)\tPrec 100.000% (99.807%)\n",
      "Epoch: [163][200/391]\tTime 0.042 (0.046)\tData 0.002 (0.007)\tLoss 0.0359 (0.0082)\tPrec 98.438% (99.755%)\n",
      "Epoch: [163][300/391]\tTime 0.040 (0.044)\tData 0.001 (0.006)\tLoss 0.0145 (0.0077)\tPrec 99.219% (99.774%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.630 (0.630)\tLoss 0.2591 (0.2591)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.330% \n",
      "best acc: 91.570000\n",
      "Epoch: [164][0/391]\tTime 0.994 (0.994)\tData 0.941 (0.941)\tLoss 0.0014 (0.0014)\tPrec 100.000% (100.000%)\n",
      "Epoch: [164][100/391]\tTime 0.042 (0.050)\tData 0.003 (0.012)\tLoss 0.0218 (0.0073)\tPrec 99.219% (99.752%)\n",
      "Epoch: [164][200/391]\tTime 0.042 (0.045)\tData 0.003 (0.007)\tLoss 0.0051 (0.0076)\tPrec 100.000% (99.751%)\n",
      "Epoch: [164][300/391]\tTime 0.042 (0.044)\tData 0.003 (0.005)\tLoss 0.0013 (0.0072)\tPrec 100.000% (99.759%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.149 (1.149)\tLoss 0.2594 (0.2594)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.280% \n",
      "best acc: 91.570000\n",
      "Epoch: [165][0/391]\tTime 0.750 (0.750)\tData 0.697 (0.697)\tLoss 0.0038 (0.0038)\tPrec 100.000% (100.000%)\n",
      "Epoch: [165][100/391]\tTime 0.044 (0.048)\tData 0.002 (0.009)\tLoss 0.0033 (0.0053)\tPrec 100.000% (99.830%)\n",
      "Epoch: [165][200/391]\tTime 0.042 (0.044)\tData 0.002 (0.006)\tLoss 0.0016 (0.0063)\tPrec 100.000% (99.813%)\n",
      "Epoch: [165][300/391]\tTime 0.039 (0.043)\tData 0.002 (0.005)\tLoss 0.0117 (0.0069)\tPrec 99.219% (99.790%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.738 (0.738)\tLoss 0.2278 (0.2278)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.300% \n",
      "best acc: 91.570000\n",
      "Epoch: [166][0/391]\tTime 0.925 (0.925)\tData 0.870 (0.870)\tLoss 0.0019 (0.0019)\tPrec 100.000% (100.000%)\n",
      "Epoch: [166][100/391]\tTime 0.045 (0.050)\tData 0.002 (0.011)\tLoss 0.0012 (0.0076)\tPrec 100.000% (99.776%)\n",
      "Epoch: [166][200/391]\tTime 0.035 (0.046)\tData 0.002 (0.007)\tLoss 0.0010 (0.0066)\tPrec 100.000% (99.810%)\n",
      "Epoch: [166][300/391]\tTime 0.032 (0.044)\tData 0.001 (0.005)\tLoss 0.0137 (0.0072)\tPrec 99.219% (99.790%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.631 (0.631)\tLoss 0.2627 (0.2627)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.300% \n",
      "best acc: 91.570000\n",
      "Epoch: [167][0/391]\tTime 0.935 (0.935)\tData 0.884 (0.884)\tLoss 0.0044 (0.0044)\tPrec 100.000% (100.000%)\n",
      "Epoch: [167][100/391]\tTime 0.041 (0.049)\tData 0.002 (0.011)\tLoss 0.0228 (0.0071)\tPrec 99.219% (99.776%)\n",
      "Epoch: [167][200/391]\tTime 0.039 (0.044)\tData 0.002 (0.007)\tLoss 0.0054 (0.0065)\tPrec 100.000% (99.802%)\n",
      "Epoch: [167][300/391]\tTime 0.042 (0.043)\tData 0.002 (0.005)\tLoss 0.0118 (0.0061)\tPrec 99.219% (99.811%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.283 (0.283)\tLoss 0.2698 (0.2698)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.480% \n",
      "best acc: 91.570000\n",
      "Epoch: [168][0/391]\tTime 0.827 (0.827)\tData 0.776 (0.776)\tLoss 0.0006 (0.0006)\tPrec 100.000% (100.000%)\n",
      "Epoch: [168][100/391]\tTime 0.040 (0.048)\tData 0.002 (0.010)\tLoss 0.0539 (0.0063)\tPrec 98.438% (99.814%)\n",
      "Epoch: [168][200/391]\tTime 0.042 (0.044)\tData 0.002 (0.006)\tLoss 0.0381 (0.0065)\tPrec 99.219% (99.786%)\n",
      "Epoch: [168][300/391]\tTime 0.038 (0.043)\tData 0.002 (0.005)\tLoss 0.0017 (0.0069)\tPrec 100.000% (99.766%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.575 (0.575)\tLoss 0.2503 (0.2503)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.300% \n",
      "best acc: 91.570000\n",
      "Epoch: [169][0/391]\tTime 1.176 (1.176)\tData 1.135 (1.135)\tLoss 0.0009 (0.0009)\tPrec 100.000% (100.000%)\n",
      "Epoch: [169][100/391]\tTime 0.036 (0.052)\tData 0.002 (0.013)\tLoss 0.0021 (0.0061)\tPrec 100.000% (99.838%)\n",
      "Epoch: [169][200/391]\tTime 0.042 (0.046)\tData 0.002 (0.008)\tLoss 0.0011 (0.0069)\tPrec 100.000% (99.810%)\n",
      "Epoch: [169][300/391]\tTime 0.046 (0.045)\tData 0.002 (0.006)\tLoss 0.0010 (0.0067)\tPrec 100.000% (99.792%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.620 (0.620)\tLoss 0.2577 (0.2577)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.430% \n",
      "best acc: 91.570000\n",
      "Epoch: [170][0/391]\tTime 0.936 (0.936)\tData 0.860 (0.860)\tLoss 0.0389 (0.0389)\tPrec 99.219% (99.219%)\n",
      "Epoch: [170][100/391]\tTime 0.042 (0.051)\tData 0.002 (0.011)\tLoss 0.0007 (0.0066)\tPrec 100.000% (99.822%)\n",
      "Epoch: [170][200/391]\tTime 0.044 (0.046)\tData 0.003 (0.007)\tLoss 0.0488 (0.0063)\tPrec 98.438% (99.810%)\n",
      "Epoch: [170][300/391]\tTime 0.041 (0.044)\tData 0.003 (0.005)\tLoss 0.0007 (0.0062)\tPrec 100.000% (99.808%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.351 (0.351)\tLoss 0.3080 (0.3080)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.430% \n",
      "best acc: 91.570000\n",
      "Epoch: [171][0/391]\tTime 1.054 (1.054)\tData 1.000 (1.000)\tLoss 0.0091 (0.0091)\tPrec 99.219% (99.219%)\n",
      "Epoch: [171][100/391]\tTime 0.039 (0.050)\tData 0.002 (0.012)\tLoss 0.0045 (0.0064)\tPrec 100.000% (99.814%)\n",
      "Epoch: [171][200/391]\tTime 0.040 (0.046)\tData 0.002 (0.007)\tLoss 0.0008 (0.0063)\tPrec 100.000% (99.806%)\n",
      "Epoch: [171][300/391]\tTime 0.043 (0.044)\tData 0.002 (0.006)\tLoss 0.0007 (0.0063)\tPrec 100.000% (99.816%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.045 (1.045)\tLoss 0.3106 (0.3106)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.320% \n",
      "best acc: 91.570000\n",
      "Epoch: [172][0/391]\tTime 0.860 (0.860)\tData 0.783 (0.783)\tLoss 0.0045 (0.0045)\tPrec 100.000% (100.000%)\n",
      "Epoch: [172][100/391]\tTime 0.040 (0.049)\tData 0.002 (0.010)\tLoss 0.0062 (0.0063)\tPrec 100.000% (99.822%)\n",
      "Epoch: [172][200/391]\tTime 0.042 (0.045)\tData 0.002 (0.007)\tLoss 0.0007 (0.0064)\tPrec 100.000% (99.813%)\n",
      "Epoch: [172][300/391]\tTime 0.041 (0.044)\tData 0.002 (0.005)\tLoss 0.0097 (0.0065)\tPrec 99.219% (99.816%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.267 (0.267)\tLoss 0.2784 (0.2784)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.440% \n",
      "best acc: 91.570000\n",
      "Epoch: [173][0/391]\tTime 1.342 (1.342)\tData 1.291 (1.291)\tLoss 0.0054 (0.0054)\tPrec 100.000% (100.000%)\n",
      "Epoch: [173][100/391]\tTime 0.039 (0.054)\tData 0.002 (0.015)\tLoss 0.0296 (0.0049)\tPrec 98.438% (99.845%)\n",
      "Epoch: [173][200/391]\tTime 0.046 (0.048)\tData 0.003 (0.009)\tLoss 0.0008 (0.0043)\tPrec 100.000% (99.852%)\n",
      "Epoch: [173][300/391]\tTime 0.043 (0.045)\tData 0.002 (0.007)\tLoss 0.0283 (0.0050)\tPrec 99.219% (99.847%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.675 (0.675)\tLoss 0.2898 (0.2898)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.500% \n",
      "best acc: 91.570000\n",
      "Epoch: [174][0/391]\tTime 0.852 (0.852)\tData 0.801 (0.801)\tLoss 0.0025 (0.0025)\tPrec 100.000% (100.000%)\n",
      "Epoch: [174][100/391]\tTime 0.048 (0.049)\tData 0.002 (0.010)\tLoss 0.0038 (0.0059)\tPrec 100.000% (99.783%)\n",
      "Epoch: [174][200/391]\tTime 0.042 (0.044)\tData 0.002 (0.006)\tLoss 0.0252 (0.0053)\tPrec 98.438% (99.829%)\n",
      "Epoch: [174][300/391]\tTime 0.039 (0.044)\tData 0.002 (0.005)\tLoss 0.0216 (0.0055)\tPrec 98.438% (99.808%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.792 (0.792)\tLoss 0.2442 (0.2442)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.730% \n",
      "best acc: 91.730000\n",
      "Epoch: [175][0/391]\tTime 0.990 (0.990)\tData 0.938 (0.938)\tLoss 0.0025 (0.0025)\tPrec 100.000% (100.000%)\n",
      "Epoch: [175][100/391]\tTime 0.041 (0.051)\tData 0.002 (0.012)\tLoss 0.0023 (0.0050)\tPrec 100.000% (99.838%)\n",
      "Epoch: [175][200/391]\tTime 0.042 (0.046)\tData 0.002 (0.007)\tLoss 0.0050 (0.0058)\tPrec 100.000% (99.817%)\n",
      "Epoch: [175][300/391]\tTime 0.037 (0.045)\tData 0.002 (0.006)\tLoss 0.0103 (0.0055)\tPrec 100.000% (99.818%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.897 (0.897)\tLoss 0.2490 (0.2490)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.560% \n",
      "best acc: 91.730000\n",
      "Epoch: [176][0/391]\tTime 0.771 (0.771)\tData 0.717 (0.717)\tLoss 0.0020 (0.0020)\tPrec 100.000% (100.000%)\n",
      "Epoch: [176][100/391]\tTime 0.037 (0.049)\tData 0.002 (0.009)\tLoss 0.0036 (0.0046)\tPrec 100.000% (99.861%)\n",
      "Epoch: [176][200/391]\tTime 0.042 (0.045)\tData 0.002 (0.006)\tLoss 0.0111 (0.0044)\tPrec 99.219% (99.864%)\n",
      "Epoch: [176][300/391]\tTime 0.040 (0.044)\tData 0.002 (0.005)\tLoss 0.0009 (0.0050)\tPrec 100.000% (99.842%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.434 (0.434)\tLoss 0.2554 (0.2554)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.340% \n",
      "best acc: 91.730000\n",
      "Epoch: [177][0/391]\tTime 1.150 (1.150)\tData 1.077 (1.077)\tLoss 0.0022 (0.0022)\tPrec 100.000% (100.000%)\n",
      "Epoch: [177][100/391]\tTime 0.039 (0.052)\tData 0.002 (0.013)\tLoss 0.0011 (0.0048)\tPrec 100.000% (99.822%)\n",
      "Epoch: [177][200/391]\tTime 0.037 (0.046)\tData 0.003 (0.008)\tLoss 0.0018 (0.0049)\tPrec 100.000% (99.825%)\n",
      "Epoch: [177][300/391]\tTime 0.040 (0.044)\tData 0.002 (0.006)\tLoss 0.0047 (0.0056)\tPrec 100.000% (99.805%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.462 (0.462)\tLoss 0.2631 (0.2631)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.350% \n",
      "best acc: 91.730000\n",
      "Epoch: [178][0/391]\tTime 1.121 (1.121)\tData 1.069 (1.069)\tLoss 0.0080 (0.0080)\tPrec 99.219% (99.219%)\n",
      "Epoch: [178][100/391]\tTime 0.039 (0.052)\tData 0.002 (0.013)\tLoss 0.0005 (0.0048)\tPrec 100.000% (99.845%)\n",
      "Epoch: [178][200/391]\tTime 0.039 (0.046)\tData 0.002 (0.007)\tLoss 0.0086 (0.0051)\tPrec 99.219% (99.856%)\n",
      "Epoch: [178][300/391]\tTime 0.039 (0.045)\tData 0.002 (0.006)\tLoss 0.0066 (0.0050)\tPrec 100.000% (99.852%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.975 (0.975)\tLoss 0.2478 (0.2478)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.650% \n",
      "best acc: 91.730000\n",
      "Epoch: [179][0/391]\tTime 1.210 (1.210)\tData 1.157 (1.157)\tLoss 0.0064 (0.0064)\tPrec 100.000% (100.000%)\n",
      "Epoch: [179][100/391]\tTime 0.033 (0.053)\tData 0.003 (0.014)\tLoss 0.0004 (0.0051)\tPrec 100.000% (99.838%)\n",
      "Epoch: [179][200/391]\tTime 0.040 (0.047)\tData 0.002 (0.008)\tLoss 0.0409 (0.0052)\tPrec 99.219% (99.833%)\n",
      "Epoch: [179][300/391]\tTime 0.035 (0.045)\tData 0.002 (0.006)\tLoss 0.0009 (0.0047)\tPrec 100.000% (99.849%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.664 (0.664)\tLoss 0.2308 (0.2308)\tPrec 96.094% (96.094%)\n",
      " * Prec 91.810% \n",
      "best acc: 91.810000\n",
      "Epoch: [180][0/391]\tTime 1.159 (1.159)\tData 1.105 (1.105)\tLoss 0.0081 (0.0081)\tPrec 99.219% (99.219%)\n",
      "Epoch: [180][100/391]\tTime 0.039 (0.052)\tData 0.002 (0.013)\tLoss 0.0015 (0.0054)\tPrec 100.000% (99.838%)\n",
      "Epoch: [180][200/391]\tTime 0.037 (0.047)\tData 0.002 (0.008)\tLoss 0.0190 (0.0047)\tPrec 99.219% (99.856%)\n",
      "Epoch: [180][300/391]\tTime 0.040 (0.045)\tData 0.002 (0.006)\tLoss 0.0004 (0.0048)\tPrec 100.000% (99.855%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.784 (0.784)\tLoss 0.2215 (0.2215)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.600% \n",
      "best acc: 91.810000\n",
      "Epoch: [181][0/391]\tTime 1.045 (1.045)\tData 0.993 (0.993)\tLoss 0.0010 (0.0010)\tPrec 100.000% (100.000%)\n",
      "Epoch: [181][100/391]\tTime 0.036 (0.051)\tData 0.002 (0.012)\tLoss 0.0269 (0.0055)\tPrec 99.219% (99.752%)\n",
      "Epoch: [181][200/391]\tTime 0.044 (0.046)\tData 0.002 (0.007)\tLoss 0.0020 (0.0048)\tPrec 100.000% (99.813%)\n",
      "Epoch: [181][300/391]\tTime 0.040 (0.045)\tData 0.002 (0.006)\tLoss 0.0007 (0.0049)\tPrec 100.000% (99.813%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.483 (0.483)\tLoss 0.2208 (0.2208)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.640% \n",
      "best acc: 91.810000\n",
      "Epoch: [182][0/391]\tTime 1.056 (1.056)\tData 1.003 (1.003)\tLoss 0.0021 (0.0021)\tPrec 100.000% (100.000%)\n",
      "Epoch: [182][100/391]\tTime 0.042 (0.051)\tData 0.002 (0.012)\tLoss 0.0002 (0.0033)\tPrec 100.000% (99.899%)\n",
      "Epoch: [182][200/391]\tTime 0.041 (0.046)\tData 0.002 (0.007)\tLoss 0.0007 (0.0050)\tPrec 100.000% (99.837%)\n",
      "Epoch: [182][300/391]\tTime 0.041 (0.044)\tData 0.002 (0.006)\tLoss 0.0015 (0.0052)\tPrec 100.000% (99.831%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.593 (0.593)\tLoss 0.2235 (0.2235)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.720% \n",
      "best acc: 91.810000\n",
      "Epoch: [183][0/391]\tTime 1.079 (1.079)\tData 1.029 (1.029)\tLoss 0.0006 (0.0006)\tPrec 100.000% (100.000%)\n",
      "Epoch: [183][100/391]\tTime 0.040 (0.051)\tData 0.002 (0.013)\tLoss 0.0010 (0.0048)\tPrec 100.000% (99.838%)\n",
      "Epoch: [183][200/391]\tTime 0.041 (0.046)\tData 0.002 (0.008)\tLoss 0.0032 (0.0050)\tPrec 100.000% (99.829%)\n",
      "Epoch: [183][300/391]\tTime 0.041 (0.044)\tData 0.002 (0.006)\tLoss 0.0014 (0.0046)\tPrec 100.000% (99.855%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.817 (0.817)\tLoss 0.1865 (0.1865)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.680% \n",
      "best acc: 91.810000\n",
      "Epoch: [184][0/391]\tTime 0.927 (0.927)\tData 0.872 (0.872)\tLoss 0.0153 (0.0153)\tPrec 99.219% (99.219%)\n",
      "Epoch: [184][100/391]\tTime 0.039 (0.051)\tData 0.003 (0.011)\tLoss 0.0013 (0.0057)\tPrec 100.000% (99.814%)\n",
      "Epoch: [184][200/391]\tTime 0.034 (0.046)\tData 0.002 (0.007)\tLoss 0.0004 (0.0056)\tPrec 100.000% (99.817%)\n",
      "Epoch: [184][300/391]\tTime 0.038 (0.044)\tData 0.002 (0.005)\tLoss 0.0162 (0.0052)\tPrec 99.219% (99.829%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.804 (0.804)\tLoss 0.2510 (0.2510)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.810% \n",
      "best acc: 91.810000\n",
      "Epoch: [185][0/391]\tTime 0.717 (0.717)\tData 0.668 (0.668)\tLoss 0.0014 (0.0014)\tPrec 100.000% (100.000%)\n",
      "Epoch: [185][100/391]\tTime 0.042 (0.048)\tData 0.002 (0.009)\tLoss 0.0002 (0.0043)\tPrec 100.000% (99.861%)\n",
      "Epoch: [185][200/391]\tTime 0.032 (0.045)\tData 0.002 (0.006)\tLoss 0.0010 (0.0048)\tPrec 100.000% (99.848%)\n",
      "Epoch: [185][300/391]\tTime 0.045 (0.044)\tData 0.003 (0.005)\tLoss 0.0005 (0.0050)\tPrec 100.000% (99.836%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.686 (0.686)\tLoss 0.2921 (0.2921)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.660% \n",
      "best acc: 91.810000\n",
      "Epoch: [186][0/391]\tTime 0.971 (0.971)\tData 0.909 (0.909)\tLoss 0.0002 (0.0002)\tPrec 100.000% (100.000%)\n",
      "Epoch: [186][100/391]\tTime 0.040 (0.052)\tData 0.002 (0.011)\tLoss 0.0002 (0.0061)\tPrec 100.000% (99.807%)\n",
      "Epoch: [186][200/391]\tTime 0.044 (0.046)\tData 0.003 (0.007)\tLoss 0.0441 (0.0059)\tPrec 99.219% (99.817%)\n",
      "Epoch: [186][300/391]\tTime 0.036 (0.045)\tData 0.003 (0.006)\tLoss 0.0037 (0.0055)\tPrec 100.000% (99.829%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.870 (0.870)\tLoss 0.3005 (0.3005)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.410% \n",
      "best acc: 91.810000\n",
      "Epoch: [187][0/391]\tTime 1.052 (1.052)\tData 0.999 (0.999)\tLoss 0.0006 (0.0006)\tPrec 100.000% (100.000%)\n",
      "Epoch: [187][100/391]\tTime 0.042 (0.053)\tData 0.002 (0.013)\tLoss 0.0005 (0.0039)\tPrec 100.000% (99.869%)\n",
      "Epoch: [187][200/391]\tTime 0.041 (0.047)\tData 0.002 (0.007)\tLoss 0.0043 (0.0044)\tPrec 100.000% (99.841%)\n",
      "Epoch: [187][300/391]\tTime 0.038 (0.045)\tData 0.002 (0.006)\tLoss 0.0006 (0.0053)\tPrec 100.000% (99.821%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.331 (0.331)\tLoss 0.2439 (0.2439)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.450% \n",
      "best acc: 91.810000\n",
      "Epoch: [188][0/391]\tTime 1.300 (1.300)\tData 1.246 (1.246)\tLoss 0.0340 (0.0340)\tPrec 98.438% (98.438%)\n",
      "Epoch: [188][100/391]\tTime 0.044 (0.054)\tData 0.002 (0.015)\tLoss 0.0083 (0.0052)\tPrec 99.219% (99.822%)\n",
      "Epoch: [188][200/391]\tTime 0.029 (0.046)\tData 0.001 (0.009)\tLoss 0.0004 (0.0042)\tPrec 100.000% (99.856%)\n",
      "Epoch: [188][300/391]\tTime 0.037 (0.044)\tData 0.002 (0.007)\tLoss 0.0003 (0.0039)\tPrec 100.000% (99.868%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 1.080 (1.080)\tLoss 0.2272 (0.2272)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.360% \n",
      "best acc: 91.810000\n",
      "Epoch: [189][0/391]\tTime 1.018 (1.018)\tData 0.959 (0.959)\tLoss 0.0002 (0.0002)\tPrec 100.000% (100.000%)\n",
      "Epoch: [189][100/391]\tTime 0.039 (0.051)\tData 0.002 (0.012)\tLoss 0.0011 (0.0040)\tPrec 100.000% (99.853%)\n",
      "Epoch: [189][200/391]\tTime 0.045 (0.047)\tData 0.003 (0.007)\tLoss 0.0006 (0.0038)\tPrec 100.000% (99.860%)\n",
      "Epoch: [189][300/391]\tTime 0.044 (0.045)\tData 0.002 (0.006)\tLoss 0.0007 (0.0035)\tPrec 100.000% (99.881%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.316 (0.316)\tLoss 0.2372 (0.2372)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.600% \n",
      "best acc: 91.810000\n",
      "Epoch: [190][0/391]\tTime 1.099 (1.099)\tData 1.062 (1.062)\tLoss 0.0047 (0.0047)\tPrec 100.000% (100.000%)\n",
      "Epoch: [190][100/391]\tTime 0.040 (0.052)\tData 0.002 (0.013)\tLoss 0.0020 (0.0044)\tPrec 100.000% (99.845%)\n",
      "Epoch: [190][200/391]\tTime 0.041 (0.047)\tData 0.002 (0.008)\tLoss 0.0037 (0.0046)\tPrec 100.000% (99.845%)\n",
      "Epoch: [190][300/391]\tTime 0.040 (0.046)\tData 0.002 (0.006)\tLoss 0.0028 (0.0046)\tPrec 100.000% (99.839%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.235 (0.235)\tLoss 0.2379 (0.2379)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.510% \n",
      "best acc: 91.810000\n",
      "Epoch: [191][0/391]\tTime 0.730 (0.730)\tData 0.686 (0.686)\tLoss 0.0025 (0.0025)\tPrec 100.000% (100.000%)\n",
      "Epoch: [191][100/391]\tTime 0.044 (0.049)\tData 0.003 (0.009)\tLoss 0.0106 (0.0050)\tPrec 99.219% (99.830%)\n",
      "Epoch: [191][200/391]\tTime 0.038 (0.046)\tData 0.003 (0.006)\tLoss 0.0010 (0.0051)\tPrec 100.000% (99.821%)\n",
      "Epoch: [191][300/391]\tTime 0.042 (0.042)\tData 0.003 (0.005)\tLoss 0.0005 (0.0046)\tPrec 100.000% (99.852%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.334 (0.334)\tLoss 0.2354 (0.2354)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.450% \n",
      "best acc: 91.810000\n",
      "Epoch: [192][0/391]\tTime 0.669 (0.669)\tData 0.630 (0.630)\tLoss 0.0014 (0.0014)\tPrec 100.000% (100.000%)\n",
      "Epoch: [192][100/391]\tTime 0.036 (0.050)\tData 0.003 (0.009)\tLoss 0.0004 (0.0038)\tPrec 100.000% (99.876%)\n",
      "Epoch: [192][200/391]\tTime 0.040 (0.046)\tData 0.003 (0.006)\tLoss 0.0024 (0.0037)\tPrec 100.000% (99.895%)\n",
      "Epoch: [192][300/391]\tTime 0.042 (0.045)\tData 0.002 (0.005)\tLoss 0.0006 (0.0039)\tPrec 100.000% (99.883%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.685 (0.685)\tLoss 0.2784 (0.2784)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.570% \n",
      "best acc: 91.810000\n",
      "Epoch: [193][0/391]\tTime 0.867 (0.867)\tData 0.819 (0.819)\tLoss 0.0016 (0.0016)\tPrec 100.000% (100.000%)\n",
      "Epoch: [193][100/391]\tTime 0.046 (0.050)\tData 0.003 (0.011)\tLoss 0.0010 (0.0037)\tPrec 100.000% (99.876%)\n",
      "Epoch: [193][200/391]\tTime 0.043 (0.046)\tData 0.002 (0.007)\tLoss 0.0003 (0.0031)\tPrec 100.000% (99.903%)\n",
      "Epoch: [193][300/391]\tTime 0.035 (0.045)\tData 0.002 (0.006)\tLoss 0.0160 (0.0036)\tPrec 99.219% (99.894%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.445 (0.445)\tLoss 0.2643 (0.2643)\tPrec 94.531% (94.531%)\n",
      " * Prec 91.740% \n",
      "best acc: 91.810000\n",
      "Epoch: [194][0/391]\tTime 0.907 (0.907)\tData 0.864 (0.864)\tLoss 0.0008 (0.0008)\tPrec 100.000% (100.000%)\n",
      "Epoch: [194][100/391]\tTime 0.044 (0.047)\tData 0.003 (0.011)\tLoss 0.0006 (0.0034)\tPrec 100.000% (99.892%)\n",
      "Epoch: [194][200/391]\tTime 0.055 (0.042)\tData 0.002 (0.007)\tLoss 0.0019 (0.0035)\tPrec 100.000% (99.899%)\n",
      "Epoch: [194][300/391]\tTime 0.043 (0.042)\tData 0.002 (0.005)\tLoss 0.0003 (0.0041)\tPrec 100.000% (99.886%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.680 (0.680)\tLoss 0.2136 (0.2136)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.480% \n",
      "best acc: 91.810000\n",
      "Epoch: [195][0/391]\tTime 0.929 (0.929)\tData 0.873 (0.873)\tLoss 0.0007 (0.0007)\tPrec 100.000% (100.000%)\n",
      "Epoch: [195][100/391]\tTime 0.046 (0.050)\tData 0.002 (0.011)\tLoss 0.0020 (0.0033)\tPrec 100.000% (99.884%)\n",
      "Epoch: [195][200/391]\tTime 0.039 (0.045)\tData 0.002 (0.007)\tLoss 0.0001 (0.0036)\tPrec 100.000% (99.883%)\n",
      "Epoch: [195][300/391]\tTime 0.032 (0.043)\tData 0.001 (0.005)\tLoss 0.0008 (0.0035)\tPrec 100.000% (99.891%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.296 (0.296)\tLoss 0.2583 (0.2583)\tPrec 96.094% (96.094%)\n",
      " * Prec 91.550% \n",
      "best acc: 91.810000\n",
      "Epoch: [196][0/391]\tTime 0.962 (0.962)\tData 0.918 (0.918)\tLoss 0.0005 (0.0005)\tPrec 100.000% (100.000%)\n",
      "Epoch: [196][100/391]\tTime 0.040 (0.044)\tData 0.002 (0.011)\tLoss 0.0048 (0.0041)\tPrec 100.000% (99.853%)\n",
      "Epoch: [196][200/391]\tTime 0.032 (0.041)\tData 0.001 (0.007)\tLoss 0.0011 (0.0033)\tPrec 100.000% (99.876%)\n",
      "Epoch: [196][300/391]\tTime 0.045 (0.042)\tData 0.003 (0.005)\tLoss 0.0247 (0.0034)\tPrec 99.219% (99.883%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.856 (0.856)\tLoss 0.2365 (0.2365)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.650% \n",
      "best acc: 91.810000\n",
      "Epoch: [197][0/391]\tTime 0.774 (0.774)\tData 0.719 (0.719)\tLoss 0.0002 (0.0002)\tPrec 100.000% (100.000%)\n",
      "Epoch: [197][100/391]\tTime 0.039 (0.048)\tData 0.002 (0.010)\tLoss 0.0005 (0.0036)\tPrec 100.000% (99.853%)\n",
      "Epoch: [197][200/391]\tTime 0.042 (0.045)\tData 0.002 (0.006)\tLoss 0.0003 (0.0045)\tPrec 100.000% (99.860%)\n",
      "Epoch: [197][300/391]\tTime 0.044 (0.044)\tData 0.003 (0.005)\tLoss 0.0014 (0.0043)\tPrec 100.000% (99.868%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.300 (0.300)\tLoss 0.2276 (0.2276)\tPrec 95.312% (95.312%)\n",
      " * Prec 91.690% \n",
      "best acc: 91.810000\n",
      "Epoch: [198][0/391]\tTime 0.935 (0.935)\tData 0.877 (0.877)\tLoss 0.0087 (0.0087)\tPrec 99.219% (99.219%)\n",
      "Epoch: [198][100/391]\tTime 0.042 (0.051)\tData 0.002 (0.011)\tLoss 0.0006 (0.0052)\tPrec 100.000% (99.822%)\n",
      "Epoch: [198][200/391]\tTime 0.038 (0.047)\tData 0.002 (0.007)\tLoss 0.0012 (0.0043)\tPrec 100.000% (99.856%)\n",
      "Epoch: [198][300/391]\tTime 0.037 (0.045)\tData 0.002 (0.005)\tLoss 0.0003 (0.0040)\tPrec 100.000% (99.875%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.321 (0.321)\tLoss 0.2705 (0.2705)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.620% \n",
      "best acc: 91.810000\n",
      "Epoch: [199][0/391]\tTime 0.873 (0.873)\tData 0.801 (0.801)\tLoss 0.0022 (0.0022)\tPrec 100.000% (100.000%)\n",
      "Epoch: [199][100/391]\tTime 0.039 (0.053)\tData 0.002 (0.011)\tLoss 0.0004 (0.0045)\tPrec 100.000% (99.876%)\n",
      "Epoch: [199][200/391]\tTime 0.042 (0.048)\tData 0.002 (0.007)\tLoss 0.0039 (0.0041)\tPrec 100.000% (99.891%)\n",
      "Epoch: [199][300/391]\tTime 0.041 (0.046)\tData 0.002 (0.006)\tLoss 0.0006 (0.0037)\tPrec 100.000% (99.896%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.879 (0.879)\tLoss 0.2407 (0.2407)\tPrec 93.750% (93.750%)\n",
      " * Prec 91.480% \n",
      "best acc: 91.810000\n"
     ]
    }
   ],
   "source": [
    "# This cell won't be given, but students will complete the training\n",
    "\n",
    "lr = 3.95e-2\n",
    "weight_decay = 1e-4\n",
    "epochs = 200\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.92, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9181/10000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/VGG16_quant4bit/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "194f6743-4c2c-43a1-a93b-524b0148f37d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prehooked\n",
      "QuantConv2d(\n",
      "  3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 1\n",
      "prehooked\n",
      "QuantConv2d(\n",
      "  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 2\n",
      "prehooked\n",
      "QuantConv2d(\n",
      "  64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 3\n",
      "prehooked\n",
      "QuantConv2d(\n",
      "  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 4\n",
      "prehooked\n",
      "QuantConv2d(\n",
      "  128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 5\n",
      "prehooked\n",
      "QuantConv2d(\n",
      "  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 6\n",
      "prehooked\n",
      "QuantConv2d(\n",
      "  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 7\n",
      "prehooked\n",
      "QuantConv2d(\n",
      "  256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 8\n",
      "prehooked\n",
      "QuantConv2d(\n",
      "  8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 9\n",
      "prehooked\n",
      "QuantConv2d(\n",
      "  8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 10\n",
      "prehooked\n",
      "QuantConv2d(\n",
      "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 11\n",
      "prehooked\n",
      "QuantConv2d(\n",
      "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 12\n",
      "prehooked\n",
      "QuantConv2d(\n",
      "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ") 13\n"
     ]
    }
   ],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\") \n",
    "counter =0\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        print(\"prehooked\")\n",
    "        counter += 1\n",
    "        print(layer, counter)\n",
    "        layer.register_forward_pre_hook(save_output)       ## Input for the module will be grapped       \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(289.2113, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "weight = model.features[0].weight.abs().sum()\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "spoken-worst",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 4.,  2.,  0.],\n",
      "          [ 3., -1., -0.],\n",
      "          [-1., -3., -3.]],\n",
      "\n",
      "         [[ 2., -1., -3.],\n",
      "          [ 2., -2., -2.],\n",
      "          [-1., -4., -3.]],\n",
      "\n",
      "         [[ 3.,  1., -2.],\n",
      "          [ 4.,  2.,  1.],\n",
      "          [ 1.,  0., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-0.,  0.,  0.],\n",
      "          [-1., -1., -0.],\n",
      "          [-2., -2., -2.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.],\n",
      "          [ 0.,  0.,  1.],\n",
      "          [-1., -2., -2.]],\n",
      "\n",
      "         [[ 1.,  1.,  1.],\n",
      "          [ 1.,  1.,  1.],\n",
      "          [-1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[-4., -2.,  0.],\n",
      "          [-6.,  1.,  5.],\n",
      "          [-1.,  3.,  3.]],\n",
      "\n",
      "         [[-4., -1.,  4.],\n",
      "          [-7.,  2.,  7.],\n",
      "          [-4.,  1.,  4.]],\n",
      "\n",
      "         [[-3., -1.,  3.],\n",
      "          [-7.,  1.,  6.],\n",
      "          [-4., -1.,  2.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.,  0.,  0.],\n",
      "          [-0.,  1.,  1.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[-0.,  1.,  1.],\n",
      "          [-0.,  1.,  1.],\n",
      "          [-0.,  0.,  1.]],\n",
      "\n",
      "         [[-0.,  0.,  0.],\n",
      "          [-1., -1., -0.],\n",
      "          [-1., -1., -1.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.],\n",
      "          [ 0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  1.,  2.],\n",
      "          [-1., -1.,  2.],\n",
      "          [ 0.,  0.,  1.]],\n",
      "\n",
      "         [[-1., -1.,  0.],\n",
      "          [-2., -3.,  0.],\n",
      "          [-0., -1.,  1.]],\n",
      "\n",
      "         [[-0., -1.,  0.],\n",
      "          [-1., -2.,  0.],\n",
      "          [ 1., -0.,  0.]]]], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "w_bit = 4\n",
    "weight_q = model.features[0].weight_q # quantized value is stored during the training\n",
    "w_alpha = model.features[0].weight_quant.wgt_alpha\n",
    "w_delta = w_alpha/(2**(w_bit-1)-1)\n",
    "weight_int = weight_q/w_delta\n",
    "print(weight_int) # you should see clean integer numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d81547da-fb7d-41cd-b5ae-a924184151ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 3, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_int.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "interior-oxygen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [ 15.0000,  15.0000,  15.0000,  ...,  15.0000,  15.0000,  15.0000],\n",
      "          ...,\n",
      "          [  2.0000,   3.0000,   4.0000,  ...,   4.0000,   5.0000,   7.0000],\n",
      "          [  0.0000,   1.0000,   2.0000,  ...,  -1.0000,   2.0000,   6.0000],\n",
      "          [  7.0000,   7.0000,   7.0000,  ...,   7.0000,   7.0000,   9.0000]],\n",
      "\n",
      "         [[-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [ 15.0000,  15.0000,  15.0000,  ...,  15.0000,  15.0000,  15.0000],\n",
      "          ...,\n",
      "          [  3.0000,   4.0000,   5.0000,  ...,   4.0000,   6.0000,   7.0000],\n",
      "          [  1.0000,   2.0000,   3.0000,  ...,  -1.0000,   2.0000,   6.0000],\n",
      "          [  7.0000,   8.0000,   8.0000,  ...,   7.0000,   7.0000,   9.0000]],\n",
      "\n",
      "         [[-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          [-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          [ 15.0000,  15.0000,  15.0000,  ...,  15.0000,  15.0000,  15.0000],\n",
      "          ...,\n",
      "          [  6.0000,   7.0000,   7.0000,  ...,   6.0000,   7.0000,   8.0000],\n",
      "          [  4.0000,   4.0000,   5.0000,  ...,   1.0000,   3.0000,   6.0000],\n",
      "          [  8.0000,   8.0000,   8.0000,  ...,   8.0000,   8.0000,   9.0000]]],\n",
      "\n",
      "\n",
      "        [[[-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [  4.0000,  -0.0000,  -4.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          ...,\n",
      "          [ -0.0000,  -0.0000,  -6.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [  5.0000,  -1.0000,  -6.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [  4.0000,  -1.0000,  -6.0000,  ..., -14.0000, -14.0000, -14.0000]],\n",
      "\n",
      "         [[-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [  8.0000,   3.0000,  -1.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          ...,\n",
      "          [  2.0000,   3.0000,  -3.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [  7.0000,   2.0000,  -3.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [  6.0000,   2.0000,  -3.0000,  ..., -14.0000, -14.0000, -14.0000]],\n",
      "\n",
      "         [[-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          [-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          [ -4.0000,  -8.0000, -11.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          ...,\n",
      "          [ -6.0000,  -5.0000,  -7.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          [ -6.0000,  -9.0000, -10.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          [ -7.0000,  -8.0000, -10.0000,  ..., -12.0000, -12.0000, -12.0000]]],\n",
      "\n",
      "\n",
      "        [[[ -6.0000,  -6.0000,  -3.0000,  ...,  -0.0000,   2.0000,   4.0000],\n",
      "          [ -3.0000,  -2.0000,  -5.0000,  ...,   2.0000,   3.0000,   3.0000],\n",
      "          [ -3.0000,  -3.0000,  -6.0000,  ...,  -0.0000,   1.0000,   2.0000],\n",
      "          ...,\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000]],\n",
      "\n",
      "         [[ -3.0000,  -3.0000,  -1.0000,  ...,   2.0000,   4.0000,   6.0000],\n",
      "          [ -1.0000,   0.0000,  -3.0000,  ...,   4.0000,   5.0000,   6.0000],\n",
      "          [ -1.0000,  -1.0000,  -4.0000,  ...,   2.0000,   3.0000,   5.0000],\n",
      "          ...,\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000]],\n",
      "\n",
      "         [[ -4.0000,  -4.0000,  -1.0000,  ...,   3.0000,   4.0000,   5.0000],\n",
      "          [ -2.0000,  -1.0000,  -3.0000,  ...,   4.0000,   4.0000,   5.0000],\n",
      "          [ -2.0000,  -2.0000,  -4.0000,  ...,   3.0000,   3.0000,   4.0000],\n",
      "          ...,\n",
      "          [-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          [-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          [-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 15.0000,  15.0000,  15.0000,  ...,  14.0000,  14.0000,  15.0000],\n",
      "          [ 15.0000,  15.0000,  15.0000,  ...,  14.0000,  15.0000,  15.0000],\n",
      "          [ 15.0000,  15.0000,  15.0000,  ...,  15.0000,  15.0000,  15.0000],\n",
      "          ...,\n",
      "          [  5.0000,   5.0000,   3.0000,  ...,   3.0000,   2.0000,   3.0000],\n",
      "          [  6.0000,   5.0000,   0.0000,  ...,  -0.0000,  -1.0000,   0.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000]],\n",
      "\n",
      "         [[ 15.0000,  15.0000,  15.0000,  ...,  14.0000,  15.0000,  15.0000],\n",
      "          [ 15.0000,  15.0000,  15.0000,  ...,  14.0000,  15.0000,  15.0000],\n",
      "          [ 15.0000,  15.0000,  15.0000,  ...,  15.0000,  15.0000,  15.0000],\n",
      "          ...,\n",
      "          [  5.0000,   5.0000,   3.0000,  ...,   4.0000,   4.0000,   4.0000],\n",
      "          [  6.0000,   5.0000,   1.0000,  ...,   2.0000,   0.0000,   1.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000]],\n",
      "\n",
      "         [[ 15.0000,  15.0000,  15.0000,  ...,  15.0000,  15.0000,  15.0000],\n",
      "          [ 15.0000,  15.0000,  15.0000,  ...,  15.0000,  15.0000,  15.0000],\n",
      "          [ 15.0000,  15.0000,  15.0000,  ...,  15.0000,  15.0000,  15.0000],\n",
      "          ...,\n",
      "          [  4.0000,   4.0000,   2.0000,  ...,   3.0000,   3.0000,   3.0000],\n",
      "          [  5.0000,   4.0000,  -0.0000,  ...,   1.0000,  -0.0000,   1.0000],\n",
      "          [-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000]]],\n",
      "\n",
      "\n",
      "        [[[  5.0000,   3.0000,   3.0000,  ...,   5.0000,   1.0000,  -2.0000],\n",
      "          [  7.0000,   6.0000,   1.0000,  ...,   2.0000,   2.0000,   2.0000],\n",
      "          [  6.0000,   6.0000,   4.0000,  ...,   3.0000,   2.0000,   3.0000],\n",
      "          ...,\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000]],\n",
      "\n",
      "         [[ 10.0000,   8.0000,   8.0000,  ...,  12.0000,   8.0000,   3.0000],\n",
      "          [ 12.0000,  12.0000,   6.0000,  ...,   9.0000,  10.0000,   8.0000],\n",
      "          [ 12.0000,  13.0000,  10.0000,  ...,   9.0000,  10.0000,  10.0000],\n",
      "          ...,\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000]],\n",
      "\n",
      "         [[  8.0000,   6.0000,   5.0000,  ...,   7.0000,   4.0000,   1.0000],\n",
      "          [  9.0000,   9.0000,   4.0000,  ...,   4.0000,   6.0000,   5.0000],\n",
      "          [  8.0000,   9.0000,   7.0000,  ...,   4.0000,   5.0000,   6.0000],\n",
      "          ...,\n",
      "          [-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          [-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          [-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000]]],\n",
      "\n",
      "\n",
      "        [[[-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          ...,\n",
      "          [-12.0000, -12.0000, -12.0000,  ...,   1.0000,   0.0000, -14.0000],\n",
      "          [ -4.0000,  -6.0000, -10.0000,  ...,   1.0000,   1.0000, -14.0000],\n",
      "          [  1.0000,   1.0000,  -2.0000,  ...,   0.0000,   0.0000, -14.0000]],\n",
      "\n",
      "         [[-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          [-14.0000, -14.0000, -14.0000,  ..., -14.0000, -14.0000, -14.0000],\n",
      "          ...,\n",
      "          [-13.0000, -12.0000, -12.0000,  ...,  -1.0000,  -1.0000, -14.0000],\n",
      "          [ -5.0000,  -7.0000, -10.0000,  ...,  -1.0000,  -1.0000, -14.0000],\n",
      "          [  1.0000,  -0.0000,  -3.0000,  ...,  -2.0000,  -2.0000, -14.0000]],\n",
      "\n",
      "         [[-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          [-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          [-12.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000, -12.0000],\n",
      "          ...,\n",
      "          [-10.0000,  -9.0000,  -9.0000,  ...,  -2.0000,  -2.0000, -12.0000],\n",
      "          [ -4.0000,  -5.0000,  -8.0000,  ...,  -1.0000,  -1.0000, -12.0000],\n",
      "          [  1.0000,   0.0000,  -2.0000,  ...,  -2.0000,  -1.0000, -12.0000]]]],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_bit = 4\n",
    "x = save_output.outputs[0][0]  # input of the 8th conv layer\n",
    "x_alpha  = model.features[0].act_alpha\n",
    "x_delta = x_alpha/(2**x_bit-1)\n",
    "\n",
    "act_quant_fn = act_quantization(x_bit) # define the quantization function\n",
    "x_q = act_quant_fn(x, x_alpha)         # create the quantized value for x\n",
    "\n",
    "x_int = x_q/x_delta\n",
    "print(x_int) # you should see clean integer numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e95d61df-af9f-4757-9d1c-10552623c0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 32, 32])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_int.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ranging-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 3, out_channels=64, kernel_size = 3, padding=1, bias = False)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "relu = nn.ReLU()\n",
    "output_int = conv_int(x_int)\n",
    "output_recovered = output_int*w_delta*x_delta\n",
    "output_recovered = relu(output_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4798, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "difference = abs(save_output.outputs[1][0] - output_recovered )\n",
    "print(difference.mean())  ## It should be small, e.g.,2.3 in my trainned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9847b443-1afd-44b0-8880-d52aa78e8458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "157dffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pad = torch.zeros(128, 3, 34, 34).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sorted-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pad[ : ,  :, 1:33, 1:33] = x_int.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a7f9bdd-6701-445f-a420-bf0ef45080d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 3, 34, 34])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pad.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbe24611-220e-4e61-a5f0-bccde1781a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000,   0.0000],\n",
       "        [  0.0000, -12.0000, -12.0000,  ..., -12.0000, -12.0000,   0.0000],\n",
       "        ...,\n",
       "        [  0.0000,   4.0000,   4.0000,  ...,   3.0000,   6.0000,   0.0000],\n",
       "        [  0.0000,   8.0000,   8.0000,  ...,   8.0000,   9.0000,   0.0000],\n",
       "        [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pad[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "significant-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_pad[0]\n",
    "X = torch.reshape(X, (X.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "688e2e6e-a200-4219-95bb-72095d0bd5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0., -14., -14., -14., -14., -14., -14., -14., -14., -14., -14., -14.,\n",
       "        -14., -14., -14., -14., -14., -14., -14., -14., -14., -14., -14., -14.,\n",
       "        -14., -14., -14., -14., -14., -14., -14., -14., -14.,   0.],\n",
       "       device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][34:68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "corresponding-significance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1156])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size() # in_ch = 3, nij = 34 * 34 = 1156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "exposed-witch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "-14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 0.0 \n",
      "\n",
      "-14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 \n",
      "\n",
      "-14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 \n",
      "\n",
      "-14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 0.0 \n",
      "\n",
      "-14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 \n",
      "\n",
      "-14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 \n",
      "\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "-14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 0.0 \n",
      "\n",
      "-14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 \n",
      "\n",
      "-14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 \n",
      "\n",
      "-14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 0.0 \n",
      "\n",
      "-14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 \n",
      "\n",
      "-14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 -14.0 \n",
      "\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 \n",
      "\n",
      "-12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 0.0 \n",
      "\n",
      "-12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 \n",
      "\n",
      "-12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 \n",
      "\n",
      "-12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 0.0 \n",
      "\n",
      "-12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 \n",
      "\n",
      "-12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 -12.000000953674316 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output stationary\n",
    "tile_id = 0 \n",
    "nij = 200 # just a random number\n",
    "#X = a_tile[tile_id,:,nij:nij+64]  # [tile_num, array row num, time_steps]\n",
    "\n",
    "# time0row7 ... time0row0\n",
    "# ...\n",
    "# time8row7 ... time0row0\n",
    "\n",
    "# row 7 ............... row0\n",
    "#  7  6  5  4  3  2  1  0      time0\n",
    "#  8  7  6  5  4  3  2  1\n",
    "# 11 10  9  8  5  4  3  2\n",
    "# 15 14 13 12  9  8 35 34\n",
    "# 16 15 14 13 10  9 36 35\n",
    "# 17 16 15 14 11 10 37 36\n",
    "# 21 20 19 18 15 14 69 68\n",
    "# 22 21 20 19 16 15 70 69\n",
    "# 23 22 21 20 17 16 71 70      time8\n",
    "\n",
    "bit_precision = 4\n",
    "row_index = [7, 6, 5, 4, 3, 2, 1, 0]\n",
    "kij_index = [0, 1, 2, 34, 35, 36, 68, 69, 70]\n",
    "\n",
    "file = open('activation_os.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for in_ch in range(X.size(0)):  # big time loop - in_ch = 3\n",
    "    for kij in range(9): # kij 0~8 - time (+ kij_index[0-8])\n",
    "        for j in range(8): # row 7-0 (row_index[0-7])\n",
    "            ind = row_index[j]+kij_index[kij]\n",
    "            if (X[in_ch, ind].item()<0):\n",
    "                X_bin = '{0:04b}'.format(int(X[in_ch, ind].item()+2**bit_precision+0.001))\n",
    "            else:\n",
    "                X_bin = '{0:04b}'.format(int(X[in_ch, ind].item()+0.001))                \n",
    "            for k in range(bit_precision):\n",
    "                file.write(X_bin[k])        \n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "            print(X[in_ch, ind].item(), end=' ')\n",
    "        file.write('\\n')\n",
    "        print(\"\\n\")\n",
    "file.close() #close file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "939c4ede-548e-463c-96b8-09452560606c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 8 7 6 3 2 1 0 \n",
      "\n",
      "10 9 8 7 4 3 2 1 \n",
      "\n",
      "11 10 9 8 5 4 3 2 \n",
      "\n",
      "15 14 13 12 9 8 7 6 \n",
      "\n",
      "16 15 14 13 10 9 8 7 \n",
      "\n",
      "17 16 15 14 11 10 9 8 \n",
      "\n",
      "21 20 19 18 15 14 13 12 \n",
      "\n",
      "22 21 20 19 16 15 14 13 \n",
      "\n",
      "23 22 21 20 17 16 15 14 \n",
      "\n",
      "9 8 7 6 3 2 1 0 \n",
      "\n",
      "10 9 8 7 4 3 2 1 \n",
      "\n",
      "11 10 9 8 5 4 3 2 \n",
      "\n",
      "15 14 13 12 9 8 7 6 \n",
      "\n",
      "16 15 14 13 10 9 8 7 \n",
      "\n",
      "17 16 15 14 11 10 9 8 \n",
      "\n",
      "21 20 19 18 15 14 13 12 \n",
      "\n",
      "22 21 20 19 16 15 14 13 \n",
      "\n",
      "23 22 21 20 17 16 15 14 \n",
      "\n",
      "9 8 7 6 3 2 1 0 \n",
      "\n",
      "10 9 8 7 4 3 2 1 \n",
      "\n",
      "11 10 9 8 5 4 3 2 \n",
      "\n",
      "15 14 13 12 9 8 7 6 \n",
      "\n",
      "16 15 14 13 10 9 8 7 \n",
      "\n",
      "17 16 15 14 11 10 9 8 \n",
      "\n",
      "21 20 19 18 15 14 13 12 \n",
      "\n",
      "22 21 20 19 16 15 14 13 \n",
      "\n",
      "23 22 21 20 17 16 15 14 \n",
      "\n",
      "9 8 7 6 3 2 1 0 \n",
      "\n",
      "10 9 8 7 4 3 2 1 \n",
      "\n",
      "11 10 9 8 5 4 3 2 \n",
      "\n",
      "15 14 13 12 9 8 7 6 \n",
      "\n",
      "16 15 14 13 10 9 8 7 \n",
      "\n",
      "17 16 15 14 11 10 9 8 \n",
      "\n",
      "21 20 19 18 15 14 13 12 \n",
      "\n",
      "22 21 20 19 16 15 14 13 \n",
      "\n",
      "23 22 21 20 17 16 15 14 \n",
      "\n",
      "9 8 7 6 3 2 1 0 \n",
      "\n",
      "10 9 8 7 4 3 2 1 \n",
      "\n",
      "11 10 9 8 5 4 3 2 \n",
      "\n",
      "15 14 13 12 9 8 7 6 \n",
      "\n",
      "16 15 14 13 10 9 8 7 \n",
      "\n",
      "17 16 15 14 11 10 9 8 \n",
      "\n",
      "21 20 19 18 15 14 13 12 \n",
      "\n",
      "22 21 20 19 16 15 14 13 \n",
      "\n",
      "23 22 21 20 17 16 15 14 \n",
      "\n",
      "9 8 7 6 3 2 1 0 \n",
      "\n",
      "10 9 8 7 4 3 2 1 \n",
      "\n",
      "11 10 9 8 5 4 3 2 \n",
      "\n",
      "15 14 13 12 9 8 7 6 \n",
      "\n",
      "16 15 14 13 10 9 8 7 \n",
      "\n",
      "17 16 15 14 11 10 9 8 \n",
      "\n",
      "21 20 19 18 15 14 13 12 \n",
      "\n",
      "22 21 20 19 16 15 14 13 \n",
      "\n",
      "23 22 21 20 17 16 15 14 \n",
      "\n",
      "9 8 7 6 3 2 1 0 \n",
      "\n",
      "10 9 8 7 4 3 2 1 \n",
      "\n",
      "11 10 9 8 5 4 3 2 \n",
      "\n",
      "15 14 13 12 9 8 7 6 \n",
      "\n",
      "16 15 14 13 10 9 8 7 \n",
      "\n",
      "17 16 15 14 11 10 9 8 \n",
      "\n",
      "21 20 19 18 15 14 13 12 \n",
      "\n",
      "22 21 20 19 16 15 14 13 \n",
      "\n",
      "23 22 21 20 17 16 15 14 \n",
      "\n",
      "9 8 7 6 3 2 1 0 \n",
      "\n",
      "10 9 8 7 4 3 2 1 \n",
      "\n",
      "11 10 9 8 5 4 3 2 \n",
      "\n",
      "15 14 13 12 9 8 7 6 \n",
      "\n",
      "16 15 14 13 10 9 8 7 \n",
      "\n",
      "17 16 15 14 11 10 9 8 \n",
      "\n",
      "21 20 19 18 15 14 13 12 \n",
      "\n",
      "22 21 20 19 16 15 14 13 \n",
      "\n",
      "23 22 21 20 17 16 15 14 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output stationary - separate files\n",
    "tile_id = 0 \n",
    "nij = 200 # just a random number\n",
    "#X = a_tile[tile_id,:,nij:nij+64]  # [tile_num, array row num, time_steps]\n",
    "\n",
    "# time0row7 ... time0row0\n",
    "# ...\n",
    "# time8row7 ... time0row0\n",
    "\n",
    "# row 7 ............... row0\n",
    "#  9  8  7  6  3  2  1  0      time0\n",
    "# 10  9  8  7  4  3  2  1\n",
    "# 11 10  9  8  5  4  3  2\n",
    "# 15 14 13 12  9  8  7  6\n",
    "# 16 15 14 13 10  9  8  7\n",
    "# 17 16 15 14 11 10  9  8\n",
    "# 21 20 19 18 15 14 13 12\n",
    "# 22 21 20 19 16 15 14 13\n",
    "# 23 22 21 20 17 16 15 14      time8\n",
    "\n",
    "bit_precision = 4\n",
    "row_index = [9, 8, 7, 6, 3, 2, 1, 0]\n",
    "kij_index = [0, 1, 2, 6, 7, 8, 12, 13, 14]\n",
    "\n",
    "\n",
    "for in_ch in range(X.size(0)):  # big time loop - in_ch = 8\n",
    "    filename = 'activation_os_ich' + str(in_ch) + '.txt'\n",
    "    file = open(filename, 'w') #write to file\n",
    "    file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "    file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "    file.write('#................#\\n')\n",
    "    \n",
    "    for kij in range(9): # kij 0~8 - time (+ kij_index[0-8])\n",
    "        for j in range(8): # row 7-0 (row_index[0-7])\n",
    "            ind = row_index[j]+kij_index[kij]\n",
    "            X_bin = '{0:04b}'.format(int(X[in_ch, ind].item()+0.001))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(X_bin[k])        \n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "            print(ind, end=' ')\n",
    "        file.write('\\n')\n",
    "        print(\"\\n\")\n",
    "file.close() #close file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1227a60f-67d1-445b-8da8-a9578c73991b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28936cad-cd36-451c-84fa-28095f45fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight stationary\n",
    "tile_id = 0 \n",
    "nij = 200 # just a random number\n",
    "#X = a_tile[tile_id,:,nij:nij+64]  # [tile_num, array row num, time_steps]\n",
    "\n",
    "bit_precision = 4\n",
    "file = open('activation1.txt', 'w') #write to file\n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:04b}'.format(int(X[7-j,i].item()+0.001))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5., 0., 0., 5., 0., 0., 8., 0.], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "minimal-serbia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 3, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_int.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22f66882-be12-4c92-b931-fe371d5c831c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 9])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_int.size() # 64, 3, 3, 3\n",
    "W = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))\n",
    "W.size() # 64, 3, 9  # o_ch, in_ch, kij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f73e719f-aeec-4b16-94b8-171346449ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  2.,  0.,  3., -1., -0., -1., -3., -3.],\n",
       "        [ 2., -1., -3.,  2., -2., -2., -1., -4., -3.],\n",
       "        [ 3.,  1., -2.,  4.,  2.,  1.,  1.,  0., -1.]], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0][:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "882fc3af-630e-47d4-900b-2f488cfc0d3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 3.0 -1.0 -0.0 -4.0 -0.0 4.0 \n",
      "\n",
      "0.0 0.0 3.0 -0.0 0.0 -2.0 0.0 2.0 \n",
      "\n",
      "0.0 0.0 2.0 -1.0 -0.0 0.0 0.0 0.0 \n",
      "\n",
      "0.0 0.0 3.0 -1.0 -0.0 -6.0 -1.0 3.0 \n",
      "\n",
      "0.0 0.0 4.0 -1.0 -0.0 1.0 -1.0 -1.0 \n",
      "\n",
      "0.0 0.0 2.0 -1.0 -0.0 5.0 -0.0 -0.0 \n",
      "\n",
      "0.0 0.0 1.0 0.0 -0.0 -1.0 -2.0 -1.0 \n",
      "\n",
      "0.0 0.0 1.0 -0.0 -0.0 3.0 -2.0 -3.0 \n",
      "\n",
      "0.0 0.0 1.0 -0.0 -0.0 3.0 -2.0 -3.0 \n",
      "\n",
      "0.0 0.0 1.0 -1.0 -0.0 -4.0 1.0 2.0 \n",
      "\n",
      "0.0 0.0 0.0 -1.0 0.0 -1.0 1.0 -1.0 \n",
      "\n",
      "0.0 0.0 -1.0 -1.0 -0.0 4.0 1.0 -3.0 \n",
      "\n",
      "0.0 1.0 -0.0 -1.0 0.0 -7.0 0.0 2.0 \n",
      "\n",
      "-0.0 1.0 0.0 -1.0 0.0 2.0 0.0 -2.0 \n",
      "\n",
      "0.0 0.0 0.0 -0.0 -0.0 7.0 1.0 -2.0 \n",
      "\n",
      "0.0 0.0 -2.0 1.0 0.0 -4.0 -1.0 -1.0 \n",
      "\n",
      "0.0 0.0 -1.0 0.0 0.0 1.0 -2.0 -4.0 \n",
      "\n",
      "0.0 0.0 -1.0 0.0 0.0 4.0 -2.0 -3.0 \n",
      "\n",
      "0.0 1.0 1.0 -0.0 0.0 -3.0 1.0 3.0 \n",
      "\n",
      "-0.0 1.0 1.0 -0.0 1.0 -1.0 1.0 1.0 \n",
      "\n",
      "0.0 1.0 -1.0 -0.0 0.0 3.0 1.0 -2.0 \n",
      "\n",
      "0.0 1.0 0.0 -0.0 1.0 -7.0 1.0 4.0 \n",
      "\n",
      "0.0 1.0 -0.0 -0.0 1.0 1.0 1.0 2.0 \n",
      "\n",
      "0.0 1.0 -1.0 -0.0 0.0 6.0 1.0 1.0 \n",
      "\n",
      "0.0 1.0 -2.0 0.0 0.0 -4.0 -1.0 1.0 \n",
      "\n",
      "0.0 1.0 -2.0 0.0 1.0 -1.0 -1.0 0.0 \n",
      "\n",
      "0.0 1.0 -2.0 0.0 0.0 2.0 -1.0 -1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# output stationary\n",
    "bit_precision = 4\n",
    "file = open('weight_os.txt', 'w') #write to file\n",
    "file.write('#kij0och7[msb-lsb],kij0och6[msb-lst],....,kij0och0[msb-lst]#\\n')\n",
    "file.write('#kij1och7[msb-lsb],kij1och6[msb-lst],....,kij1och0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "for in_ch in range(W.size(1)):   # in_ch = 3\n",
    "    for kij in range(W.size(2)):   # kij = 9\n",
    "        for o_ch in range(8):   # o_ch = 64 -> only first 8\n",
    "            if (W[7-o_ch, in_ch, kij].item()<0):\n",
    "                W_bin = '{0:04b}'.format(int(W[7-o_ch, in_ch, kij].item()+2**bit_precision+0.001))\n",
    "            else:\n",
    "                W_bin = '{0:04b}'.format(int(W[7-o_ch, in_ch, kij].item()+0.001))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(W_bin[k])        \n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "            print(W[7-o_ch, in_ch, kij].item(), end=' ')\n",
    "        file.write('\\n')\n",
    "        print('\\n')\n",
    "file.close() #close file  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5e39f52-ef51-46ee-b06e-e06614ffa9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output stationary - separate files\n",
    "bit_precision = 4\n",
    "for in_ch in range(W.size(0)):   # in_ch = 8\n",
    "    filename = 'weight_os_ich' + str(in_ch) + '.txt'\n",
    "    file = open(filename, 'w') #write to file\n",
    "    file.write('#kij0och7[msb-lsb],kij0och6[msb-lst],....,kij0och0[msb-lst]#\\n')\n",
    "    file.write('#kij1och7[msb-lsb],kij1och6[msb-lst],....,kij1och0[msb-lst]#\\n')\n",
    "    file.write('#................#\\n')\n",
    "    for kij in range(W.size(2)):   # kij = 9\n",
    "        for o_ch in range(W.size(1)):   # o_ch = 8\n",
    "            if (W[in_ch, 7-o_ch, kij].item()<0):\n",
    "                W_bin = '{0:04b}'.format(int(W[in_ch, 7-o_ch, kij].item()+2**bit_precision+0.001))\n",
    "            else:\n",
    "                W_bin = '{0:04b}'.format(int(W[in_ch, 7-o_ch, kij].item()+0.001))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(W_bin[k])        \n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "file.close() #close file  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76851af-e824-4e41-9f4a-7fcf5a3e9d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0da64738-4ed4-494c-aac3-ef94a9275d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight stationary\n",
    "bit_precision = 4\n",
    "file = open('weight1.txt', 'w') #write to file\n",
    "file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "for kij in range(9):\n",
    "    for i in range(W.size(0)):  \n",
    "        for j in range(W.size(1)):\n",
    "            if (W[i, 7-j, kij].item()<0):\n",
    "                W_bin = '{0:04b}'.format(int(W[i,7-j,kij].item()+2**bit_precision+0.001))\n",
    "            else:\n",
    "                W_bin = '{0:04b}'.format(int(W[i,7-j,kij].item()+0.001))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(W_bin[k])        \n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "file.close() #close file  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8c6d7c5-b5ba-4649-a1d2-cc6e69006083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7.0000,  3.0000,  7.0000, -2.0000, -3.0000, -3.0000,  7.0000,  2.0000],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bade1b-0145-4bf7-b70f-fc294cdaf0c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c44337f4-a48a-40f7-be25-436e5fca6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_nijg = range(X.size(1)) ## psum nij group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "943c8edd-7107-4d83-bd31-d534dbf3d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "psum = torch.zeros(8, len(p_nijg), 9).cuda() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "016d0414-8cba-4361-bcfe-2fedd54b7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kij in range(9):  \n",
    "    for nij in p_nijg:       # time domain, sequentially given input\n",
    "        m = nn.Linear(8, 8, bias=False)\n",
    "        m.weight = torch.nn.Parameter(W[:,:,kij])\n",
    "        psum[:, nij, kij] = m(X[:,nij]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee7da35d-bbfd-439b-ad8d-d0cedf9cb188",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_precision = 16\n",
    "file = open('psum1.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "for kij in range(9):\n",
    "    for i in range(psum.size(1)):\n",
    "        for j in range(psum.size(0)):\n",
    "            if (psum[7-j,i,kij].item()<0):\n",
    "                P_bin = '{0:016b}'.format(int(psum[7-j,i,kij].item()+2**bit_precision+0.001))\n",
    "            else:\n",
    "                P_bin = '{0:016b}'.format(int(psum[7-j,i,kij].item()+0.001))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(P_bin[k])\n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d56435e9-173c-44f4-8f03-2002ca788036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 22.,  67.,  25., -42., -53., -38.,  31.,  85.], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psum[:,8,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c7a5d4-b1b2-4c02-84a2-d56e3799d6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "506b7c4d-f6fa-439f-a92a-99aa16057f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 32, 32])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_int.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "332e5c3e-4c3b-40ac-a5df-56ac781d99c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = output_int[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59092bec-ac90-4d24-9b02-159fcc729b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "629e49a8-b20c-41d1-884d-cbe7cafbdfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.reshape(out, (out.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c80baf4-0fbf-4d9a-8318-9ed3b83c7dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d4ca109-b842-4774-8f40-d025b743fd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1024])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size() # och, onij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "191dc31a-4f28-411a-a1a9-3030a3d33c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_precision = 16\n",
    "file = open('output_os.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(8): # first 8 och\n",
    "    for j in range(8): # first 8 onij\n",
    "        if (out[7-j,i].item()<0):\n",
    "            O_bin = '{0:016b}'.format(int(out[7-j,i].item()+2**bit_precision+0.001))\n",
    "        else:\n",
    "            O_bin = '{0:016b}'.format(int(out[7-j,i].item()+0.001))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(O_bin[k])\n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6269128d-c9df-4668-916d-73019893d4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 126.0000,  168.0000,  -76.0000,  -36.0000,   56.0000,  -28.0000,\n",
       "        -100.0000,    0.0000,   50.0000,  112.0000,  -22.0000,  -24.0000,\n",
       "          78.0000,  -72.0000,  -30.0000,   50.0000,    0.0000,  -60.0000,\n",
       "          72.0000, -134.0000,  -60.0000,   28.0000,  238.0000,  -28.0000,\n",
       "          70.0000,    0.0000,    0.0000,   70.0000,  -60.0000,    0.0000,\n",
       "         188.0000,  -12.0000,    2.0000,  -50.0000,   12.0000,  -74.0000,\n",
       "          68.0000,   64.0000,   14.0000,  134.0000, -266.0000,  -20.0000,\n",
       "        -230.0000,  -44.0000,   56.0000,  -74.0000,  -14.0000,   42.0000,\n",
       "         -38.0000,   22.0000,  366.0000,   42.0000,  132.0000,  -54.0000,\n",
       "          -6.0000,  116.0000,   44.0000,  140.0000,  -74.0000, -134.0000,\n",
       "          34.0000,  -10.0000,    0.0000,   80.0000], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f565a8d-88d3-4614-97a6-73e061b653e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
